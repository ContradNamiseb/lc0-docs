<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Q9ZYT7KV87"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Q9ZYT7KV87');
</script>

<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Leela Chess Zero: src/neural/backends/cuda/network_cuda.cc Source File</title>
<link rel="icon" type="image/png" href="../images/favicon.png" />
<link href="../css/tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../js/jquery.js"></script>
<script type="text/javascript" src="../js/dynsections.js"></script>
<link href="../css/navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../js/resize.js"></script>
<script type="text/javascript" src="../js/navtreedata.js?v=3"></script>
<script type="text/javascript" src="../js/navtree.js?v=3"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="../css/doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Leela Chess Zero<span id="projectnumber">&#160;dev</span>
   </div>
   <div id="projectbrief">Neural network based chess engine</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../js/menudata.js?v=3"></script>
<script type="text/javascript" src="../js/menu.js?v=3"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function() { init_codefold(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('network__cuda_8cc_source.html','../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">network_cuda.cc</div></div>
</div><!--header-->
<div class="contents">
<a href="network__cuda_8cc.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/*</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">  This file is part of Leela Chess Zero.</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">  Copyright (C) 2018-2022 The LCZero Authors</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment"></span> </div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment">  Leela Chess is free software: you can redistribute it and/or modify</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment">  it under the terms of the GNU General Public License as published by</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">  the Free Software Foundation, either version 3 of the License, or</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment">  (at your option) any later version.</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment"></span> </div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment">  Leela Chess is distributed in the hope that it will be useful,</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment">  but WITHOUT ANY WARRANTY; without even the implied warranty of</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment">  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment">  GNU General Public License for more details.</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment"></span> </div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment">  You should have received a copy of the GNU General Public License</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="comment">  along with Leela Chess.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="comment"></span> </div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="comment">  Additional permission under GNU GPL version 3 section 7</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="comment"></span> </div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="comment">  If you modify this Program, or any covered work, by linking or</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="comment">  combining it with NVIDIA Corporation&#39;s libraries from the NVIDIA CUDA</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="comment">  Toolkit and the NVIDIA CUDA Deep Neural Network library (or a</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="comment">  modified version of those libraries), containing parts covered by the</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="comment">  terms of the respective license agreement, the licensors of this</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="comment">  Program grant you additional permission to convey the resulting work.</span></div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="comment">*/</span></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="preprocessor">#include &lt;cassert&gt;</span></div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="preprocessor">#include &lt;list&gt;</span></div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="preprocessor">#include &lt;memory&gt;</span></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span><span class="preprocessor">#include &lt;mutex&gt;</span></div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span><span class="preprocessor">#include &lt;type_traits&gt;</span></div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span> </div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="preprocessor">#include &quot;<a class="code" href="cuda__common_8h.html">cuda_common.h</a>&quot;</span></div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span><span class="preprocessor">#include &quot;<a class="code" href="sycl_2inputs__outputs_8h.html">inputs_outputs.h</a>&quot;</span></div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span><span class="preprocessor">#include &quot;<a class="code" href="sycl_2kernels_8h.html">kernels.h</a>&quot;</span></div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span><span class="preprocessor">#include &quot;<a class="code" href="sycl_2layers_8h.html">layers.h</a>&quot;</span></div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span><span class="preprocessor">#include &quot;<a class="code" href="neural_2factory_8h.html">neural/factory.h</a>&quot;</span></div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span><span class="preprocessor">#include &quot;<a class="code" href="network__legacy_8h.html">neural/network_legacy.h</a>&quot;</span></div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span><span class="preprocessor">#include &quot;<a class="code" href="attention__policy__map_8h.html">neural/tables/attention_policy_map.h</a>&quot;</span></div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span><span class="preprocessor">#include &quot;<a class="code" href="policy__map_8h.html">neural/tables/policy_map.h</a>&quot;</span></div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span><span class="preprocessor">#include &quot;<a class="code" href="exception_8h.html">utils/exception.h</a>&quot;</span></div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span><span class="preprocessor">#include &quot;<a class="code" href="fp16__utils_8h.html">utils/fp16_utils.h</a>&quot;</span></div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span><span class="preprocessor">#include &quot;<a class="code" href="trace_8h.html">utils/trace.h</a>&quot;</span></div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span> </div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span><span class="preprocessor">#if CUDART_VERSION &gt;= 11010</span></div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span><span class="preprocessor">#define CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS 1</span></div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno"><a class="line" href="network__cuda_8cc.html#ad0077596f0a38b26cf89984e950c8225">   49</a></span><span class="preprocessor">#define CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS 0</span></div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span><span class="preprocessor">#undef cudaEventWaitExternal</span></div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span><span class="preprocessor">#undef cudaEventRecordExternal</span></div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span> </div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacelczero.html">lczero</a> {</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span><span class="keyword">using namespace </span>cudnn_backend;</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span> </div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span><span class="keyword">class </span>CudaNetwork;</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span> </div>
<div class="foldopen" id="foldopen00061" data-start="{" data-end="}">
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno"><a class="line" href="namespacelczero.html#a240fb199a13e5acdecb5207efc7becde">   61</a></span><span class="keyword">static</span> <span class="keywordtype">size_t</span> <a class="code hl_function" href="namespacelczero.html#a240fb199a13e5acdecb5207efc7becde">getMaxAttentionHeadSize</a>(</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>    <span class="keyword">const</span> <a class="code hl_struct" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html">MultiHeadWeights::PolicyHead</a>&amp; weights, <span class="keywordtype">int</span> N) {</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> embedding_op_size = weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#afa3328e192dbca1c42f672b922c58c07">ip_pol_b</a>.size();</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> policy_d_model = weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#ab693b3cf4392b0a4e2e5e2f71c31e942">ip2_pol_b</a>.size();</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>  assert(policy_d_model == weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a6708295c625a521a7b574d5c686ef902">ip3_pol_b</a>.size());</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span> </div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>  <span class="keywordtype">size_t</span> encoder_d_model = 0;</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>  <span class="keywordtype">size_t</span> encoder_dff = 0;</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span> </div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>  <span class="keywordflow">if</span> (weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a989114dff69e54ef3ade4e826b10050e">pol_encoder</a>.size() &gt; 0) {</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>    encoder_d_model = weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a989114dff69e54ef3ade4e826b10050e">pol_encoder</a>[0].mha.q_b.size();</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>    encoder_dff = weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a989114dff69e54ef3ade4e826b10050e">pol_encoder</a>[0].ffn.dense1_b.size();</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span> </div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>    assert(encoder_d_model == weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a989114dff69e54ef3ade4e826b10050e">pol_encoder</a>[0].mha.k_b.size());</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>    assert(encoder_d_model == weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a989114dff69e54ef3ade4e826b10050e">pol_encoder</a>[0].mha.v_b.size());</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>    assert(embedding_op_size == weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a989114dff69e54ef3ade4e826b10050e">pol_encoder</a>[0].ffn.dense2_b.size());</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>  }</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span> </div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> encoder_heads = weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#af4967d303488d7d3c623f9db707e5281">pol_encoder_head_count</a>;</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span> </div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>  <span class="keywordtype">size_t</span> size =</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>      N * 64 *</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>      std::max(std::max(embedding_op_size, encoder_dff), policy_d_model);</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span> </div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>  <span class="comment">// size of matmul_qk matrix = encoder_heads_ * Batch * 64 * 64</span></div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> matmul_qk_size = encoder_heads * N * 64 * 64;</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> output_size = N * (64 * 64 + 8 * 24);</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>  size = std::max(size, std::max(matmul_qk_size, output_size));</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span> </div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>  <span class="keywordtype">size_t</span> qkv_size = N * 64 * encoder_d_model;</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>  <span class="comment">// We store qkv in single allocation, and other intermediate tensors are</span></div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>  <span class="comment">// sometimes stored by splitting an allocation into two halves.</span></div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>  size = std::max(2 * size, 3 * qkv_size);</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>  <span class="keywordflow">return</span> size;</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>}</div>
</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span> </div>
<div class="foldopen" id="foldopen00098" data-start="{" data-end="}">
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno"><a class="line" href="namespacelczero.html#af3c3d8d9760200f64a76d8e13de19e9f">   98</a></span><span class="keyword">static</span> <span class="keywordtype">size_t</span> <a class="code hl_function" href="namespacelczero.html#af3c3d8d9760200f64a76d8e13de19e9f">getMaxAttentionBodySize</a>(<span class="keyword">const</span> <a class="code hl_struct" href="structlczero_1_1MultiHeadWeights.html">MultiHeadWeights</a>&amp; weights, <span class="keywordtype">int</span> N) {</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> embedding_op_size = weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#afd8cd75e63fb1aedd507537dd8cc0318">ip_emb_b</a>.size();</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span> </div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>  <span class="keywordtype">size_t</span> encoder_d_model = 0;</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>  <span class="keywordtype">size_t</span> encoder_dff = 0;</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span> </div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>  <span class="keywordflow">if</span> (weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">encoder</a>.size() &gt; 0) {</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>    encoder_d_model = weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">encoder</a>[0].mha.q_b.size();</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>    encoder_dff = weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">encoder</a>[0].ffn.dense1_b.size();</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span> </div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>    assert(encoder_d_model == weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">encoder</a>[0].mha.k_b.size());</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>    assert(encoder_d_model == weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">encoder</a>[0].mha.v_b.size());</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>    assert(embedding_op_size == weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">encoder</a>[0].ffn.dense2_b.size());</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>  }</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span> </div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> encoder_heads = weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a9582fabaa777e21eba5346b865646913">encoder_head_count</a>;</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span> </div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>  <span class="keywordtype">size_t</span> size =</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>      N * 64 *</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>      std::max(std::max(embedding_op_size, encoder_dff), encoder_d_model);</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span> </div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>  <span class="comment">// size of matmul_qk matrix = encoder_heads_ * Batch * 64 * 64</span></div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> matmul_qk_size = encoder_heads * N * 64 * 64;</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> output_size = N * (64 * 64 + 8 * 24);</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>  size = std::max(size, std::max(matmul_qk_size, output_size));</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span> </div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>  <span class="keywordtype">size_t</span> qkv_size = N * 64 * encoder_d_model;</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>  <span class="comment">// We store qkv in single allocation, and other intermediate tensors are</span></div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>  <span class="comment">// sometimes stored by splitting an allocation into two halves.</span></div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>  size = std::max(2 * size, 3 * qkv_size);</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>  <span class="keywordflow">return</span> size;</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>}</div>
</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span> </div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="foldopen" id="foldopen00134" data-start="{" data-end="};">
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html">  134</a></span><span class="keyword">class </span><a class="code hl_class" href="classlczero_1_1CudaNetworkComputation.html">CudaNetworkComputation</a> : <span class="keyword">public</span> <a class="code hl_class" href="classlczero_1_1NetworkComputation.html">NetworkComputation</a> {</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span> <span class="keyword">public</span>:</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>  <a class="code hl_class" href="classlczero_1_1CudaNetworkComputation.html">CudaNetworkComputation</a>(<a class="code hl_class" href="classlczero_1_1CudaNetwork.html">CudaNetwork&lt;DataType&gt;</a>* network, <span class="keywordtype">bool</span> wdl,</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>                         <span class="keywordtype">bool</span> moves_left);</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>  <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#ae90593942136474f6b3e73520e9e5097">~CudaNetworkComputation</a>();</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span> </div>
<div class="foldopen" id="foldopen00146" data-start="{" data-end="}">
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#aa6c57c4e2e5cc50053e86eb2b6297d47">  146</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#aa6c57c4e2e5cc50053e86eb2b6297d47">AddInput</a>(<a class="code hl_typedef" href="namespacelczero.html#a1110b86a736271d5d1669bee1adf0065">InputPlanes</a>&amp;&amp; <a class="code hl_variable" href="WinogradCommon_8h.html#aba9cd67e67fe1d1e46c1f273b3e68d67">input</a>)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>    <span class="keyword">const</span> <span class="keyword">auto</span> iter_mask =</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>        &amp;<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;input_masks_mem_[<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">batch_size_</a> * <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a>];</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>    <span class="keyword">const</span> <span class="keyword">auto</span> iter_val =</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>        &amp;<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;input_val_mem_[<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">batch_size_</a> * <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a>];</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span> </div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>    assert(<a class="code hl_variable" href="WinogradCommon_8h.html#aba9cd67e67fe1d1e46c1f273b3e68d67">input</a>.size() == <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a>);</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a>; i++) {</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>      <span class="keyword">const</span> <span class="keyword">auto</span>&amp; plane = <a class="code hl_variable" href="WinogradCommon_8h.html#aba9cd67e67fe1d1e46c1f273b3e68d67">input</a>[i];</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>      iter_mask[i] = plane.mask;</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>      <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#abe98729db620e6ebf04d17937ef638b6">ToType</a>(iter_val[i], plane.value);</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>    }</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span> </div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">batch_size_</a>++;</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>  }</div>
</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span> </div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a2c13d328c17e7f3a5ba6d488b800a6e4">ComputeBlocking</a>() <span class="keyword">override</span>;</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span> </div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#abef905f0b31b30dbe835e13a23a3c166">CaptureGraph</a>(std::unique_lock&lt;std::mutex&gt;&amp;&amp; lock = {});</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span> </div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a11d0d6c9bde122187f4404aec3bb36da">  172</a></span>  <span class="keywordtype">int</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a11d0d6c9bde122187f4404aec3bb36da">GetBatchSize</a>()<span class="keyword"> const override </span>{ <span class="keywordflow">return</span> <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">batch_size_</a>; }</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span> </div>
<div class="foldopen" id="foldopen00174" data-start="{" data-end="}">
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a782841c1c8dbe70b647bb56d1a3bcdd5">  174</a></span>  <span class="keywordtype">float</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a782841c1c8dbe70b647bb56d1a3bcdd5">GetQVal</a>(<span class="keywordtype">int</span> sample)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#abf8d449b0777209bffcaabdef15b578f">wdl_</a>) {</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>      <span class="keyword">const</span> <span class="keywordtype">float</span>* wdl =</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>          <span class="keyword">sizeof</span>(<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;op_value_mem_[0]) == <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>)</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>              ? (<span class="keywordtype">float</span>*)<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;op_value_mem_</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>              : <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;wdl_cpu_softmax_.get();</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>      <span class="keywordflow">return</span> wdl[2 * sample];</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>    }</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#a2d28b2933cc4dbdac8714d9f28861a19">FromType</a>(<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;op_value_mem_[sample]);</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>  }</div>
</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span> </div>
<div class="foldopen" id="foldopen00185" data-start="{" data-end="}">
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a68be8566dc1d5baec280adfd456e6a1d">  185</a></span>  <span class="keywordtype">float</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a68be8566dc1d5baec280adfd456e6a1d">GetDVal</a>(<span class="keywordtype">int</span> sample)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#abf8d449b0777209bffcaabdef15b578f">wdl_</a>) {</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>      <span class="keyword">const</span> <span class="keywordtype">float</span>* wdl =</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>          <span class="keyword">sizeof</span>(<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;op_value_mem_[0]) == <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>)</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>              ? (<span class="keywordtype">float</span>*)<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;op_value_mem_</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>              : <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;wdl_cpu_softmax_.get();</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>      <span class="keywordflow">return</span> wdl[2 * sample + 1];</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>    }</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>    <span class="keywordflow">return</span> 0.0f;</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>  }</div>
</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span> </div>
<div class="foldopen" id="foldopen00196" data-start="{" data-end="}">
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a75f70f6420e41e170a7e0ba5acfc2ed7">  196</a></span>  <span class="keywordtype">float</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a75f70f6420e41e170a7e0ba5acfc2ed7">GetPVal</a>(<span class="keywordtype">int</span> sample, <span class="keywordtype">int</span> move_id)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#a2d28b2933cc4dbdac8714d9f28861a19">FromType</a>(</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>        <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;op_policy_mem_[sample * <a class="code hl_variable" href="namespacelczero_1_1cudnn__backend.html#a3298666071469a49009d91a8ac5f9c7b">kNumOutputPolicy</a> + move_id]);</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>  }</div>
</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span> </div>
<div class="foldopen" id="foldopen00201" data-start="{" data-end="}">
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a4aa08aa611773a1fe38b28cf6916ecb4">  201</a></span>  <span class="keywordtype">float</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a4aa08aa611773a1fe38b28cf6916ecb4">GetMVal</a>(<span class="keywordtype">int</span> sample)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#aa9628aa93257e176db31704c79eb2b4a">moves_left_</a>) {</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>      <span class="keywordflow">return</span> <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#a2d28b2933cc4dbdac8714d9f28861a19">FromType</a>(<a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>-&gt;op_moves_left_mem_[sample]);</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>    }</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>    <span class="keywordflow">return</span> 0.0f;</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>  }</div>
</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span> </div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span> <span class="keyword">private</span>:</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>  <span class="comment">// Memory holding inputs, outputs.</span></div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">  210</a></span>  std::unique_ptr&lt;InputsOutputs&lt;DataType&gt;&gt; <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a>;</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">  211</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">batch_size_</a>;</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#abf8d449b0777209bffcaabdef15b578f">  212</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#abf8d449b0777209bffcaabdef15b578f">wdl_</a>;</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#aa9628aa93257e176db31704c79eb2b4a">  213</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#aa9628aa93257e176db31704c79eb2b4a">moves_left_</a>;</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span> </div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#ab16d8a24586379a53268bc760f6db4fe">  215</a></span>  <a class="code hl_class" href="classlczero_1_1CudaNetwork.html">CudaNetwork&lt;DataType&gt;</a>* <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ab16d8a24586379a53268bc760f6db4fe">network_</a>;</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>};</div>
</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span> </div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="foldopen" id="foldopen00221" data-start="{" data-end="};">
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html">  221</a></span><span class="keyword">class </span><a class="code hl_class" href="classlczero_1_1CudaNetwork.html">CudaNetwork</a> : <span class="keyword">public</span> <a class="code hl_class" href="classlczero_1_1Network.html">Network</a> {</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span> <span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00223" data-start="{" data-end="}">
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a019e15da7d32a5cab87befc6fd040b53">  223</a></span>  <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a019e15da7d32a5cab87befc6fd040b53">CudaNetwork</a>(<span class="keyword">const</span> <a class="code hl_typedef" href="namespacelczero.html#a6705e82c4f5d6edcac8d0ca3b2240b29">WeightsFile</a>&amp; file, <span class="keyword">const</span> <a class="code hl_class" href="classlczero_1_1OptionsDict.html">OptionsDict</a>&amp; options)</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>      : <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8569c32a2f7f878f57f2a232b097dac8">capabilities_</a>{file.format().network_format().<a class="code hl_variable" href="WinogradCommon_8h.html#aba9cd67e67fe1d1e46c1f273b3e68d67">input</a>(),</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>                      file.format().network_format().<a class="code hl_variable" href="WinogradCommon_8h.html#acdb1009d58a21974bf65d60a5ef9929e">output</a>(),</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>                      file.format().network_format().moves_left()} {</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>    <a class="code hl_struct" href="structlczero_1_1MultiHeadWeights.html">MultiHeadWeights</a> weights(file.weights());</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a> = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;gpu&quot;</span>, 0);</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a01699a1f6860cda41dfee54217b1862c">enable_graph_capture_</a> = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;graph_capture&quot;</span>, <span class="keyword">true</span>);</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span> </div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>    <span class="keyword">const</span> <span class="keyword">auto</span> nf = file.format().network_format();</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>    <span class="keyword">using </span>NF = pblczero::NetworkFormat;</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1b16fc6e42242f982303703bbfa55340">conv_policy_</a> = nf.policy() == NF::POLICY_CONVOLUTION;</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae017cf365d571ddb91a223a3e7c48a0f">attn_policy_</a> = nf.policy() == NF::POLICY_ATTENTION;</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a> = nf.network() == NF::NETWORK_ATTENTIONBODY_WITH_HEADFORMAT ||</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>                 nf.network() == NF::NETWORK_ATTENTIONBODY_WITH_MULTIHEADFORMAT;</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span> </div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a> = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;max_batch&quot;</span>, 1024);</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>    <span class="comment">// min_batch_size_ is chosen as 4 as it is common that for sizes less than</span></div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>    <span class="comment">// 4 that there is no performance gain, but there is variance in the</span></div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>    <span class="comment">// outputs, which means that there is extra non-determinism in some</span></div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>    <span class="comment">// scenarios, including using the multiplexing backend.</span></div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a240b95efc1b5559d4ff8c5ce6faaad5c">min_batch_size_</a> =</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>        options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;min_batch&quot;</span>, std::min(4, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>));</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a> &lt; <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a240b95efc1b5559d4ff8c5ce6faaad5c">min_batch_size_</a>)</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Max batch must not be less than min_batch setting.&quot;</span>);</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span> </div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>    <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ae4d5a550345de6b79b516b740871649f">showInfo</a>();</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span> </div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span><span class="preprocessor">#ifdef USE_CUTLASS</span></div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;Compiled with CUTLASS enabled&quot;</span>;</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span> </div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>    <span class="keywordtype">int</span> total_gpus;</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaGetDeviceCount(&amp;total_gpus));</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span> </div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a> &gt;= total_gpus)</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Invalid GPU Id: &quot;</span> + std::to_string(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>));</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span> </div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>    cudaDeviceProp deviceProp = {};</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>    cudaGetDeviceProperties(&amp;deviceProp, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>);</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>    <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#af647744ff0e16fa1875f0b2e9504c8f8">showDeviceInfo</a>(deviceProp, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>);</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span> </div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7203422407bcef3715a4b9fd9836e515">l2_cache_size_</a> = deviceProp.l2CacheSize;</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad2c0d5066570e1aa1b97873cf5da9bea">sm_count_</a> = deviceProp.multiProcessorCount;</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span> </div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae27e343d2c18e3ecd492101c33d24239">allow_cache_opt_</a> = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;cache_opt&quot;</span>, <span class="keyword">false</span>);</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span> </div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>    <span class="comment">// Select GPU to run on (for *the current* thread).</span></div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaSetDevice(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>));</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span> </div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a> = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;multi_stream&quot;</span>, <span class="keyword">false</span>);</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span> </div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>    <span class="comment">// layout used by cuda backend is nchw.</span></div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a20d84b728c194b4708c6de9fb82445b1">has_tensor_cores_</a> = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>    <span class="keyword">constexpr</span> <span class="keywordtype">bool</span> fp16 = std::is_same&lt;half, DataType&gt;::value;</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span> </div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>    <span class="keywordflow">if</span> (fp16) {</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>      <span class="comment">// Check if the GPU support FP16.</span></div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span> </div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>      <span class="keywordflow">if</span> ((deviceProp.major == 6 &amp;&amp; deviceProp.minor != 1) ||</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>          (deviceProp.major == 5 &amp;&amp; deviceProp.minor == 3)) {</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>        <span class="comment">// FP16 without tensor cores supported on GP100 (SM 6.0) and Jetson</span></div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>        <span class="comment">// (SM 5.3 and 6.2). SM 6.1 GPUs also have FP16, but slower than FP32.</span></div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>        ;</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>      } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (deviceProp.major &gt;= 7) {</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>        <span class="comment">// Some GPUs (GTX 16xx) are SM 7.5 but don&#39;t have tensor cores</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>        <span class="comment">// enabling TENSOR_OP_MATH for them works but is very very slow</span></div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>        <span class="comment">// (likely because the system emulates it).</span></div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>        <span class="keywordflow">if</span> (!strstr(deviceProp.name, <span class="stringliteral">&quot;GTX 16&quot;</span>)) {</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a20d84b728c194b4708c6de9fb82445b1">has_tensor_cores_</a> = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>        }</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>      } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>        <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Your GPU doesn&#39;t support FP16&quot;</span>);</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>      }</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>    }</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span> </div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>          cudaStreamCreateWithFlags(&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>, cudaStreamNonBlocking));</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>          cudaStreamCreateWithFlags(&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a>, cudaStreamNonBlocking));</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>          cudaStreamCreateWithFlags(&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900">download_stream_</a>, cudaStreamNonBlocking));</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventCreateWithFlags(&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6">compute_ordering_event_</a>,</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>                                                cudaEventDisableTiming));</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>      <a class="code hl_define" href="cuda__common_8h.html#a7df6734b37d817be68002a816e49a5d1">ReportCUBLASErrors</a>(cublasCreate(&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">cublas_</a>));</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>      <a class="code hl_define" href="cuda__common_8h.html#a7df6734b37d817be68002a816e49a5d1">ReportCUBLASErrors</a>(cublasSetStream(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">cublas_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>));</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>      <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a20d84b728c194b4708c6de9fb82445b1">has_tensor_cores_</a>)</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>        <a class="code hl_define" href="cuda__common_8h.html#a7df6734b37d817be68002a816e49a5d1">ReportCUBLASErrors</a>(cublasSetMathMode(</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>            <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">cublas_</a>,</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>            CUBLAS_TENSOR_OP_MATH));  <span class="comment">// Deprecated on CUDA 11.0 and later</span></div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>      <span class="keywordflow">else</span> <span class="keywordflow">if</span> (fp16)</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>        <a class="code hl_define" href="cuda__common_8h.html#a7df6734b37d817be68002a816e49a5d1">ReportCUBLASErrors</a>(cublasSetMathMode(</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>            <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">cublas_</a>,</div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>            <a class="code hl_define" href="cuda__common_8h.html#a5df7402b2cc2025fcde387e576d19e1c">CUBLAS_PEDANTIC_MATH</a>));  <span class="comment">// Explicitly set PEDANTIC_MATH mode to</span></div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>                                     <span class="comment">// avoid cublas bug of making use of tensor</span></div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>                                     <span class="comment">// core math on TU11x GPUs that don&#39;t</span></div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>                                     <span class="comment">// support it.</span></div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>    }</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span> </div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> kNumInputPlanes = <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a>;</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> kNumFilters = (int)weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a50df248b182ed963bd366a66d12bcf6d">input</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>.size();</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> = (int)weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>.size();</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ace0225a707963a917029a40ba0a96ece">numFilters_</a> = kNumFilters;</div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span> </div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acdd66225ad7c652e33a47accfdc411e8">num_encoder_blocks_</a> = (int)weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">encoder</a>.size();</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>) {</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>      assert(weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#afd8cd75e63fb1aedd507537dd8cc0318">ip_emb_b</a>.size() &gt; 0);</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>    }</div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span> </div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span>    <span class="comment">// Warn if the memory required for storing transformed weights is</span></div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>    <span class="comment">// going to exceed 40% of total video memory, force custom_winograd off</span></div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>    <span class="comment">// if it&#39;s going to exceed 50% of memory.</span></div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span>    <span class="keywordtype">size_t</span> residual_single_layer_weight_size =</div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>        3 * 3 * kNumFilters * kNumFilters * <span class="keyword">sizeof</span>(DataType);</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>    <span class="keywordtype">size_t</span> residual_weight_size =</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>        residual_single_layer_weight_size * <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> * 2;</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>    <span class="keywordtype">size_t</span> transformed_residual_weight_size = residual_weight_size * 4;</div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span> </div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>    <span class="keywordflow">if</span> (transformed_residual_weight_size &gt; 0.4 * deviceProp.totalGlobalMem) {</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>      <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;WARNING: Low GPU video memory. You may run into OOM errors. Try &quot;</span></div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>              <span class="stringliteral">&quot;using a smaller network.&quot;</span>;</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>    }</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span> </div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>    <span class="comment">// Disable res block fusing for fp32 for now (not worth it)</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>    <span class="comment">// TODO: make it work for filters not a multiple of 32.</span></div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>    <span class="comment">// Note that when used with SE, the optimization</span></div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>    <span class="comment">// works only when filter count is &lt;= 384 (pre-Ampere), or less than 512</span></div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>    <span class="comment">// (Ampere)</span></div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>    <span class="comment">// It turns dynamically off based on filter count (see</span></div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>    <span class="comment">// ResidualBlock&lt;DataType&gt;::Eval)</span></div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>    <span class="keywordflow">if</span> (kNumFilters % 32 == 0 &amp;&amp; std::is_same&lt;half, DataType&gt;::value) {</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a> = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a> = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>    }</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>    <span class="comment">// Override if set in backend-opts.</span></div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>    <span class="keywordflow">if</span> (options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a7a5cef61f5c4aa5cba99b314e0ba05ac">Exists</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;res_block_fusing&quot;</span>)) {</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a> = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1e48aa5d30fccb31803845d8cde4047d">Get</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;res_block_fusing&quot;</span>);</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>    }</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span> </div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>    <span class="keywordtype">bool</span> use_fused_mha = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>    <span class="keywordflow">if</span> (deviceProp.major &gt;= 8 &amp;&amp; fp16) {</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>      use_fused_mha = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;fused_mha&quot;</span>, <span class="keyword">true</span>);</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>    }</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span> </div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>    <span class="keyword">const</span> <span class="keywordtype">bool</span> use_gemm_ex = deviceProp.major &gt;= 5;</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span> </div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>    <span class="comment">// 0. Check for SE.</span></div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a09ba6230578a4bb53a0acd260c3eb515">has_se_</a> = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> &amp;&amp; weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[0].has_se) {</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a09ba6230578a4bb53a0acd260c3eb515">has_se_</a> = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>    }</div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span> </div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>    <span class="comment">// Have some minumum as we also use this for transforming weights.</span></div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>    <span class="keywordtype">size_t</span> max_weight_size = 128 * 1024 * 1024;</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span> </div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>    <span class="comment">// parts from scratch allocation are suballocated to hold various weights</span></div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>    <span class="comment">// and biases when transforming winograd weights (one layer at a time), 128</span></div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>    <span class="comment">// MB is way more than that what we need but make sure it&#39;s at least 3x of</span></div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>    <span class="comment">// single layer&#39;s weight size to be safe.</span></div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>    <span class="keywordflow">if</span> (max_weight_size &lt; 3 * residual_single_layer_weight_size)</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>      max_weight_size = 3 * residual_single_layer_weight_size;</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span> </div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a> = max_weight_size;</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span> </div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>    <span class="comment">// Need additional space for transformed input/outputs which are 36/16</span></div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>    <span class="comment">// times size (4x4 block transformed into 6x6).</span></div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> &gt; 0) {</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>      <span class="keyword">const</span> <span class="keywordtype">size_t</span> transformed_tensor_size =</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>          (size_t)(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a> * kNumFilters * 64 * (36.0 / 16.0) *</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>                   <span class="keyword">sizeof</span>(DataType));</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a> = std::max(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, 2 * transformed_tensor_size);</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>    }</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span> </div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>    std::string policy_head =</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>        options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;std::string&gt;(<span class="stringliteral">&quot;policy_head&quot;</span>, <span class="stringliteral">&quot;vanilla&quot;</span>);</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>    <span class="comment">// Check that selected policy head exists.</span></div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>    <span class="keywordflow">if</span> (!weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights.html#a70de487aab76d3bd5cd544c2355d5d15">policy_heads</a>.contains(policy_head)) {</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;The policy head you specified &#39;&quot;</span> + policy_head +</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>                      <span class="stringliteral">&quot;&#39; does not exist in this net.&quot;</span>);</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>    }</div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>    std::string value_head =</div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>        options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;std::string&gt;(<span class="stringliteral">&quot;value_head&quot;</span>, <span class="stringliteral">&quot;winner&quot;</span>);</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>    <span class="comment">// Check that selected value head exists.</span></div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>    <span class="keywordflow">if</span> (!weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights.html#a48356a0287e65c36497e0bb0f70283e0">value_heads</a>.contains(value_head)) {</div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;The value head you specified &#39;&quot;</span> + value_head +</div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span>                      <span class="stringliteral">&quot;&#39; does not exist in this net.&quot;</span>);</div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>    }</div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span> </div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>    <span class="comment">// Attention policy head or body may need more memory</span></div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> attentionPolicySize =</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>        <a class="code hl_function" href="namespacelczero.html#a240fb199a13e5acdecb5207efc7becde">getMaxAttentionHeadSize</a>(weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights.html#a70de487aab76d3bd5cd544c2355d5d15">policy_heads</a>.at(policy_head),</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>                                <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>) *</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>        <span class="keyword">sizeof</span>(DataType);</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span> </div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> attentionBodySize =</div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>        <a class="code hl_function" href="namespacelczero.html#af3c3d8d9760200f64a76d8e13de19e9f">getMaxAttentionBodySize</a>(weights, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>) * <span class="keyword">sizeof</span>(DataType);</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a> = std::max(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>,</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>                             std::max(attentionPolicySize, attentionBodySize));</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span> </div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaMalloc(&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>));</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span> </div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>    <span class="keyword">const</span> <span class="keywordtype">bool</span> mish_net = file.format().network_format().default_activation() ==</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>                          pblczero::NetworkFormat::DEFAULT_ACTIVATION_MISH;</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span> </div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>    <a class="code hl_enumeration" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deb">ActivationFunction</a> act = mish_net ? <a class="code hl_enumvalue" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deba6d1459a7bd32ebd9560eac8dd0935406">ACTIVATION_MISH</a> : <a class="code hl_enumvalue" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deba26efbe0bfd6bc4ec3eb8a7ead18e599b">ACTIVATION_RELU</a>;</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span> </div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>    <span class="comment">// 2. Build the network, and copy the weights to GPU memory.</span></div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span> </div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>    <span class="comment">// Input conv only used if there are residual blocks in the network</span></div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> &gt; 0) {</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>      <span class="comment">// Input.</span></div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>      {</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>        <span class="keyword">auto</span> inputConv = std::make_unique&lt;FusedWinogradConvSELayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>            <span class="keyword">nullptr</span>, kNumFilters, 8, 8, kNumInputPlanes, act, <span class="keyword">true</span>, <span class="keyword">false</span>,</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>            <span class="keyword">false</span>, 0, use_gemm_ex, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a>);</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>        inputConv-&gt;LoadWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a50df248b182ed963bd366a66d12bcf6d">input</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#a062401a39d4b2600851563d3dbde5c22">weights</a>[0],</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>                               &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a50df248b182ed963bd366a66d12bcf6d">input</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>[0], <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>        <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(inputConv));</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>      }</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span> </div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>      <span class="comment">// Residual block.</span></div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> block = 0; block &lt; <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a>; block++) {</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>        <span class="keywordtype">bool</span> has_se = weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].has_se;</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>        <span class="keywordtype">int</span> se_k = (int)weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.b1.size();</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span> </div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>        <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a>) {</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>          <span class="keyword">auto</span> layer = std::make_unique&lt;ResidualBlock&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>              <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), kNumFilters, has_se, se_k, use_gemm_ex,</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>              block == 0, block == (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> - 1), act,</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>              deviceProp.sharedMemPerBlockOptin);</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>          layer-&gt;LoadWeights0(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv1.weights[0],</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>                              &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv1.biases[0],</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>                              <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>          layer-&gt;LoadWeights1(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv2.weights[0],</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>                              &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv2.biases[0],</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>                              <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>          <span class="keywordflow">if</span> (has_se)</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>            layer-&gt;LoadSEWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.w1[0],</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>                                 &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.b1[0],</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>                                 &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.w2[0],</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>                                 &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.b2[0],</div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>                                 <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(layer));</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>          <span class="keyword">auto</span> conv1 = std::make_unique&lt;FusedWinogradConvSELayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span>              <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), kNumFilters, 8, 8, kNumFilters, act, <span class="keyword">true</span>, <span class="keyword">false</span>,</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>              <span class="keyword">false</span>, 0, use_gemm_ex);</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>          conv1-&gt;LoadWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv1.weights[0],</div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span>                             &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv1.biases[0],</div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>                             <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(conv1));</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span> </div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>          <span class="keyword">auto</span> conv2 = std::make_unique&lt;FusedWinogradConvSELayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>              <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), kNumFilters, 8, 8, kNumFilters, act, <span class="keyword">true</span>, <span class="keyword">true</span>,</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>              has_se, se_k, use_gemm_ex);</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>          conv2-&gt;LoadWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv2.weights[0],</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>                             &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].conv2.biases[0],</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>                             <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>          <span class="keywordflow">if</span> (has_se)</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>            conv2-&gt;LoadSEWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.w1[0],</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>                                 &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.b1[0],</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>                                 &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.w2[0],</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>                                 &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">residual</a>[block].se.b2[0],</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>                                 <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(conv2));</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>        }</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>      }</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9">resi_last_</a> = <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>();</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>    }</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span> </div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>) {</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>      <a class="code hl_struct" href="structlczero_1_1Activations.html">Activations</a> activations;</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span>      <span class="keyword">const</span> <span class="keyword">auto</span> smolgen_activation =</div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>          file.format().network_format().<a class="code hl_variable" href="structlczero_1_1Activations.html#a61bc2215e0e54dee6ce148dfa3194c89">smolgen_activation</a>();</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>      activations.<a class="code hl_variable" href="structlczero_1_1Activations.html#a61bc2215e0e54dee6ce148dfa3194c89">smolgen_activation</a> =</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>          smolgen_activation == pblczero::NetworkFormat::ACTIVATION_DEFAULT</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>              ? act</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>              : <span class="keyword">static_cast&lt;</span><a class="code hl_enumeration" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deb">ActivationFunction</a><span class="keyword">&gt;</span>(smolgen_activation);</div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>      <span class="keyword">const</span> <span class="keyword">auto</span> ffn_activation =</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>          file.format().network_format().ffn_activation();</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>      activations.<a class="code hl_variable" href="structlczero_1_1Activations.html#af742824fa3de24a9ed53aaeb108f4743">ffn_activation</a> =</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>          ffn_activation == pblczero::NetworkFormat::ACTIVATION_DEFAULT</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>              ? act</div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>              : <span class="keyword">static_cast&lt;</span><a class="code hl_enumeration" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deb">ActivationFunction</a><span class="keyword">&gt;</span>(ffn_activation);</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>      activations.<a class="code hl_variable" href="structlczero_1_1Activations.html#acedf50afa85656c44557297ae292b2fe">default_activation</a> = act;</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span> </div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>      <span class="keyword">auto</span> attention_body = std::make_unique&lt;AttentionBody&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>          weights, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>, activations, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a>,</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> &gt; 0 ? kNumFilters : <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>,</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>          <span class="keyword">static_cast&lt;</span><a class="code hl_enumeration" href="namespacelczero.html#a6859c8ceb3dbdef33a21752d16b40311">InputEmbedding</a><span class="keyword">&gt;</span>(</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>              file.format().network_format().input_embedding()) ==</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>              <a class="code hl_enumvalue" href="namespacelczero.html#a6859c8ceb3dbdef33a21752d16b40311a450d6145004b0b7a54288b65401b9c91">InputEmbedding::INPUT_EMBEDDING_PE_DENSE</a>,</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>          use_gemm_ex, use_fused_mha);</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(attention_body));</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span> </div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a07e2823f1a2f64f1fc684e1ec5859ae9">encoder_last_</a> = <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>();</div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>    }</div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span> </div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>    <span class="comment">// Policy head.</span></div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>    {</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>      <a class="code hl_struct" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html">MultiHeadWeights::PolicyHead</a>&amp; head = weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights.html#a70de487aab76d3bd5cd544c2355d5d15">policy_heads</a>.at(policy_head);</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>      <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae017cf365d571ddb91a223a3e7c48a0f">attn_policy_</a>) {</div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>        <span class="keyword">auto</span> AttentionPolicy = std::make_unique&lt;AttentionPolicyHead&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>            <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), head, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>, act,</div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>            <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>, use_gemm_ex);</div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>        <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(AttentionPolicy));</div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span> </div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>        <span class="keyword">auto</span> policymap = std::make_unique&lt;PolicyMapLayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span>            <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), <a class="code hl_variable" href="namespacelczero_1_1cudnn__backend.html#a3298666071469a49009d91a8ac5f9c7b">kNumOutputPolicy</a>, 1, 1, 64 * 64 + 8 * 24, <span class="keyword">true</span>);</div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>        policymap-&gt;LoadWeights(<a class="code hl_variable" href="namespacelczero.html#a27f519ff52a925ebea6591f5c0b1fd75">kAttnPolicyMap</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>        <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(policymap));</div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span> </div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span>      } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span>        <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1b16fc6e42242f982303703bbfa55340">conv_policy_</a>) {</div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>          assert(!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>);  <span class="comment">// not supported with attention body</span></div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>          <span class="keyword">auto</span> conv1 = std::make_unique&lt;FusedWinogradConvSELayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span>              <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9">resi_last_</a>, kNumFilters, 8, 8, kNumFilters, act, <span class="keyword">true</span>, <span class="keyword">false</span>,</div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>              <span class="keyword">false</span>, 0, use_gemm_ex);</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span>          conv1-&gt;LoadWeights(&amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#abf72641a1aa339a3fcfbb090e8f15069">policy1</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#a062401a39d4b2600851563d3dbde5c22">weights</a>[0], &amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#abf72641a1aa339a3fcfbb090e8f15069">policy1</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>[0],</div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>                             <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(conv1));</div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span> </div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span>          <span class="keyword">auto</span> pol_channels = head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a66881320029e901b5440098017bebd40">policy</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>.size();</div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span> </div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span>          <span class="comment">// No relu</span></div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span>          <span class="keyword">auto</span> conv2 = std::make_unique&lt;FusedWinogradConvSELayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span>              <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), pol_channels, 8, 8, kNumFilters, <a class="code hl_enumvalue" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5debabf0ab8acc3bbb5028fde6be432108a42">ACTIVATION_NONE</a>,</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span>              <span class="keyword">true</span>, <span class="keyword">false</span>, <span class="keyword">false</span>, 0, use_gemm_ex);</div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>          conv2-&gt;LoadWeights(&amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a66881320029e901b5440098017bebd40">policy</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#a062401a39d4b2600851563d3dbde5c22">weights</a>[0], &amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a66881320029e901b5440098017bebd40">policy</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>[0],</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>                             <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(conv2));</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span> </div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>          <span class="keyword">auto</span> policymap = std::make_unique&lt;PolicyMapLayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>              <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), <a class="code hl_variable" href="namespacelczero_1_1cudnn__backend.html#a3298666071469a49009d91a8ac5f9c7b">kNumOutputPolicy</a>, 1, 1, 73 * 8 * 8, <span class="keyword">false</span>);</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>          policymap-&gt;LoadWeights(<a class="code hl_variable" href="namespacelczero.html#a2c97d5e3f3602f9ec8b13fe7b2357f45">kConvPolicyMap</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span> </div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(policymap));</div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span>          assert(!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>);  <span class="comment">// not supported with attention body</span></div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span>          <span class="keyword">auto</span> convPol = std::make_unique&lt;Conv1Layer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>              <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9">resi_last_</a>, head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a66881320029e901b5440098017bebd40">policy</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>.size(), 8, 8, kNumFilters, act,</div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>              <span class="keyword">true</span>, use_gemm_ex);</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span>          convPol-&gt;LoadWeights(&amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a66881320029e901b5440098017bebd40">policy</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#a062401a39d4b2600851563d3dbde5c22">weights</a>[0], &amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a66881320029e901b5440098017bebd40">policy</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>[0],</div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>                               <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(convPol));</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span> </div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span>          <span class="keyword">auto</span> FCPol = std::make_unique&lt;FCLayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span>              <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#afa3328e192dbca1c42f672b922c58c07">ip_pol_b</a>.size(), 1, 1, <span class="keyword">true</span>,</div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span>              <a class="code hl_enumvalue" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5debabf0ab8acc3bbb5028fde6be432108a42">ACTIVATION_NONE</a>);</div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span>          FCPol-&gt;LoadWeights(&amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a4ad6b4f6a45370d2b027e485810f6664">ip_pol_w</a>[0], &amp;head.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#afa3328e192dbca1c42f672b922c58c07">ip_pol_b</a>[0],</div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span>                             <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(FCPol));</div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span>        }</div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span>      }</div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span>    }</div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span> </div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span>    <span class="comment">// Value heads.</span></div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span>    {</div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span>      <span class="keyword">const</span> <a class="code hl_struct" href="structlczero_1_1MultiHeadWeights_1_1ValueHead.html">MultiHeadWeights::ValueHead</a>&amp; head =</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span>          weights.<a class="code hl_variable" href="structlczero_1_1MultiHeadWeights.html#a48356a0287e65c36497e0bb0f70283e0">value_heads</a>.at(value_head);</div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a> = file.format().network_format().value() ==</div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span>             pblczero::NetworkFormat::VALUE_WDL;</div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span>      <a class="code hl_class" href="classlczero_1_1cudnn__backend_1_1BaseLayer.html">BaseLayer&lt;DataType&gt;</a>* lastlayer = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a> ? <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a07e2823f1a2f64f1fc684e1ec5859ae9">encoder_last_</a> : <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9">resi_last_</a>;</div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span>      <span class="keyword">auto</span> value_main = std::make_unique&lt;ValueHead&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span>          lastlayer, head, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a>, act, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>,</div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span>          use_gemm_ex);</div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(value_main));</div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span>    }</div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span> </div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>    <span class="comment">// Moves left head</span></div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a> = (file.format().network_format().moves_left() ==</div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span>                   pblczero::NetworkFormat::MOVES_LEFT_V1) &amp;&amp;</div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span>                  options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;mlh&quot;</span>, <span class="keyword">true</span>);</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a>) {</div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span>      <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>) {</div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span>        <span class="keyword">auto</span> embedded_mov = std::make_unique&lt;EmbeddingLayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span>            <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a07e2823f1a2f64f1fc684e1ec5859ae9">encoder_last_</a>, weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a34d8bebf0bc622ba0c2aabd0d15f1b8c">ip_mov_w</a>, weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a218ce4baa9bb56870ffd003f13644899">ip_mov_b</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>,</div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span>            act);</div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span>        <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(embedded_mov));</div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span>      } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span>        <span class="keyword">auto</span> convMov = std::make_unique&lt;Conv1Layer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span>            <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9">resi_last_</a>, weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a416c6acae612bf4d6175b91a572288ba">moves_left</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>.size(), 8, 8, kNumFilters,</div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span>            act, <span class="keyword">true</span>, use_gemm_ex);</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span>        convMov-&gt;LoadWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a416c6acae612bf4d6175b91a572288ba">moves_left</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#a062401a39d4b2600851563d3dbde5c22">weights</a>[0],</div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span>                             &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a416c6acae612bf4d6175b91a572288ba">moves_left</a>.<a class="code hl_variable" href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">biases</a>[0], <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span>        <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(convMov));</div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span>      }</div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span>      <span class="keyword">auto</span> FCMov1 = std::make_unique&lt;FCLayer&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span>          <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a24798deb8d6e2f121fca8c0ff14b6f82">ip1_mov_b</a>.size(), 1, 1, <span class="keyword">true</span>, act);</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>      FCMov1-&gt;LoadWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#af1184855e43ad9ab83b48cfb9070a1b9">ip1_mov_w</a>[0], &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#a24798deb8d6e2f121fca8c0ff14b6f82">ip1_mov_b</a>[0],</div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span>                          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(FCMov1));</div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span> </div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>      <span class="keyword">auto</span> FCMov2 = std::make_unique&lt;FCLayer&lt;DataType&gt;&gt;(<a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>(), 1, 1, 1,</div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>                                                        <span class="keyword">true</span>, <a class="code hl_enumvalue" href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deba26efbe0bfd6bc4ec3eb8a7ead18e599b">ACTIVATION_RELU</a>);</div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>      FCMov2-&gt;LoadWeights(&amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#af20434c7ec66229e04a1230a1e2a54a1">ip2_mov_w</a>[0], &amp;weights.<a class="code hl_variable" href="structlczero_1_1BaseWeights.html#aa1cebf1449bd6f7ad6dba9de31500be7">ip2_mov_b</a>[0],</div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span>                          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>);</div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.emplace_back(std::move(FCMov2));</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span>    }</div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span> </div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>    <span class="comment">// 3. Allocate GPU memory for running the network:</span></div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>    <span class="comment">//    - three buffers of max size are enough (one to hold input, second to</span></div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span>    <span class="comment">//      hold output and third to hold skip connection&#39;s input).</span></div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span> </div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span>    <span class="comment">// size of input to the network</span></div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>    <span class="keywordtype">size_t</span> maxSize = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a> * kNumInputPlanes * 64 * <span class="keyword">sizeof</span>(DataType);</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span> </div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span>    <span class="comment">// take max size of all layers</span></div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span>    <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; layer : <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>) {</div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span>      maxSize = std::max(maxSize, layer-&gt;GetOutputSize(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>));</div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span>    }</div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span> </div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span>    <span class="keywordflow">if</span> ((<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae017cf365d571ddb91a223a3e7c48a0f">attn_policy_</a> || <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a> || <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>) &amp;&amp;</div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span>        (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a> &gt; maxSize)) {</div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span>      maxSize = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>;</div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span>    }</div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span> </div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>      <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; mem : <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a5827d93e06b1e2750fff7848894bdf2e">tensor_mem_</a>) {</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span>        <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaMalloc(&amp;mem, maxSize));</div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span>        <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaMemset(mem, 0, maxSize));</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>      }</div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span>    }</div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span> </div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9145d366464720a1f82f065bed9b0b32">tensor_mem_size_</a> = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a> ? maxSize : 0;</div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span> </div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span>    <span class="comment">// pre-allocate cuda graphs for search threads</span></div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span>    <span class="keyword">auto</span> allocateCudaGraphs = [&amp;] {</div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaSetDevice(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>));</div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>      <a class="code hl_class" href="classlczero_1_1CudaNetworkComputation.html">CudaNetworkComputation&lt;DataType&gt;</a> comp(<span class="keyword">this</span>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a>);</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span>      comp.<a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#aa6c57c4e2e5cc50053e86eb2b6297d47">AddInput</a>(<a class="code hl_typedef" href="namespacelczero.html#a1110b86a736271d5d1669bee1adf0065">InputPlanes</a>{(size_t)kNumInputPlanes});</div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span>      <span class="comment">// Make sure cublas is initialized in this thread.</span></div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>      comp.<a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a2c13d328c17e7f3a5ba6d488b800a6e4">ComputeBlocking</a>();</div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a6e6f47b4107450f2a9d4b3a0831359dc">GetMiniBatchSize</a>(); i++) {</div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>        comp.<a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#aa6c57c4e2e5cc50053e86eb2b6297d47">AddInput</a>(<a class="code hl_typedef" href="namespacelczero.html#a1110b86a736271d5d1669bee1adf0065">InputPlanes</a>{(size_t)kNumInputPlanes});</div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span>        <span class="keyword">auto</span> lock = <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ab5f7f804f46016185d60917813962b11">LockEval</a>();</div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span>        comp.<a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#abef905f0b31b30dbe835e13a23a3c166">CaptureGraph</a>(std::move(lock));</div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span>      }</div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span>    };</div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span>    std::thread t2(allocateCudaGraphs);</div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span>    allocateCudaGraphs();</div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span>    t2.join();</div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span>  }</div>
</div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span> </div>
<div class="foldopen" id="foldopen00668" data-start="{" data-end="}">
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ab5f7f804f46016185d60917813962b11">  668</a></span>  std::unique_lock&lt;std::mutex&gt; <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ab5f7f804f46016185d60917813962b11">LockEval</a>() {</div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>      <span class="keywordflow">return</span> {};</div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span>      <span class="keywordflow">return</span> std::unique_lock&lt;std::mutex&gt;{<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1fe4bf7e630779253e4c7f7f7b1d0821">lock_</a>};</div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span>    }</div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span>  }</div>
</div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span> </div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a246408fa495ed9f280c1900ef2672fba">  676</a></span>  <span class="keywordtype">bool</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a246408fa495ed9f280c1900ef2672fba">GetGraphCaptureEnabled</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a01699a1f6860cda41dfee54217b1862c">enable_graph_capture_</a>; }</div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span> </div>
<div class="foldopen" id="foldopen00678" data-start="{" data-end="}">
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a52518e90e82eda0c97d5c4fa7dea7a2d">  678</a></span>  <a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1CudaGraphCapture.html">CudaGraphCapture&lt;DataType&gt;</a> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a52518e90e82eda0c97d5c4fa7dea7a2d">BeginCapture</a>(<a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">InputsOutputs&lt;DataType&gt;</a>&amp; io) {</div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span>      <span class="keywordflow">return</span> {io, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900">download_stream_</a>};</div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span>      <span class="keywordflow">return</span> {io, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900">download_stream_</a>};</div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno">  685</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span>      <span class="keywordflow">return</span> {io, io.<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aebb70855764f1d081f94c14144b5d834">upload_stream_</a>, io.<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acbcc77293f33466a563a107ba64ee66f">download_stream_</a>};</div>
<div class="line"><a id="l00687" name="l00687"></a><span class="lineno">  687</span>    }</div>
<div class="line"><a id="l00688" name="l00688"></a><span class="lineno">  688</span>  }</div>
</div>
<div class="line"><a id="l00689" name="l00689"></a><span class="lineno">  689</span> </div>
<div class="foldopen" id="foldopen00690" data-start="{" data-end="}">
<div class="line"><a id="l00690" name="l00690"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ad9bc088c3f7061fc9b4a50b9287cec94">  690</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ad9bc088c3f7061fc9b4a50b9287cec94">UploadInputs</a>(<a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">InputsOutputs&lt;DataType&gt;</a>* io, <span class="keywordtype">int</span> batchSize) {</div>
<div class="line"><a id="l00691" name="l00691"></a><span class="lineno">  691</span>    <span class="comment">// Multu-stream can capture uploads without external events.</span></div>
<div class="line"><a id="l00692" name="l00692"></a><span class="lineno">  692</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00693" name="l00693"></a><span class="lineno">  693</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span>        cudaMemcpyAsync(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a8912b9a29a368748dfb2c2a0f6ef8e81">input_masks_mem_gpu_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#ac2d5c4d887a02dd9412fb7feb86f1a12">input_masks_mem_</a>,</div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span>                        batchSize * <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a> * <span class="keyword">sizeof</span>(uint64_t),</div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span>                        cudaMemcpyHostToDevice, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a>));</div>
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno">  697</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaMemcpyAsync(</div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span>        io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acfb18940f77e933875fa4c5ee1fc4fc3">input_val_mem_gpu_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a30d21cb6211dea2b644fc266b2346a0b">input_val_mem_</a>,</div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span>        batchSize * <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a> * <span class="keyword">sizeof</span>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a30d21cb6211dea2b644fc266b2346a0b">input_val_mem_</a>[0]),</div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span>        cudaMemcpyHostToDevice, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a>));</div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aac9567857edcb49b00e14289ba13879c">upload_done_event_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a>));</div>
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno">  702</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span>        cudaStreamWaitEvent(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aac9567857edcb49b00e14289ba13879c">upload_done_event_</a>, 0));</div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span>  }</div>
</div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span> </div>
<div class="foldopen" id="foldopen00706" data-start="{" data-end="}">
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ad0acd2032fffa2aab27dbfaf23a48f1c">  706</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ad0acd2032fffa2aab27dbfaf23a48f1c">GraphLaunch</a>(<a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">InputsOutputs&lt;DataType&gt;</a>* io, <span class="keywordtype">int</span> batchSize) {</div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span>    io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a0f56c096b24f7992e92fdef66c78ed65">cuda_graphs_</a>[batchSize - 1].Launch(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a4da2faa3d3467b0b891fda272ec89186">exec_stream_</a>);</div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno">  711</span>      <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ad9bc088c3f7061fc9b4a50b9287cec94">UploadInputs</a>(io, batchSize);</div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span> </div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span>      io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a0f56c096b24f7992e92fdef66c78ed65">cuda_graphs_</a>[batchSize - 1].Launch(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>);</div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span>          cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a54e36f778959e1698ea7f47ca3069d26">download_done_event_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>));</div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span>      io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a0f56c096b24f7992e92fdef66c78ed65">cuda_graphs_</a>[batchSize - 1].Launch(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a4da2faa3d3467b0b891fda272ec89186">exec_stream_</a>);</div>
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno">  718</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span>          cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a54e36f778959e1698ea7f47ca3069d26">download_done_event_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a4da2faa3d3467b0b891fda272ec89186">exec_stream_</a>));</div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span>    }</div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span>  }</div>
</div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span> </div>
<div class="foldopen" id="foldopen00724" data-start="{" data-end="}">
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#aa3b5bd67092d91cdf27dca2ebfbd1e5c">  724</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#aa3b5bd67092d91cdf27dca2ebfbd1e5c">forwardEval</a>(<a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">InputsOutputs&lt;DataType&gt;</a>* io, <span class="keywordtype">int</span> batchSize,</div>
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno">  725</span>                   [[maybe_unused]] <span class="keywordtype">bool</span> capture = <span class="keyword">false</span>) {</div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span>    <span class="comment">// It is safe to evaluate larger than the batchSize</span></div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span>    <span class="comment">// as all buffers are designed to handle max_batch_size</span></div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span>    <span class="comment">// and the extra invalid results are never read.</span></div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span>    <span class="keywordflow">if</span> (batchSize &lt; <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a240b95efc1b5559d4ff8c5ce6faaad5c">min_batch_size_</a>) batchSize = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a240b95efc1b5559d4ff8c5ce6faaad5c">min_batch_size_</a>;</div>
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno">  730</span> </div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span><span class="preprocessor">#ifdef DEBUG_RAW_NPS</span></div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno">  732</span>    <span class="keyword">auto</span> t_start = std::chrono::high_resolution_clock::now();</div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno">  734</span> </div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span>    <span class="comment">// Expand packed planes to full planes.</span></div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span>    uint64_t* ipDataMasks = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a8912b9a29a368748dfb2c2a0f6ef8e81">input_masks_mem_gpu_</a>;</div>
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno">  737</span>    <span class="keyword">auto</span>* ipDataValues = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acfb18940f77e933875fa4c5ee1fc4fc3">input_val_mem_gpu_</a>;</div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span> </div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span>    DataType* tensor_mem[3];</div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span>    <span class="keywordtype">void</span>* scratch_mem;</div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span>    DataType*** offset_pointers;</div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span>    DataType*** head_offset_pointers;</div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span>    cudaStream_t compute_stream, upload_stream, download_stream;</div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span>    cublasHandle_t cublas;</div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno">  746</span>      <span class="comment">// We use tensor and scratch memory from InputOutputs (so that multiple</span></div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span>      <span class="comment">// requests can run in parallel)</span></div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; 3; i++) tensor_mem[i] = (DataType*)io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a88cce011cef46a3778871a606e2cfb0d">tensor_mem_</a>[i];</div>
<div class="line"><a id="l00749" name="l00749"></a><span class="lineno">  749</span>      scratch_mem = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a571a3d91326a06e4ef7ec76e949627c2">scratch_mem_</a>;</div>
<div class="line"><a id="l00750" name="l00750"></a><span class="lineno">  750</span>      offset_pointers = (DataType***)&amp;io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a96fb812fdea09c0bfb3652971b33ff4d">offset_pointers_</a>;</div>
<div class="line"><a id="l00751" name="l00751"></a><span class="lineno">  751</span>      head_offset_pointers = (DataType***)&amp;io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a5e256066b490e604c805c7f536ef06f9">head_offset_pointers_</a>;</div>
<div class="line"><a id="l00752" name="l00752"></a><span class="lineno">  752</span>      compute_stream = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a1dd4b31880458cf40c1846c96b0ffb85">compute_stream_</a>;</div>
<div class="line"><a id="l00753" name="l00753"></a><span class="lineno">  753</span>      upload_stream = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aebb70855764f1d081f94c14144b5d834">upload_stream_</a>;</div>
<div class="line"><a id="l00754" name="l00754"></a><span class="lineno">  754</span>      download_stream = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acbcc77293f33466a563a107ba64ee66f">download_stream_</a>;</div>
<div class="line"><a id="l00755" name="l00755"></a><span class="lineno">  755</span>      cublas = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7306070b1b58feb189bc380e0071e7a1">cublas_</a>;</div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; 3; i++) tensor_mem[i] = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a5827d93e06b1e2750fff7848894bdf2e">tensor_mem_</a>[i];</div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span>      scratch_mem = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>;</div>
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno">  759</span>      offset_pointers = (DataType***)&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9777fa5c5fe58d7eff4447cd7be0764b">offset_pointers_</a>;</div>
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno">  760</span>      head_offset_pointers = (DataType***)&amp;<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a41dbeae09f8028210d3115908711a0d3">head_offset_pointers_</a>;</div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span>      compute_stream = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>;</div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span>      upload_stream = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a>;</div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span>      download_stream = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900">download_stream_</a>;</div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span>      cublas = <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">cublas_</a>;</div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span>    }</div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span> </div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a> || <a class="code hl_define" href="network__cuda_8cc.html#ad0077596f0a38b26cf89984e950c8225">CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</a>) {</div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span>          cudaMemcpyAsync(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a8912b9a29a368748dfb2c2a0f6ef8e81">input_masks_mem_gpu_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#ac2d5c4d887a02dd9412fb7feb86f1a12">input_masks_mem_</a>,</div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span>                          batchSize * <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a> * <span class="keyword">sizeof</span>(uint64_t),</div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span>                          cudaMemcpyHostToDevice, upload_stream));</div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaMemcpyAsync(</div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span>          io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acfb18940f77e933875fa4c5ee1fc4fc3">input_val_mem_gpu_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a30d21cb6211dea2b644fc266b2346a0b">input_val_mem_</a>,</div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span>          batchSize * <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a> * <span class="keyword">sizeof</span>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a30d21cb6211dea2b644fc266b2346a0b">input_val_mem_</a>[0]),</div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span>          cudaMemcpyHostToDevice, upload_stream));</div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aac9567857edcb49b00e14289ba13879c">upload_done_event_</a>, upload_stream));</div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span>          cudaStreamWaitEvent(compute_stream, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aac9567857edcb49b00e14289ba13879c">upload_done_event_</a>, 0));</div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span>    }</div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span> </div>
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno">  781</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span>          cudaStreamWaitEvent(compute_stream, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6">compute_ordering_event_</a>,</div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span>                              capture ? cudaEventWaitExternal : 0));</div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno">  787</span>    }</div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span> </div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span>    <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#ae749a185fa49e8fe54067dcd0647f4fe">expandPlanes_NCHW</a>(tensor_mem[0], ipDataMasks, ipDataValues,</div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span>                      batchSize * <a class="code hl_variable" href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">kInputPlanes</a>, compute_stream);</div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span> </div>
<div class="line"><a id="l00792" name="l00792"></a><span class="lineno">  792</span>    <span class="keyword">auto</span>* opPol = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a123f601c65e02f3f56afed1d6a0ea081">op_policy_mem_gpu_</a>;</div>
<div class="line"><a id="l00793" name="l00793"></a><span class="lineno">  793</span>    <span class="keyword">auto</span>* opVal = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7c64b4d62f281e4fc83f0dfcf82cfb08">op_value_mem_gpu_</a>;</div>
<div class="line"><a id="l00794" name="l00794"></a><span class="lineno">  794</span>    <span class="keyword">auto</span>* opMov = io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aa9840db2798fa87fd3b8b229b876297b">op_moves_left_mem_gpu_</a>;</div>
<div class="line"><a id="l00795" name="l00795"></a><span class="lineno">  795</span> </div>
<div class="line"><a id="l00796" name="l00796"></a><span class="lineno">  796</span>    <span class="comment">// Figure out if the memory requirment for running the res block would fit</span></div>
<div class="line"><a id="l00797" name="l00797"></a><span class="lineno">  797</span>    <span class="comment">// in the L2 cache.</span></div>
<div class="line"><a id="l00798" name="l00798"></a><span class="lineno">  798</span>    <span class="keywordtype">bool</span> enableCacheOpt = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span>    DataType* skip_connection =</div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span>        <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a> ? tensor_mem[1] : tensor_mem[2];</div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span> </div>
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno">  802</span><span class="preprocessor">#if CUDART_VERSION &gt;= 11000</span></div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> pre_transform_tensor_size =</div>
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno">  804</span>        batchSize * <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ace0225a707963a917029a40ba0a96ece">numFilters_</a> * 8 * 8 * <span class="keyword">sizeof</span>(DataType);</div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> transformed_tensor_size = pre_transform_tensor_size * 36 / 16;</div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> res_block_mem =</div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span>        transformed_tensor_size * 2 + pre_transform_tensor_size;</div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span> </div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span>    cudaStreamAttrValue stream_attribute = {};</div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span>    stream_attribute.accessPolicyWindow.base_ptr = tensor_mem[2];</div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span>    stream_attribute.accessPolicyWindow.num_bytes = res_block_mem;</div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span>    stream_attribute.accessPolicyWindow.hitRatio = 1.0f;</div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span>    stream_attribute.accessPolicyWindow.hitProp = cudaAccessPropertyPersisting;</div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span>    stream_attribute.accessPolicyWindow.missProp = cudaAccessPropertyStreaming;</div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span> </div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae27e343d2c18e3ecd492101c33d24239">allow_cache_opt_</a> &amp;&amp; <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a> &amp;&amp;</div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span>        (<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(res_block_mem) &lt;= <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>) &amp;&amp;</div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span>        (res_block_mem &lt;= <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7203422407bcef3715a4b9fd9836e515">l2_cache_size_</a>)) {</div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span>      <span class="comment">// we can use a single alloc to hold all the required tensors, and enable</span></div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span>      <span class="comment">// persistent L2 caching on it</span></div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaStreamSetAttribute(</div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span>          compute_stream, cudaStreamAttributeAccessPolicyWindow,</div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span>          &amp;stream_attribute));</div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span> </div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span>      enableCacheOpt = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span>      skip_connection =</div>
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno">  827</span>          tensor_mem[2] + 2 * transformed_tensor_size / <span class="keyword">sizeof</span>(DataType);</div>
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno">  828</span>    }</div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span> </div>
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno">  831</span>    <span class="keywordtype">int</span> l = 0;</div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span> </div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno">  833</span>    DataType* <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a> = tensor_mem[0];</div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span>    DataType* spare1 = tensor_mem[1];</div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno">  835</span>    DataType* spare2 = tensor_mem[2];</div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span> </div>
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno">  837</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> &gt; 0) {</div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span>      <span class="comment">// Input.</span></div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, skip_connection, tensor_mem[0], <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span>                          scratch_mem, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span>                          compute_stream);  <span class="comment">// input conv</span></div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span> </div>
<div class="line"><a id="l00843" name="l00843"></a><span class="lineno">  843</span>      <span class="comment">// Residual block.</span></div>
<div class="line"><a id="l00844" name="l00844"></a><span class="lineno">  844</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> block = 0; block &lt; <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a>; block++) {</div>
<div class="line"><a id="l00845" name="l00845"></a><span class="lineno">  845</span>        <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a>) {</div>
<div class="line"><a id="l00846" name="l00846"></a><span class="lineno">  846</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, tensor_mem[2], skip_connection,</div>
<div class="line"><a id="l00847" name="l00847"></a><span class="lineno">  847</span>                              <span class="keyword">nullptr</span>, enableCacheOpt ? <span class="keyword">nullptr</span> : scratch_mem,</div>
<div class="line"><a id="l00848" name="l00848"></a><span class="lineno">  848</span>                              <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00849" name="l00849"></a><span class="lineno">  849</span>                              compute_stream);  <span class="comment">// block</span></div>
<div class="line"><a id="l00850" name="l00850"></a><span class="lineno">  850</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00851" name="l00851"></a><span class="lineno">  851</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, tensor_mem[0], tensor_mem[2], <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00852" name="l00852"></a><span class="lineno">  852</span>                              scratch_mem, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00853" name="l00853"></a><span class="lineno">  853</span>                              compute_stream);  <span class="comment">// conv1</span></div>
<div class="line"><a id="l00854" name="l00854"></a><span class="lineno">  854</span> </div>
<div class="line"><a id="l00855" name="l00855"></a><span class="lineno">  855</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, tensor_mem[2], tensor_mem[0],</div>
<div class="line"><a id="l00856" name="l00856"></a><span class="lineno">  856</span>                              tensor_mem[2], scratch_mem, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>,</div>
<div class="line"><a id="l00857" name="l00857"></a><span class="lineno">  857</span>                              <span class="keyword">nullptr</span>, cublas, compute_stream);  <span class="comment">// conv2</span></div>
<div class="line"><a id="l00858" name="l00858"></a><span class="lineno">  858</span>        }</div>
<div class="line"><a id="l00859" name="l00859"></a><span class="lineno">  859</span>      }</div>
<div class="line"><a id="l00860" name="l00860"></a><span class="lineno">  860</span> </div>
<div class="line"><a id="l00861" name="l00861"></a><span class="lineno">  861</span>      <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a> = tensor_mem[2];</div>
<div class="line"><a id="l00862" name="l00862"></a><span class="lineno">  862</span>      spare1 = tensor_mem[0];</div>
<div class="line"><a id="l00863" name="l00863"></a><span class="lineno">  863</span>      spare2 = tensor_mem[1];</div>
<div class="line"><a id="l00864" name="l00864"></a><span class="lineno">  864</span>    }</div>
<div class="line"><a id="l00865" name="l00865"></a><span class="lineno">  865</span> </div>
<div class="line"><a id="l00866" name="l00866"></a><span class="lineno">  866</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>) {</div>
<div class="line"><a id="l00867" name="l00867"></a><span class="lineno">  867</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(</div>
<div class="line"><a id="l00868" name="l00868"></a><span class="lineno">  868</span>          batchSize, tensor_mem[1],</div>
<div class="line"><a id="l00869" name="l00869"></a><span class="lineno">  869</span>          (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> &gt; 0) ? tensor_mem[2] : tensor_mem[0],</div>
<div class="line"><a id="l00870" name="l00870"></a><span class="lineno">  870</span>          (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a> &gt; 0) ? tensor_mem[0] : tensor_mem[2], scratch_mem,</div>
<div class="line"><a id="l00871" name="l00871"></a><span class="lineno">  871</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas, compute_stream,</div>
<div class="line"><a id="l00872" name="l00872"></a><span class="lineno">  872</span>          offset_pointers);  <span class="comment">// Entire attention body of the network</span></div>
<div class="line"><a id="l00873" name="l00873"></a><span class="lineno">  873</span> </div>
<div class="line"><a id="l00874" name="l00874"></a><span class="lineno">  874</span>      <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a> = tensor_mem[1];</div>
<div class="line"><a id="l00875" name="l00875"></a><span class="lineno">  875</span>      spare1 = tensor_mem[0];</div>
<div class="line"><a id="l00876" name="l00876"></a><span class="lineno">  876</span>      spare2 = tensor_mem[2];</div>
<div class="line"><a id="l00877" name="l00877"></a><span class="lineno">  877</span>    }</div>
<div class="line"><a id="l00878" name="l00878"></a><span class="lineno">  878</span> </div>
<div class="line"><a id="l00879" name="l00879"></a><span class="lineno">  879</span><span class="preprocessor">#if CUDART_VERSION &gt;= 11000</span></div>
<div class="line"><a id="l00880" name="l00880"></a><span class="lineno">  880</span>    <span class="keywordflow">if</span> (enableCacheOpt) {</div>
<div class="line"><a id="l00881" name="l00881"></a><span class="lineno">  881</span>      <span class="comment">// reset the cache settings</span></div>
<div class="line"><a id="l00882" name="l00882"></a><span class="lineno">  882</span>      stream_attribute.accessPolicyWindow.num_bytes = 0;</div>
<div class="line"><a id="l00883" name="l00883"></a><span class="lineno">  883</span>      cudaStreamSetAttribute(compute_stream,</div>
<div class="line"><a id="l00884" name="l00884"></a><span class="lineno">  884</span>                             cudaStreamAttributeAccessPolicyWindow,</div>
<div class="line"><a id="l00885" name="l00885"></a><span class="lineno">  885</span>                             &amp;stream_attribute);</div>
<div class="line"><a id="l00886" name="l00886"></a><span class="lineno">  886</span>      cudaCtxResetPersistingL2Cache();</div>
<div class="line"><a id="l00887" name="l00887"></a><span class="lineno">  887</span>    }</div>
<div class="line"><a id="l00888" name="l00888"></a><span class="lineno">  888</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00889" name="l00889"></a><span class="lineno">  889</span> </div>
<div class="line"><a id="l00890" name="l00890"></a><span class="lineno">  890</span>    <span class="comment">// Policy head.</span></div>
<div class="line"><a id="l00891" name="l00891"></a><span class="lineno">  891</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae017cf365d571ddb91a223a3e7c48a0f">attn_policy_</a>) {</div>
<div class="line"><a id="l00892" name="l00892"></a><span class="lineno">  892</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(</div>
<div class="line"><a id="l00893" name="l00893"></a><span class="lineno">  893</span>          batchSize, spare1, <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a>, spare2, scratch_mem, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00894" name="l00894"></a><span class="lineno">  894</span>          cublas, compute_stream,</div>
<div class="line"><a id="l00895" name="l00895"></a><span class="lineno">  895</span>          head_offset_pointers);  <span class="comment">// Entire Attention policy head except for the</span></div>
<div class="line"><a id="l00896" name="l00896"></a><span class="lineno">  896</span>                                  <span class="comment">// policy map</span></div>
<div class="line"><a id="l00897" name="l00897"></a><span class="lineno">  897</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(</div>
<div class="line"><a id="l00898" name="l00898"></a><span class="lineno">  898</span>          batchSize, (DataType*)opPol, spare1, <span class="keyword">nullptr</span>, scratch_mem,</div>
<div class="line"><a id="l00899" name="l00899"></a><span class="lineno">  899</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00900" name="l00900"></a><span class="lineno">  900</span>          compute_stream);  <span class="comment">// policy map layer  // POLICY output</span></div>
<div class="line"><a id="l00901" name="l00901"></a><span class="lineno">  901</span> </div>
<div class="line"><a id="l00902" name="l00902"></a><span class="lineno">  902</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1b16fc6e42242f982303703bbfa55340">conv_policy_</a>) {</div>
<div class="line"><a id="l00903" name="l00903"></a><span class="lineno">  903</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, spare1, <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a>, <span class="keyword">nullptr</span>, scratch_mem,</div>
<div class="line"><a id="l00904" name="l00904"></a><span class="lineno">  904</span>                          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00905" name="l00905"></a><span class="lineno">  905</span>                          compute_stream);  <span class="comment">// policy conv1</span></div>
<div class="line"><a id="l00906" name="l00906"></a><span class="lineno">  906</span> </div>
<div class="line"><a id="l00907" name="l00907"></a><span class="lineno">  907</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, spare2, spare1, <span class="keyword">nullptr</span>, scratch_mem,</div>
<div class="line"><a id="l00908" name="l00908"></a><span class="lineno">  908</span>                          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00909" name="l00909"></a><span class="lineno">  909</span>                          compute_stream);  <span class="comment">// policy conv2</span></div>
<div class="line"><a id="l00910" name="l00910"></a><span class="lineno">  910</span> </div>
<div class="line"><a id="l00911" name="l00911"></a><span class="lineno">  911</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(</div>
<div class="line"><a id="l00912" name="l00912"></a><span class="lineno">  912</span>          batchSize, (DataType*)opPol, spare2, <span class="keyword">nullptr</span>, scratch_mem,</div>
<div class="line"><a id="l00913" name="l00913"></a><span class="lineno">  913</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00914" name="l00914"></a><span class="lineno">  914</span>          compute_stream);  <span class="comment">// policy map layer  // POLICY output</span></div>
<div class="line"><a id="l00915" name="l00915"></a><span class="lineno">  915</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00916" name="l00916"></a><span class="lineno">  916</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, spare1, <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a>, <span class="keyword">nullptr</span>, scratch_mem,</div>
<div class="line"><a id="l00917" name="l00917"></a><span class="lineno">  917</span>                          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00918" name="l00918"></a><span class="lineno">  918</span>                          compute_stream);  <span class="comment">// pol conv</span></div>
<div class="line"><a id="l00919" name="l00919"></a><span class="lineno">  919</span> </div>
<div class="line"><a id="l00920" name="l00920"></a><span class="lineno">  920</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, (DataType*)opPol, spare1, <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00921" name="l00921"></a><span class="lineno">  921</span>                          scratch_mem, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00922" name="l00922"></a><span class="lineno">  922</span>                          compute_stream);  <span class="comment">// pol FC  // POLICY</span></div>
<div class="line"><a id="l00923" name="l00923"></a><span class="lineno">  923</span>    }</div>
<div class="line"><a id="l00924" name="l00924"></a><span class="lineno">  924</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acde2451f3e98943ed59a4642835d5970">policy_done_event_</a>, compute_stream));</div>
<div class="line"><a id="l00925" name="l00925"></a><span class="lineno">  925</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00926" name="l00926"></a><span class="lineno">  926</span>        cudaStreamWaitEvent(download_stream, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acde2451f3e98943ed59a4642835d5970">policy_done_event_</a>, 0));</div>
<div class="line"><a id="l00927" name="l00927"></a><span class="lineno">  927</span> </div>
<div class="line"><a id="l00928" name="l00928"></a><span class="lineno">  928</span>    <span class="comment">// Copy policy output from device memory to host memory.</span></div>
<div class="line"><a id="l00929" name="l00929"></a><span class="lineno">  929</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaMemcpyAsync(</div>
<div class="line"><a id="l00930" name="l00930"></a><span class="lineno">  930</span>        io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7cf020ede9475c67907d528517fbb559">op_policy_mem_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a123f601c65e02f3f56afed1d6a0ea081">op_policy_mem_gpu_</a>,</div>
<div class="line"><a id="l00931" name="l00931"></a><span class="lineno">  931</span>        <span class="keyword">sizeof</span>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7cf020ede9475c67907d528517fbb559">op_policy_mem_</a>[0]) * <a class="code hl_variable" href="namespacelczero_1_1cudnn__backend.html#a3298666071469a49009d91a8ac5f9c7b">kNumOutputPolicy</a> * batchSize,</div>
<div class="line"><a id="l00932" name="l00932"></a><span class="lineno">  932</span>        cudaMemcpyDeviceToHost, download_stream));</div>
<div class="line"><a id="l00933" name="l00933"></a><span class="lineno">  933</span> </div>
<div class="line"><a id="l00934" name="l00934"></a><span class="lineno">  934</span>    <span class="comment">// value head</span></div>
<div class="line"><a id="l00935" name="l00935"></a><span class="lineno">  935</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, (DataType*)opVal, <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a>, spare2, scratch_mem,</div>
<div class="line"><a id="l00936" name="l00936"></a><span class="lineno">  936</span>                        <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00937" name="l00937"></a><span class="lineno">  937</span>                        compute_stream);  <span class="comment">// value head</span></div>
<div class="line"><a id="l00938" name="l00938"></a><span class="lineno">  938</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a> &amp;&amp; !<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00939" name="l00939"></a><span class="lineno">  939</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l00940" name="l00940"></a><span class="lineno">  940</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00941" name="l00941"></a><span class="lineno">  941</span>          cudaEventRecordWithFlags(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6">compute_ordering_event_</a>, compute_stream,</div>
<div class="line"><a id="l00942" name="l00942"></a><span class="lineno">  942</span>                                   capture ? cudaEventRecordExternal : 0));</div>
<div class="line"><a id="l00943" name="l00943"></a><span class="lineno">  943</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00944" name="l00944"></a><span class="lineno">  944</span>    }</div>
<div class="line"><a id="l00945" name="l00945"></a><span class="lineno">  945</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a86b4ff2bf7753745691b0e2d2d445697">value_done_event_</a>, compute_stream));</div>
<div class="line"><a id="l00946" name="l00946"></a><span class="lineno">  946</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00947" name="l00947"></a><span class="lineno">  947</span>        cudaStreamWaitEvent(download_stream, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a86b4ff2bf7753745691b0e2d2d445697">value_done_event_</a>, 0));</div>
<div class="line"><a id="l00948" name="l00948"></a><span class="lineno">  948</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaMemcpyAsync(</div>
<div class="line"><a id="l00949" name="l00949"></a><span class="lineno">  949</span>        io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">op_value_mem_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7c64b4d62f281e4fc83f0dfcf82cfb08">op_value_mem_gpu_</a>,</div>
<div class="line"><a id="l00950" name="l00950"></a><span class="lineno">  950</span>        <span class="keyword">sizeof</span>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">op_value_mem_</a>[0]) * (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a> ? 3 : 1) * batchSize,</div>
<div class="line"><a id="l00951" name="l00951"></a><span class="lineno">  951</span>        cudaMemcpyDeviceToHost, download_stream));</div>
<div class="line"><a id="l00952" name="l00952"></a><span class="lineno">  952</span> </div>
<div class="line"><a id="l00953" name="l00953"></a><span class="lineno">  953</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a>) {</div>
<div class="line"><a id="l00954" name="l00954"></a><span class="lineno">  954</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l00955" name="l00955"></a><span class="lineno">  955</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventRecordWithFlags(</div>
<div class="line"><a id="l00956" name="l00956"></a><span class="lineno">  956</span>          io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9b3778db8e28d7d69e3a411b021f382d">wdl_download_done_event_</a>, download_stream,</div>
<div class="line"><a id="l00957" name="l00957"></a><span class="lineno">  957</span>          capture ? cudaEventRecordExternal : 0));</div>
<div class="line"><a id="l00958" name="l00958"></a><span class="lineno">  958</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00959" name="l00959"></a><span class="lineno">  959</span>    }</div>
<div class="line"><a id="l00960" name="l00960"></a><span class="lineno">  960</span> </div>
<div class="line"><a id="l00961" name="l00961"></a><span class="lineno">  961</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a>) {</div>
<div class="line"><a id="l00962" name="l00962"></a><span class="lineno">  962</span>      <span class="comment">// Moves left head</span></div>
<div class="line"><a id="l00963" name="l00963"></a><span class="lineno">  963</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, spare1, <a class="code hl_variable" href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a>, <span class="keyword">nullptr</span>, scratch_mem,</div>
<div class="line"><a id="l00964" name="l00964"></a><span class="lineno">  964</span>                          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00965" name="l00965"></a><span class="lineno">  965</span>                          compute_stream);  <span class="comment">// moves conv or embedding</span></div>
<div class="line"><a id="l00966" name="l00966"></a><span class="lineno">  966</span> </div>
<div class="line"><a id="l00967" name="l00967"></a><span class="lineno">  967</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, spare2, spare1, <span class="keyword">nullptr</span>, scratch_mem,</div>
<div class="line"><a id="l00968" name="l00968"></a><span class="lineno">  968</span>                          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00969" name="l00969"></a><span class="lineno">  969</span>                          compute_stream);  <span class="comment">// moves FC1</span></div>
<div class="line"><a id="l00970" name="l00970"></a><span class="lineno">  970</span> </div>
<div class="line"><a id="l00971" name="l00971"></a><span class="lineno">  971</span>      <span class="comment">// Moves left FC2</span></div>
<div class="line"><a id="l00972" name="l00972"></a><span class="lineno">  972</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>[l++]-&gt;Eval(batchSize, (DataType*)opMov, spare2, <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00973" name="l00973"></a><span class="lineno">  973</span>                          scratch_mem, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>, <span class="keyword">nullptr</span>, cublas,</div>
<div class="line"><a id="l00974" name="l00974"></a><span class="lineno">  974</span>                          compute_stream);</div>
<div class="line"><a id="l00975" name="l00975"></a><span class="lineno">  975</span>      <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l00976" name="l00976"></a><span class="lineno">  976</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l00977" name="l00977"></a><span class="lineno">  977</span>        <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00978" name="l00978"></a><span class="lineno">  978</span>            cudaEventRecordWithFlags(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6">compute_ordering_event_</a>, compute_stream,</div>
<div class="line"><a id="l00979" name="l00979"></a><span class="lineno">  979</span>                                     capture ? cudaEventRecordExternal : 0));</div>
<div class="line"><a id="l00980" name="l00980"></a><span class="lineno">  980</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00981" name="l00981"></a><span class="lineno">  981</span>      }</div>
<div class="line"><a id="l00982" name="l00982"></a><span class="lineno">  982</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00983" name="l00983"></a><span class="lineno">  983</span>          cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acfddb909034c09e42b6a25dd2c3fb49d">moves_left_done_event_</a>, compute_stream));</div>
<div class="line"><a id="l00984" name="l00984"></a><span class="lineno">  984</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00985" name="l00985"></a><span class="lineno">  985</span>          cudaStreamWaitEvent(download_stream, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acfddb909034c09e42b6a25dd2c3fb49d">moves_left_done_event_</a>, 0));</div>
<div class="line"><a id="l00986" name="l00986"></a><span class="lineno">  986</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00987" name="l00987"></a><span class="lineno">  987</span>          cudaMemcpyAsync(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a0d6a81afd143971bdd7b624e63ba4f87">op_moves_left_mem_</a>, io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aa9840db2798fa87fd3b8b229b876297b">op_moves_left_mem_gpu_</a>,</div>
<div class="line"><a id="l00988" name="l00988"></a><span class="lineno">  988</span>                          <span class="keyword">sizeof</span>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a0d6a81afd143971bdd7b624e63ba4f87">op_moves_left_mem_</a>[0]) * batchSize,</div>
<div class="line"><a id="l00989" name="l00989"></a><span class="lineno">  989</span>                          cudaMemcpyDeviceToHost, download_stream));</div>
<div class="line"><a id="l00990" name="l00990"></a><span class="lineno">  990</span>    }</div>
<div class="line"><a id="l00991" name="l00991"></a><span class="lineno">  991</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l00992" name="l00992"></a><span class="lineno">  992</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00993" name="l00993"></a><span class="lineno">  993</span>        cudaEventRecordWithFlags(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a54e36f778959e1698ea7f47ca3069d26">download_done_event_</a>, download_stream,</div>
<div class="line"><a id="l00994" name="l00994"></a><span class="lineno">  994</span>                                 capture ? cudaEventRecordExternal : 0));</div>
<div class="line"><a id="l00995" name="l00995"></a><span class="lineno">  995</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00996" name="l00996"></a><span class="lineno">  996</span>    <span class="keywordflow">if</span> (!capture) {</div>
<div class="line"><a id="l00997" name="l00997"></a><span class="lineno">  997</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(</div>
<div class="line"><a id="l00998" name="l00998"></a><span class="lineno">  998</span>          cudaEventRecord(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a54e36f778959e1698ea7f47ca3069d26">download_done_event_</a>, download_stream));</div>
<div class="line"><a id="l00999" name="l00999"></a><span class="lineno">  999</span>    }</div>
<div class="line"><a id="l01000" name="l01000"></a><span class="lineno"> 1000</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l01001" name="l01001"></a><span class="lineno"> 1001</span>  }</div>
</div>
<div class="line"><a id="l01002" name="l01002"></a><span class="lineno"> 1002</span> </div>
<div class="foldopen" id="foldopen01003" data-start="{" data-end="}">
<div class="line"><a id="l01003" name="l01003"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a22edd11d982e72b03926885f155bca0d"> 1003</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a22edd11d982e72b03926885f155bca0d">finishEval</a>(<a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">InputsOutputs&lt;DataType&gt;</a>* io, <span class="keywordtype">int</span> batchSize) {</div>
<div class="line"><a id="l01004" name="l01004"></a><span class="lineno"> 1004</span><span class="preprocessor">#if !CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l01005" name="l01005"></a><span class="lineno"> 1005</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventSynchronize(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a54e36f778959e1698ea7f47ca3069d26">download_done_event_</a>));</div>
<div class="line"><a id="l01006" name="l01006"></a><span class="lineno"> 1006</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l01007" name="l01007"></a><span class="lineno"> 1007</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a>) {</div>
<div class="line"><a id="l01008" name="l01008"></a><span class="lineno"> 1008</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l01009" name="l01009"></a><span class="lineno"> 1009</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventSynchronize(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9b3778db8e28d7d69e3a411b021f382d">wdl_download_done_event_</a>));</div>
<div class="line"><a id="l01010" name="l01010"></a><span class="lineno"> 1010</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l01011" name="l01011"></a><span class="lineno"> 1011</span>      <span class="comment">// Value softmax done cpu side.</span></div>
<div class="line"><a id="l01012" name="l01012"></a><span class="lineno"> 1012</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; batchSize; i++) {</div>
<div class="line"><a id="l01013" name="l01013"></a><span class="lineno"> 1013</span>        <span class="keywordtype">float</span>* wdl = <span class="keyword">sizeof</span>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">op_value_mem_</a>[0]) == <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>)</div>
<div class="line"><a id="l01014" name="l01014"></a><span class="lineno"> 1014</span>                         ? (<span class="keywordtype">float</span>*)io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">op_value_mem_</a></div>
<div class="line"><a id="l01015" name="l01015"></a><span class="lineno"> 1015</span>                         : io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aed753991b629b7e429233f65cb1cb40c">wdl_cpu_softmax_</a>.get();</div>
<div class="line"><a id="l01016" name="l01016"></a><span class="lineno"> 1016</span>        <span class="keywordtype">float</span> w = <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#a2d28b2933cc4dbdac8714d9f28861a19">FromType</a>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">op_value_mem_</a>[3 * i + 0]);</div>
<div class="line"><a id="l01017" name="l01017"></a><span class="lineno"> 1017</span>        <span class="keywordtype">float</span> <a class="code hl_variable" href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a> = <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#a2d28b2933cc4dbdac8714d9f28861a19">FromType</a>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">op_value_mem_</a>[3 * i + 1]);</div>
<div class="line"><a id="l01018" name="l01018"></a><span class="lineno"> 1018</span>        <span class="keywordtype">float</span> l = <a class="code hl_function" href="namespacelczero_1_1cudnn__backend.html#a2d28b2933cc4dbdac8714d9f28861a19">FromType</a>(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">op_value_mem_</a>[3 * i + 2]);</div>
<div class="line"><a id="l01019" name="l01019"></a><span class="lineno"> 1019</span>        <span class="keywordtype">float</span> <a class="code hl_variable" href="memcache_8cc.html#ac51334f57ef8b81c0629c9421798c344">m</a> = std::max({w, <a class="code hl_variable" href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a>, l});</div>
<div class="line"><a id="l01020" name="l01020"></a><span class="lineno"> 1020</span>        w = std::exp(w - <a class="code hl_variable" href="memcache_8cc.html#ac51334f57ef8b81c0629c9421798c344">m</a>);</div>
<div class="line"><a id="l01021" name="l01021"></a><span class="lineno"> 1021</span>        <a class="code hl_variable" href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a> = std::exp(<a class="code hl_variable" href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a> - <a class="code hl_variable" href="memcache_8cc.html#ac51334f57ef8b81c0629c9421798c344">m</a>);</div>
<div class="line"><a id="l01022" name="l01022"></a><span class="lineno"> 1022</span>        l = std::exp(l - <a class="code hl_variable" href="memcache_8cc.html#ac51334f57ef8b81c0629c9421798c344">m</a>);</div>
<div class="line"><a id="l01023" name="l01023"></a><span class="lineno"> 1023</span>        <span class="keywordtype">float</span> sum = w + <a class="code hl_variable" href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a> + l;</div>
<div class="line"><a id="l01024" name="l01024"></a><span class="lineno"> 1024</span>        w /= sum;</div>
<div class="line"><a id="l01025" name="l01025"></a><span class="lineno"> 1025</span>        l /= sum;</div>
<div class="line"><a id="l01026" name="l01026"></a><span class="lineno"> 1026</span>        <a class="code hl_variable" href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a> /= sum;</div>
<div class="line"><a id="l01027" name="l01027"></a><span class="lineno"> 1027</span>        wdl[2 * i + 0] = w - l;</div>
<div class="line"><a id="l01028" name="l01028"></a><span class="lineno"> 1028</span>        wdl[2 * i + 1] = <a class="code hl_variable" href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a>;</div>
<div class="line"><a id="l01029" name="l01029"></a><span class="lineno"> 1029</span>      }</div>
<div class="line"><a id="l01030" name="l01030"></a><span class="lineno"> 1030</span>    }</div>
<div class="line"><a id="l01031" name="l01031"></a><span class="lineno"> 1031</span><span class="preprocessor">#if CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l01032" name="l01032"></a><span class="lineno"> 1032</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventSynchronize(io-&gt;<a class="code hl_variable" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a54e36f778959e1698ea7f47ca3069d26">download_done_event_</a>));</div>
<div class="line"><a id="l01033" name="l01033"></a><span class="lineno"> 1033</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l01034" name="l01034"></a><span class="lineno"> 1034</span>  }</div>
</div>
<div class="line"><a id="l01035" name="l01035"></a><span class="lineno"> 1035</span> </div>
<div class="foldopen" id="foldopen01036" data-start="{" data-end="}">
<div class="line"><a id="l01036" name="l01036"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a46d705e0e218edd9dee101e809e29e6f"> 1036</a></span>  <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a46d705e0e218edd9dee101e809e29e6f">~CudaNetwork</a>() {</div>
<div class="line"><a id="l01037" name="l01037"></a><span class="lineno"> 1037</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>) <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaFree(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>));</div>
<div class="line"><a id="l01038" name="l01038"></a><span class="lineno"> 1038</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>) {</div>
<div class="line"><a id="l01039" name="l01039"></a><span class="lineno"> 1039</span>      <span class="keywordflow">for</span> (<span class="keyword">auto</span> mem : <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a5827d93e06b1e2750fff7848894bdf2e">tensor_mem_</a>) {</div>
<div class="line"><a id="l01040" name="l01040"></a><span class="lineno"> 1040</span>        <span class="keywordflow">if</span> (mem) <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaFree(mem));</div>
<div class="line"><a id="l01041" name="l01041"></a><span class="lineno"> 1041</span>      }</div>
<div class="line"><a id="l01042" name="l01042"></a><span class="lineno"> 1042</span>      <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9777fa5c5fe58d7eff4447cd7be0764b">offset_pointers_</a>) <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaFree(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9777fa5c5fe58d7eff4447cd7be0764b">offset_pointers_</a>));</div>
<div class="line"><a id="l01043" name="l01043"></a><span class="lineno"> 1043</span>      <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a41dbeae09f8028210d3115908711a0d3">head_offset_pointers_</a>)</div>
<div class="line"><a id="l01044" name="l01044"></a><span class="lineno"> 1044</span>        <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaFree(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a41dbeae09f8028210d3115908711a0d3">head_offset_pointers_</a>));</div>
<div class="line"><a id="l01045" name="l01045"></a><span class="lineno"> 1045</span>      <a class="code hl_define" href="cuda__common_8h.html#a7df6734b37d817be68002a816e49a5d1">ReportCUBLASErrors</a>(cublasDestroy(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">cublas_</a>));</div>
<div class="line"><a id="l01046" name="l01046"></a><span class="lineno"> 1046</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaStreamDestroy(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a>));</div>
<div class="line"><a id="l01047" name="l01047"></a><span class="lineno"> 1047</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaStreamDestroy(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a>));</div>
<div class="line"><a id="l01048" name="l01048"></a><span class="lineno"> 1048</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaStreamDestroy(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900">download_stream_</a>));</div>
<div class="line"><a id="l01049" name="l01049"></a><span class="lineno"> 1049</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaEventDestroy(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6">compute_ordering_event_</a>));</div>
<div class="line"><a id="l01050" name="l01050"></a><span class="lineno"> 1050</span>    }</div>
<div class="line"><a id="l01051" name="l01051"></a><span class="lineno"> 1051</span>  }</div>
</div>
<div class="line"><a id="l01052" name="l01052"></a><span class="lineno"> 1052</span> </div>
<div class="foldopen" id="foldopen01053" data-start="{" data-end="}">
<div class="line"><a id="l01053" name="l01053"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a272fc67afccd2b11b44c0f7cbffd0769"> 1053</a></span>  <span class="keyword">const</span> <a class="code hl_struct" href="structlczero_1_1NetworkCapabilities.html">NetworkCapabilities</a>&amp; <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a272fc67afccd2b11b44c0f7cbffd0769">GetCapabilities</a>()<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l01054" name="l01054"></a><span class="lineno"> 1054</span>    <span class="keywordflow">return</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8569c32a2f7f878f57f2a232b097dac8">capabilities_</a>;</div>
<div class="line"><a id="l01055" name="l01055"></a><span class="lineno"> 1055</span>  }</div>
</div>
<div class="line"><a id="l01056" name="l01056"></a><span class="lineno"> 1056</span> </div>
<div class="foldopen" id="foldopen01057" data-start="{" data-end="}">
<div class="line"><a id="l01057" name="l01057"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a6e6f47b4107450f2a9d4b3a0831359dc"> 1057</a></span>  <span class="keywordtype">int</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a6e6f47b4107450f2a9d4b3a0831359dc">GetMiniBatchSize</a>()<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l01058" name="l01058"></a><span class="lineno"> 1058</span>    <span class="comment">// Simple heuristic that seems to work for a wide range of GPUs.</span></div>
<div class="line"><a id="l01059" name="l01059"></a><span class="lineno"> 1059</span>    <span class="keywordflow">return</span> 2 * <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad2c0d5066570e1aa1b97873cf5da9bea">sm_count_</a>;</div>
<div class="line"><a id="l01060" name="l01060"></a><span class="lineno"> 1060</span>  }</div>
</div>
<div class="line"><a id="l01061" name="l01061"></a><span class="lineno"> 1061</span> </div>
<div class="foldopen" id="foldopen01062" data-start="{" data-end="}">
<div class="line"><a id="l01062" name="l01062"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#af9036a86e264666d5bf78e7ce38ba94d"> 1062</a></span>  <span class="keywordtype">int</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#af9036a86e264666d5bf78e7ce38ba94d">GetPreferredBatchStep</a>()<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l01063" name="l01063"></a><span class="lineno"> 1063</span>    <span class="keywordtype">int</span> preferred_split = 7;</div>
<div class="line"><a id="l01064" name="l01064"></a><span class="lineno"> 1064</span>    <span class="keywordflow">while</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad2c0d5066570e1aa1b97873cf5da9bea">sm_count_</a> % preferred_split != 0) preferred_split++;</div>
<div class="line"><a id="l01065" name="l01065"></a><span class="lineno"> 1065</span>    <span class="keywordflow">return</span> preferred_split;</div>
<div class="line"><a id="l01066" name="l01066"></a><span class="lineno"> 1066</span>  }</div>
</div>
<div class="line"><a id="l01067" name="l01067"></a><span class="lineno"> 1067</span> </div>
<div class="line"><a id="l01068" name="l01068"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#abcc07a7f035ddc5baff3b24c0e6119e8"> 1068</a></span>  <span class="keywordtype">int</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#abcc07a7f035ddc5baff3b24c0e6119e8">GetThreads</a>()<span class="keyword"> const override </span>{ <span class="keywordflow">return</span> 1 + <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>; }</div>
<div class="line"><a id="l01069" name="l01069"></a><span class="lineno"> 1069</span> </div>
<div class="foldopen" id="foldopen01070" data-start="{" data-end="}">
<div class="line"><a id="l01070" name="l01070"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a51f27881b41e4b4caff5b18c6faec3f7"> 1070</a></span>  std::unique_ptr&lt;NetworkComputation&gt; <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a51f27881b41e4b4caff5b18c6faec3f7">NewComputation</a>()<span class="keyword"> override </span>{</div>
<div class="line"><a id="l01071" name="l01071"></a><span class="lineno"> 1071</span>    <span class="comment">// Set correct gpu id for this computation (as it might have been called</span></div>
<div class="line"><a id="l01072" name="l01072"></a><span class="lineno"> 1072</span>    <span class="comment">// from a different thread).</span></div>
<div class="line"><a id="l01073" name="l01073"></a><span class="lineno"> 1073</span>    <span class="keywordtype">int</span> device = -1;</div>
<div class="line"><a id="l01074" name="l01074"></a><span class="lineno"> 1074</span>    <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaGetDevice(&amp;device));</div>
<div class="line"><a id="l01075" name="l01075"></a><span class="lineno"> 1075</span>    <span class="keywordflow">if</span> (device != <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>) {</div>
<div class="line"><a id="l01076" name="l01076"></a><span class="lineno"> 1076</span>      <a class="code hl_define" href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a>(cudaSetDevice(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>));</div>
<div class="line"><a id="l01077" name="l01077"></a><span class="lineno"> 1077</span>    }</div>
<div class="line"><a id="l01078" name="l01078"></a><span class="lineno"> 1078</span>    <span class="keywordflow">return</span> std::make_unique&lt;CudaNetworkComputation&lt;DataType&gt;&gt;(<span class="keyword">this</span>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a>,</div>
<div class="line"><a id="l01079" name="l01079"></a><span class="lineno"> 1079</span>                                                              <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a>);</div>
<div class="line"><a id="l01080" name="l01080"></a><span class="lineno"> 1080</span>  }</div>
</div>
<div class="line"><a id="l01081" name="l01081"></a><span class="lineno"> 1081</span> </div>
<div class="foldopen" id="foldopen01082" data-start="{" data-end="}">
<div class="line"><a id="l01082" name="l01082"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a8be42510552691603217878b80f6603f"> 1082</a></span>  std::unique_ptr&lt;InputsOutputs&lt;DataType&gt;&gt; <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a8be42510552691603217878b80f6603f">GetInputsOutputs</a>() {</div>
<div class="line"><a id="l01083" name="l01083"></a><span class="lineno"> 1083</span>    std::lock_guard&lt;std::mutex&gt; lock(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a55b3652578313fe3b4ace6617f05b2c0">inputs_outputs_lock_</a>);</div>
<div class="line"><a id="l01084" name="l01084"></a><span class="lineno"> 1084</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad4e9918939cfb8e524021339b08cfb44">free_inputs_outputs_</a>.empty()) {</div>
<div class="line"><a id="l01085" name="l01085"></a><span class="lineno"> 1085</span>      <span class="keywordflow">return</span> std::make_unique&lt;InputsOutputs&lt;DataType&gt;&gt;(</div>
<div class="line"><a id="l01086" name="l01086"></a><span class="lineno"> 1086</span>          <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9145d366464720a1f82f065bed9b0b32">tensor_mem_size_</a>, <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>,</div>
<div class="line"><a id="l01087" name="l01087"></a><span class="lineno"> 1087</span>          !<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a20d84b728c194b4708c6de9fb82445b1">has_tensor_cores_</a> &amp;&amp; std::is_same&lt;half, DataType&gt;::value);</div>
<div class="line"><a id="l01088" name="l01088"></a><span class="lineno"> 1088</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l01089" name="l01089"></a><span class="lineno"> 1089</span>      std::unique_ptr&lt;InputsOutputs&lt;DataType&gt;&gt; resource =</div>
<div class="line"><a id="l01090" name="l01090"></a><span class="lineno"> 1090</span>          std::move(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad4e9918939cfb8e524021339b08cfb44">free_inputs_outputs_</a>.front());</div>
<div class="line"><a id="l01091" name="l01091"></a><span class="lineno"> 1091</span>      <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad4e9918939cfb8e524021339b08cfb44">free_inputs_outputs_</a>.pop_front();</div>
<div class="line"><a id="l01092" name="l01092"></a><span class="lineno"> 1092</span>      <span class="keywordflow">return</span> resource;</div>
<div class="line"><a id="l01093" name="l01093"></a><span class="lineno"> 1093</span>    }</div>
<div class="line"><a id="l01094" name="l01094"></a><span class="lineno"> 1094</span>  }</div>
</div>
<div class="line"><a id="l01095" name="l01095"></a><span class="lineno"> 1095</span> </div>
<div class="foldopen" id="foldopen01096" data-start="{" data-end="}">
<div class="line"><a id="l01096" name="l01096"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#aca8d94d41b7aa1167404d99966f65ef9"> 1096</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#aca8d94d41b7aa1167404d99966f65ef9">ReleaseInputsOutputs</a>(std::unique_ptr&lt;<a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">InputsOutputs&lt;DataType&gt;</a>&gt; resource) {</div>
<div class="line"><a id="l01097" name="l01097"></a><span class="lineno"> 1097</span>    std::lock_guard&lt;std::mutex&gt; lock(<a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a55b3652578313fe3b4ace6617f05b2c0">inputs_outputs_lock_</a>);</div>
<div class="line"><a id="l01098" name="l01098"></a><span class="lineno"> 1098</span>    <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad4e9918939cfb8e524021339b08cfb44">free_inputs_outputs_</a>.push_back(std::move(resource));</div>
<div class="line"><a id="l01099" name="l01099"></a><span class="lineno"> 1099</span>  }</div>
</div>
<div class="line"><a id="l01100" name="l01100"></a><span class="lineno"> 1100</span> </div>
<div class="line"><a id="l01101" name="l01101"></a><span class="lineno"> 1101</span>  <span class="comment">// Apparently nvcc doesn&#39;t see constructor invocations through make_unique.</span></div>
<div class="line"><a id="l01102" name="l01102"></a><span class="lineno"> 1102</span>  <span class="comment">// This function invokes constructor just to please complier and silence</span></div>
<div class="line"><a id="l01103" name="l01103"></a><span class="lineno"> 1103</span>  <span class="comment">// warning. Is never called (but compiler thinks that it could).</span></div>
<div class="foldopen" id="foldopen01104" data-start="{" data-end="}">
<div class="line"><a id="l01104" name="l01104"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ae45134fc073d795ca426fc3d7cca6f80"> 1104</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ae45134fc073d795ca426fc3d7cca6f80">UglyFunctionToSilenceNvccWarning</a>() {</div>
<div class="line"><a id="l01105" name="l01105"></a><span class="lineno"> 1105</span>    <a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">InputsOutputs&lt;DataType&gt;</a> io(0, <span class="keyword">false</span>, <span class="keyword">false</span>, <span class="keyword">false</span>);</div>
<div class="line"><a id="l01106" name="l01106"></a><span class="lineno"> 1106</span>  }</div>
</div>
<div class="line"><a id="l01107" name="l01107"></a><span class="lineno"> 1107</span> </div>
<div class="line"><a id="l01108" name="l01108"></a><span class="lineno"> 1108</span> <span class="keyword">private</span>:</div>
<div class="line"><a id="l01109" name="l01109"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a8569c32a2f7f878f57f2a232b097dac8"> 1109</a></span>  <span class="keyword">const</span> <a class="code hl_struct" href="structlczero_1_1NetworkCapabilities.html">NetworkCapabilities</a> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8569c32a2f7f878f57f2a232b097dac8">capabilities_</a>;</div>
<div class="line"><a id="l01110" name="l01110"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d"> 1110</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">gpu_id_</a>;</div>
<div class="line"><a id="l01111" name="l01111"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a7203422407bcef3715a4b9fd9836e515"> 1111</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7203422407bcef3715a4b9fd9836e515">l2_cache_size_</a>;</div>
<div class="line"><a id="l01112" name="l01112"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ad2c0d5066570e1aa1b97873cf5da9bea"> 1112</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad2c0d5066570e1aa1b97873cf5da9bea">sm_count_</a>;</div>
<div class="line"><a id="l01113" name="l01113"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff"> 1113</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">max_batch_size_</a>;</div>
<div class="line"><a id="l01114" name="l01114"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a240b95efc1b5559d4ff8c5ce6faaad5c"> 1114</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a240b95efc1b5559d4ff8c5ce6faaad5c">min_batch_size_</a>;</div>
<div class="line"><a id="l01115" name="l01115"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a01699a1f6860cda41dfee54217b1862c"> 1115</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a01699a1f6860cda41dfee54217b1862c">enable_graph_capture_</a>;</div>
<div class="line"><a id="l01116" name="l01116"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de"> 1116</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">wdl_</a>;</div>
<div class="line"><a id="l01117" name="l01117"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824"> 1117</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">moves_left_</a>;</div>
<div class="line"><a id="l01118" name="l01118"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c"> 1118</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">use_res_block_winograd_fuse_opt_</a>;  <span class="comment">// fuse operations inside the residual</span></div>
<div class="line"><a id="l01119" name="l01119"></a><span class="lineno"> 1119</span>                                          <span class="comment">// tower</span></div>
<div class="line"><a id="l01120" name="l01120"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee"> 1120</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">multi_stream_</a>;                     <span class="comment">// run multiple parallel network evals</span></div>
<div class="line"><a id="l01121" name="l01121"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ae27e343d2c18e3ecd492101c33d24239"> 1121</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae27e343d2c18e3ecd492101c33d24239">allow_cache_opt_</a>;  <span class="comment">// try to fit residual block activations in L2 cache</span></div>
<div class="line"><a id="l01122" name="l01122"></a><span class="lineno"> 1122</span> </div>
<div class="line"><a id="l01123" name="l01123"></a><span class="lineno"> 1123</span>  <span class="comment">// Currently only one NN Eval can happen a time (we can fix this if needed</span></div>
<div class="line"><a id="l01124" name="l01124"></a><span class="lineno"> 1124</span>  <span class="comment">// by allocating more memory).</span></div>
<div class="line"><a id="l01125" name="l01125"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a1fe4bf7e630779253e4c7f7f7b1d0821"> 1125</a></span>  <span class="keyword">mutable</span> std::mutex <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1fe4bf7e630779253e4c7f7f7b1d0821">lock_</a>;</div>
<div class="line"><a id="l01126" name="l01126"></a><span class="lineno"> 1126</span> </div>
<div class="line"><a id="l01127" name="l01127"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d"> 1127</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">numBlocks_</a>;</div>
<div class="line"><a id="l01128" name="l01128"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ace0225a707963a917029a40ba0a96ece"> 1128</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ace0225a707963a917029a40ba0a96ece">numFilters_</a>;</div>
<div class="line"><a id="l01129" name="l01129"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a09ba6230578a4bb53a0acd260c3eb515"> 1129</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a09ba6230578a4bb53a0acd260c3eb515">has_se_</a>;</div>
<div class="line"><a id="l01130" name="l01130"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a1b16fc6e42242f982303703bbfa55340"> 1130</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1b16fc6e42242f982303703bbfa55340">conv_policy_</a>;</div>
<div class="line"><a id="l01131" name="l01131"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ae017cf365d571ddb91a223a3e7c48a0f"> 1131</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae017cf365d571ddb91a223a3e7c48a0f">attn_policy_</a>;</div>
<div class="line"><a id="l01132" name="l01132"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130"> 1132</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">attn_body_</a>;</div>
<div class="line"><a id="l01133" name="l01133"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#acdd66225ad7c652e33a47accfdc411e8"> 1133</a></span>  <span class="keywordtype">int</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acdd66225ad7c652e33a47accfdc411e8">num_encoder_blocks_</a>;</div>
<div class="line"><a id="l01134" name="l01134"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3"> 1134</a></span>  std::vector&lt;std::unique_ptr&lt;BaseLayer&lt;DataType&gt;&gt;&gt; <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>;</div>
<div class="line"><a id="l01135" name="l01135"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4"> 1135</a></span>  <a class="code hl_class" href="classlczero_1_1cudnn__backend_1_1BaseLayer.html">BaseLayer&lt;DataType&gt;</a>* <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">getLastLayer</a>() { <span class="keywordflow">return</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">network_</a>.back().get(); }</div>
<div class="line"><a id="l01136" name="l01136"></a><span class="lineno"> 1136</span> </div>
<div class="line"><a id="l01137" name="l01137"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9"> 1137</a></span>  <a class="code hl_class" href="classlczero_1_1cudnn__backend_1_1BaseLayer.html">BaseLayer&lt;DataType&gt;</a>* <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9">resi_last_</a>;</div>
<div class="line"><a id="l01138" name="l01138"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a07e2823f1a2f64f1fc684e1ec5859ae9"> 1138</a></span>  <a class="code hl_class" href="classlczero_1_1cudnn__backend_1_1BaseLayer.html">BaseLayer&lt;DataType&gt;</a>* <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a07e2823f1a2f64f1fc684e1ec5859ae9">encoder_last_</a>;</div>
<div class="line"><a id="l01139" name="l01139"></a><span class="lineno"> 1139</span> </div>
<div class="line"><a id="l01140" name="l01140"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a9145d366464720a1f82f065bed9b0b32"> 1140</a></span>  <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9145d366464720a1f82f065bed9b0b32">tensor_mem_size_</a>;</div>
<div class="line"><a id="l01141" name="l01141"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29"> 1141</a></span>  <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">scratch_size_</a>;</div>
<div class="line"><a id="l01142" name="l01142"></a><span class="lineno"> 1142</span> </div>
<div class="line"><a id="l01143" name="l01143"></a><span class="lineno"> 1143</span>  <span class="comment">// this copy is used only for initialization when multi-stream is enabled</span></div>
<div class="line"><a id="l01144" name="l01144"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e"> 1144</a></span>  <span class="keywordtype">void</span>* <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">scratch_mem_</a>;</div>
<div class="line"><a id="l01145" name="l01145"></a><span class="lineno"> 1145</span>  <span class="comment">// this is only used when multi-stream is disabled</span></div>
<div class="line"><a id="l01146" name="l01146"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a9777fa5c5fe58d7eff4447cd7be0764b"> 1146</a></span>  <span class="keywordtype">void</span>** <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9777fa5c5fe58d7eff4447cd7be0764b">offset_pointers_</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l01147" name="l01147"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a41dbeae09f8028210d3115908711a0d3"> 1147</a></span>  <span class="keywordtype">void</span>** <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a41dbeae09f8028210d3115908711a0d3">head_offset_pointers_</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l01148" name="l01148"></a><span class="lineno"> 1148</span> </div>
<div class="line"><a id="l01149" name="l01149"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a20d84b728c194b4708c6de9fb82445b1"> 1149</a></span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a20d84b728c194b4708c6de9fb82445b1">has_tensor_cores_</a>;</div>
<div class="line"><a id="l01150" name="l01150"></a><span class="lineno"> 1150</span> </div>
<div class="line"><a id="l01151" name="l01151"></a><span class="lineno"> 1151</span>  <span class="comment">// not used when multi-steam is enabled</span></div>
<div class="line"><a id="l01152" name="l01152"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76"> 1152</a></span>  cudaStream_t <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">compute_stream_</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l01153" name="l01153"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668"> 1153</a></span>  cudaStream_t <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">upload_stream_</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l01154" name="l01154"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900"> 1154</a></span>  cudaStream_t <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900">download_stream_</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l01155" name="l01155"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6"> 1155</a></span>  cudaEvent_t <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6">compute_ordering_event_</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l01156" name="l01156"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54"> 1156</a></span>  cublasHandle_t <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">cublas_</a>;</div>
<div class="line"><a id="l01157" name="l01157"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a5827d93e06b1e2750fff7848894bdf2e"> 1157</a></span>  DataType* <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a5827d93e06b1e2750fff7848894bdf2e">tensor_mem_</a>[3];</div>
<div class="line"><a id="l01158" name="l01158"></a><span class="lineno"> 1158</span> </div>
<div class="line"><a id="l01159" name="l01159"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#a55b3652578313fe3b4ace6617f05b2c0"> 1159</a></span>  <span class="keyword">mutable</span> std::mutex <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#a55b3652578313fe3b4ace6617f05b2c0">inputs_outputs_lock_</a>;</div>
<div class="line"><a id="l01160" name="l01160"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ad4e9918939cfb8e524021339b08cfb44"> 1160</a></span>  std::list&lt;std::unique_ptr&lt;InputsOutputs&lt;DataType&gt;&gt;&gt; <a class="code hl_variable" href="classlczero_1_1CudaNetwork.html#ad4e9918939cfb8e524021339b08cfb44">free_inputs_outputs_</a>;</div>
<div class="line"><a id="l01161" name="l01161"></a><span class="lineno"> 1161</span> </div>
<div class="foldopen" id="foldopen01162" data-start="{" data-end="}">
<div class="line"><a id="l01162" name="l01162"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#ae4d5a550345de6b79b516b740871649f"> 1162</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#ae4d5a550345de6b79b516b740871649f">showInfo</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a id="l01163" name="l01163"></a><span class="lineno"> 1163</span>    <span class="keywordtype">int</span> version;</div>
<div class="line"><a id="l01164" name="l01164"></a><span class="lineno"> 1164</span>    <span class="keywordtype">int</span> ret = cudaRuntimeGetVersion(&amp;version);</div>
<div class="line"><a id="l01165" name="l01165"></a><span class="lineno"> 1165</span>    <span class="keywordflow">switch</span> (ret) {</div>
<div class="line"><a id="l01166" name="l01166"></a><span class="lineno"> 1166</span>      <span class="keywordflow">case</span> cudaErrorInitializationError:</div>
<div class="line"><a id="l01167" name="l01167"></a><span class="lineno"> 1167</span>        <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;CUDA driver and/or runtime could not be initialized&quot;</span>);</div>
<div class="line"><a id="l01168" name="l01168"></a><span class="lineno"> 1168</span>      <span class="keywordflow">case</span> cudaErrorInsufficientDriver:</div>
<div class="line"><a id="l01169" name="l01169"></a><span class="lineno"> 1169</span>        <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;No CUDA driver, or one older than the CUDA library&quot;</span>);</div>
<div class="line"><a id="l01170" name="l01170"></a><span class="lineno"> 1170</span>      <span class="keywordflow">case</span> cudaErrorNoDevice:</div>
<div class="line"><a id="l01171" name="l01171"></a><span class="lineno"> 1171</span>        <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;No CUDA-capable devices detected&quot;</span>);</div>
<div class="line"><a id="l01172" name="l01172"></a><span class="lineno"> 1172</span>    }</div>
<div class="line"><a id="l01173" name="l01173"></a><span class="lineno"> 1173</span>    <span class="keywordtype">int</span> major = version / 1000;</div>
<div class="line"><a id="l01174" name="l01174"></a><span class="lineno"> 1174</span>    <span class="keywordtype">int</span> minor = (version - major * 1000) / 10;</div>
<div class="line"><a id="l01175" name="l01175"></a><span class="lineno"> 1175</span>    <span class="keywordtype">int</span> pl = version - major * 1000 - minor * 10;</div>
<div class="line"><a id="l01176" name="l01176"></a><span class="lineno"> 1176</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;CUDA Runtime version: &quot;</span> &lt;&lt; major &lt;&lt; <span class="stringliteral">&quot;.&quot;</span> &lt;&lt; minor &lt;&lt; <span class="stringliteral">&quot;.&quot;</span> &lt;&lt; pl;</div>
<div class="line"><a id="l01177" name="l01177"></a><span class="lineno"> 1177</span>    <span class="keywordflow">if</span> (version != CUDART_VERSION) {</div>
<div class="line"><a id="l01178" name="l01178"></a><span class="lineno"> 1178</span>      major = CUDART_VERSION / 1000;</div>
<div class="line"><a id="l01179" name="l01179"></a><span class="lineno"> 1179</span>      minor = (CUDART_VERSION - major * 1000) / 10;</div>
<div class="line"><a id="l01180" name="l01180"></a><span class="lineno"> 1180</span>      pl = CUDART_VERSION - major * 1000 - minor * 10;</div>
<div class="line"><a id="l01181" name="l01181"></a><span class="lineno"> 1181</span>      <span class="comment">// After cuda 11, newer version with same major is OK.</span></div>
<div class="line"><a id="l01182" name="l01182"></a><span class="lineno"> 1182</span>      <span class="keywordflow">if</span> (major &lt; 11 || (major != version / 1000) || version &lt; CUDART_VERSION) {</div>
<div class="line"><a id="l01183" name="l01183"></a><span class="lineno"> 1183</span>        <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;WARNING: CUDA Runtime version mismatch, was compiled with &quot;</span></div>
<div class="line"><a id="l01184" name="l01184"></a><span class="lineno"> 1184</span>                <span class="stringliteral">&quot;version &quot;</span></div>
<div class="line"><a id="l01185" name="l01185"></a><span class="lineno"> 1185</span>             &lt;&lt; major &lt;&lt; <span class="stringliteral">&quot;.&quot;</span> &lt;&lt; minor &lt;&lt; <span class="stringliteral">&quot;.&quot;</span> &lt;&lt; pl;</div>
<div class="line"><a id="l01186" name="l01186"></a><span class="lineno"> 1186</span>      }</div>
<div class="line"><a id="l01187" name="l01187"></a><span class="lineno"> 1187</span>    }</div>
<div class="line"><a id="l01188" name="l01188"></a><span class="lineno"> 1188</span>    cudaDriverGetVersion(&amp;version);</div>
<div class="line"><a id="l01189" name="l01189"></a><span class="lineno"> 1189</span>    major = version / 1000;</div>
<div class="line"><a id="l01190" name="l01190"></a><span class="lineno"> 1190</span>    minor = (version - major * 1000) / 10;</div>
<div class="line"><a id="l01191" name="l01191"></a><span class="lineno"> 1191</span>    pl = version - major * 1000 - minor * 10;</div>
<div class="line"><a id="l01192" name="l01192"></a><span class="lineno"> 1192</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;Latest version of CUDA supported by the driver: &quot;</span> &lt;&lt; major &lt;&lt; <span class="stringliteral">&quot;.&quot;</span></div>
<div class="line"><a id="l01193" name="l01193"></a><span class="lineno"> 1193</span>         &lt;&lt; minor &lt;&lt; <span class="stringliteral">&quot;.&quot;</span> &lt;&lt; pl;</div>
<div class="line"><a id="l01194" name="l01194"></a><span class="lineno"> 1194</span>    <span class="keywordflow">if</span> (version &lt; CUDART_VERSION) {</div>
<div class="line"><a id="l01195" name="l01195"></a><span class="lineno"> 1195</span>      <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;WARNING: code was compiled with unsupported CUDA version.&quot;</span>;</div>
<div class="line"><a id="l01196" name="l01196"></a><span class="lineno"> 1196</span>    }</div>
<div class="line"><a id="l01197" name="l01197"></a><span class="lineno"> 1197</span>  }</div>
</div>
<div class="line"><a id="l01198" name="l01198"></a><span class="lineno"> 1198</span> </div>
<div class="foldopen" id="foldopen01199" data-start="{" data-end="}">
<div class="line"><a id="l01199" name="l01199"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetwork.html#af647744ff0e16fa1875f0b2e9504c8f8"> 1199</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetwork.html#af647744ff0e16fa1875f0b2e9504c8f8">showDeviceInfo</a>(<span class="keyword">const</span> cudaDeviceProp&amp; deviceProp,</div>
<div class="line"><a id="l01200" name="l01200"></a><span class="lineno"> 1200</span>                      [[maybe_unused]] <span class="keywordtype">int</span> deviceId)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l01201" name="l01201"></a><span class="lineno"> 1201</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;GPU: &quot;</span> &lt;&lt; deviceProp.name;</div>
<div class="line"><a id="l01202" name="l01202"></a><span class="lineno"> 1202</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;GPU memory: &quot;</span> &lt;&lt; deviceProp.totalGlobalMem / std::pow(2.0f, 30)</div>
<div class="line"><a id="l01203" name="l01203"></a><span class="lineno"> 1203</span>         &lt;&lt; <span class="stringliteral">&quot; Gb&quot;</span>;</div>
<div class="line"><a id="l01204" name="l01204"></a><span class="lineno"> 1204</span>    <span class="comment">// Get clock rate</span></div>
<div class="line"><a id="l01205" name="l01205"></a><span class="lineno"> 1205</span>    <span class="keywordtype">float</span> clockRateMHz;</div>
<div class="line"><a id="l01206" name="l01206"></a><span class="lineno"> 1206</span><span class="preprocessor">#if CUDART_VERSION &gt;= 13000</span></div>
<div class="line"><a id="l01207" name="l01207"></a><span class="lineno"> 1207</span>    <span class="keywordtype">int</span> clockRatekHz;</div>
<div class="line"><a id="l01208" name="l01208"></a><span class="lineno"> 1208</span>    cudaError_t err =</div>
<div class="line"><a id="l01209" name="l01209"></a><span class="lineno"> 1209</span>        cudaDeviceGetAttribute(&amp;clockRatekHz, cudaDevAttrClockRate, deviceId);</div>
<div class="line"><a id="l01210" name="l01210"></a><span class="lineno"> 1210</span>    <span class="keywordflow">if</span> (err != cudaSuccess) {</div>
<div class="line"><a id="l01211" name="l01211"></a><span class="lineno"> 1211</span>      <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;Error getting clock rate: &quot;</span> &lt;&lt; cudaGetErrorString(err);</div>
<div class="line"><a id="l01212" name="l01212"></a><span class="lineno"> 1212</span>      clockRateMHz = 0.0f;  <span class="comment">// Fallback value</span></div>
<div class="line"><a id="l01213" name="l01213"></a><span class="lineno"> 1213</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l01214" name="l01214"></a><span class="lineno"> 1214</span>      clockRateMHz = clockRatekHz / 1e3f;</div>
<div class="line"><a id="l01215" name="l01215"></a><span class="lineno"> 1215</span>    }</div>
<div class="line"><a id="l01216" name="l01216"></a><span class="lineno"> 1216</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l01217" name="l01217"></a><span class="lineno"> 1217</span>    clockRateMHz = deviceProp.clockRate / 1e3f;</div>
<div class="line"><a id="l01218" name="l01218"></a><span class="lineno"> 1218</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l01219" name="l01219"></a><span class="lineno"> 1219</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;GPU clock frequency: &quot;</span> &lt;&lt; clockRateMHz &lt;&lt; <span class="stringliteral">&quot; MHz&quot;</span>;</div>
<div class="line"><a id="l01220" name="l01220"></a><span class="lineno"> 1220</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;GPU compute capability: &quot;</span> &lt;&lt; deviceProp.major &lt;&lt; <span class="stringliteral">&quot;.&quot;</span></div>
<div class="line"><a id="l01221" name="l01221"></a><span class="lineno"> 1221</span>         &lt;&lt; deviceProp.minor;</div>
<div class="line"><a id="l01222" name="l01222"></a><span class="lineno"> 1222</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;L2 cache capacity: &quot;</span> &lt;&lt; deviceProp.l2CacheSize;</div>
<div class="line"><a id="l01223" name="l01223"></a><span class="lineno"> 1223</span>    <span class="keywordflow">if</span> (std::is_same&lt;float, DataType&gt;::value &amp;&amp; deviceProp.major &gt;= 7) {</div>
<div class="line"><a id="l01224" name="l01224"></a><span class="lineno"> 1224</span>      <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;WARNING: you will probably get better performance from the &quot;</span></div>
<div class="line"><a id="l01225" name="l01225"></a><span class="lineno"> 1225</span>              <span class="stringliteral">&quot;cuda-fp16 backend.&quot;</span>;</div>
<div class="line"><a id="l01226" name="l01226"></a><span class="lineno"> 1226</span>    }</div>
<div class="line"><a id="l01227" name="l01227"></a><span class="lineno"> 1227</span>  }</div>
</div>
<div class="line"><a id="l01228" name="l01228"></a><span class="lineno"> 1228</span>};</div>
</div>
<div class="line"><a id="l01229" name="l01229"></a><span class="lineno"> 1229</span> </div>
<div class="line"><a id="l01230" name="l01230"></a><span class="lineno"> 1230</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="foldopen" id="foldopen01231" data-start="{" data-end="}">
<div class="line"><a id="l01231" name="l01231"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a83439fbc9dd4cd235c33c2b6a4ce3c4e"> 1231</a></span><a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a83439fbc9dd4cd235c33c2b6a4ce3c4e">CudaNetworkComputation&lt;DataType&gt;::CudaNetworkComputation</a>(</div>
<div class="line"><a id="l01232" name="l01232"></a><span class="lineno"> 1232</span>    <a class="code hl_class" href="classlczero_1_1CudaNetwork.html">CudaNetwork&lt;DataType&gt;</a>* network, <span class="keywordtype">bool</span> wdl, <span class="keywordtype">bool</span> moves_left)</div>
<div class="line"><a id="l01233" name="l01233"></a><span class="lineno"> 1233</span>    : <a class="code hl_variable" href="network__blas_8cc.html#a705d0a7ba8d3c6c61f9486a9e37c0197">wdl_</a>(wdl), <a class="code hl_variable" href="network__blas_8cc.html#a5962f2d981f098ad69c81771db5452da">moves_left_</a>(moves_left), <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>(network) {</div>
<div class="line"><a id="l01234" name="l01234"></a><span class="lineno"> 1234</span>  <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">batch_size_</a> = 0;</div>
<div class="line"><a id="l01235" name="l01235"></a><span class="lineno"> 1235</span>  <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">inputs_outputs_</a> = <a class="code hl_variable" href="classlczero_1_1CudaNetworkComputation.html#ab16d8a24586379a53268bc760f6db4fe">network_</a>-&gt;GetInputsOutputs();</div>
<div class="line"><a id="l01236" name="l01236"></a><span class="lineno"> 1236</span>}</div>
</div>
<div class="line"><a id="l01237" name="l01237"></a><span class="lineno"> 1237</span> </div>
<div class="line"><a id="l01238" name="l01238"></a><span class="lineno"> 1238</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="foldopen" id="foldopen01239" data-start="{" data-end="}">
<div class="line"><a id="l01239" name="l01239"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#ae90593942136474f6b3e73520e9e5097"> 1239</a></span><a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#ae90593942136474f6b3e73520e9e5097">CudaNetworkComputation&lt;DataType&gt;::~CudaNetworkComputation</a>() {</div>
<div class="line"><a id="l01240" name="l01240"></a><span class="lineno"> 1240</span>  <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;ReleaseInputsOutputs(std::move(inputs_outputs_));</div>
<div class="line"><a id="l01241" name="l01241"></a><span class="lineno"> 1241</span>}</div>
</div>
<div class="line"><a id="l01242" name="l01242"></a><span class="lineno"> 1242</span> </div>
<div class="line"><a id="l01243" name="l01243"></a><span class="lineno"> 1243</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="foldopen" id="foldopen01244" data-start="{" data-end="}">
<div class="line"><a id="l01244" name="l01244"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#abef905f0b31b30dbe835e13a23a3c166"> 1244</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#abef905f0b31b30dbe835e13a23a3c166">CudaNetworkComputation&lt;DataType&gt;::CaptureGraph</a>(</div>
<div class="line"><a id="l01245" name="l01245"></a><span class="lineno"> 1245</span>    std::unique_lock&lt;std::mutex&gt;&amp;&amp; lock) {</div>
<div class="line"><a id="l01246" name="l01246"></a><span class="lineno"> 1246</span>  <span class="keywordflow">if</span> (!<a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;GetGraphCaptureEnabled()) <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l01247" name="l01247"></a><span class="lineno"> 1247</span>  <span class="keywordflow">if</span> (!<a class="code hl_struct" href="structlczero_1_1cudnn__backend_1_1CudaGraphCapture.html">CudaGraphCapture&lt;DataType&gt;::EnsureEnoughFreeMemory</a>()) {</div>
<div class="line"><a id="l01248" name="l01248"></a><span class="lineno"> 1248</span>    <span class="keyword">static</span> std::once_flag flag;</div>
<div class="line"><a id="l01249" name="l01249"></a><span class="lineno"> 1249</span>    std::call_once(flag, []() {</div>
<div class="line"><a id="l01250" name="l01250"></a><span class="lineno"> 1250</span>      <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;WARNING: Not enough GPU memory to capture CUDA graphs.&quot;</span>;</div>
<div class="line"><a id="l01251" name="l01251"></a><span class="lineno"> 1251</span>    });</div>
<div class="line"><a id="l01252" name="l01252"></a><span class="lineno"> 1252</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l01253" name="l01253"></a><span class="lineno"> 1253</span>  }</div>
<div class="line"><a id="l01254" name="l01254"></a><span class="lineno"> 1254</span>  <span class="keyword">auto</span> capture = <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;BeginCapture(*inputs_outputs_);</div>
<div class="line"><a id="l01255" name="l01255"></a><span class="lineno"> 1255</span>  <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;forwardEval(inputs_outputs_.get(), GetBatchSize(), <span class="keyword">true</span>);</div>
<div class="line"><a id="l01256" name="l01256"></a><span class="lineno"> 1256</span>  capture.EndCapture();</div>
<div class="line"><a id="l01257" name="l01257"></a><span class="lineno"> 1257</span>  <span class="keywordflow">if</span> (lock.owns_lock()) lock.unlock();</div>
<div class="line"><a id="l01258" name="l01258"></a><span class="lineno"> 1258</span>  inputs_outputs_-&gt;cuda_graphs_[GetBatchSize() - 1] = capture;</div>
<div class="line"><a id="l01259" name="l01259"></a><span class="lineno"> 1259</span>}</div>
</div>
<div class="line"><a id="l01260" name="l01260"></a><span class="lineno"> 1260</span> </div>
<div class="line"><a id="l01261" name="l01261"></a><span class="lineno"> 1261</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="foldopen" id="foldopen01262" data-start="{" data-end="}">
<div class="line"><a id="l01262" name="l01262"></a><span class="lineno"><a class="line" href="classlczero_1_1CudaNetworkComputation.html#a2c13d328c17e7f3a5ba6d488b800a6e4"> 1262</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classlczero_1_1CudaNetworkComputation.html#a2c13d328c17e7f3a5ba6d488b800a6e4">CudaNetworkComputation&lt;DataType&gt;::ComputeBlocking</a>() {</div>
<div class="line"><a id="l01263" name="l01263"></a><span class="lineno"> 1263</span>  <a class="code hl_define" href="trace_8h.html#a389db795981333907e77e3454e1fcbf3">LCTRACE_FUNCTION_SCOPE</a>;</div>
<div class="line"><a id="l01264" name="l01264"></a><span class="lineno"> 1264</span>  assert(GetBatchSize() &gt;= 1);</div>
<div class="line"><a id="l01265" name="l01265"></a><span class="lineno"> 1265</span>  <span class="keywordflow">if</span> (inputs_outputs_-&gt;cuda_graphs_[GetBatchSize() - 1]) {</div>
<div class="line"><a id="l01266" name="l01266"></a><span class="lineno"> 1266</span>    std::unique_lock&lt;std::mutex&gt; lock = <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;LockEval();</div>
<div class="line"><a id="l01267" name="l01267"></a><span class="lineno"> 1267</span>    <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;GraphLaunch(inputs_outputs_.get(), GetBatchSize());</div>
<div class="line"><a id="l01268" name="l01268"></a><span class="lineno"> 1268</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l01269" name="l01269"></a><span class="lineno"> 1269</span>    std::unique_lock&lt;std::mutex&gt; lock = <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;LockEval();</div>
<div class="line"><a id="l01270" name="l01270"></a><span class="lineno"> 1270</span><span class="preprocessor">#if !CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</span></div>
<div class="line"><a id="l01271" name="l01271"></a><span class="lineno"> 1271</span>    <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;UploadInputs(inputs_outputs_.get(), GetBatchSize());</div>
<div class="line"><a id="l01272" name="l01272"></a><span class="lineno"> 1272</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l01273" name="l01273"></a><span class="lineno"> 1273</span>    <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;forwardEval(inputs_outputs_.get(), GetBatchSize());</div>
<div class="line"><a id="l01274" name="l01274"></a><span class="lineno"> 1274</span>    CaptureGraph(std::move(lock));</div>
<div class="line"><a id="l01275" name="l01275"></a><span class="lineno"> 1275</span>  }</div>
<div class="line"><a id="l01276" name="l01276"></a><span class="lineno"> 1276</span>  <a class="code hl_variable" href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a>-&gt;finishEval(inputs_outputs_.get(), GetBatchSize());</div>
<div class="line"><a id="l01277" name="l01277"></a><span class="lineno"> 1277</span>}</div>
</div>
<div class="line"><a id="l01278" name="l01278"></a><span class="lineno"> 1278</span> </div>
<div class="line"><a id="l01279" name="l01279"></a><span class="lineno"> 1279</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DataType&gt;</div>
<div class="foldopen" id="foldopen01280" data-start="{" data-end="}">
<div class="line"><a id="l01280" name="l01280"></a><span class="lineno"><a class="line" href="namespacelczero.html#ace425dcea6ffa6a3da929f5ddf79d907"> 1280</a></span>std::unique_ptr&lt;Network&gt; <a class="code hl_function" href="namespacelczero.html#ace425dcea6ffa6a3da929f5ddf79d907">MakeCudaNetwork</a>(<span class="keyword">const</span> std::optional&lt;WeightsFile&gt;&amp; w,</div>
<div class="line"><a id="l01281" name="l01281"></a><span class="lineno"> 1281</span>                                         <span class="keyword">const</span> <a class="code hl_class" href="classlczero_1_1OptionsDict.html">OptionsDict</a>&amp; options) {</div>
<div class="line"><a id="l01282" name="l01282"></a><span class="lineno"> 1282</span>  <span class="keywordflow">if</span> (!w) {</div>
<div class="line"><a id="l01283" name="l01283"></a><span class="lineno"> 1283</span>    <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(</div>
<div class="line"><a id="l01284" name="l01284"></a><span class="lineno"> 1284</span>        <span class="stringliteral">&quot;The cuda&quot;</span> +</div>
<div class="line"><a id="l01285" name="l01285"></a><span class="lineno"> 1285</span>        std::string(std::is_same&lt;half, DataType&gt;::value ? <span class="stringliteral">&quot;-fp16&quot;</span> : <span class="stringliteral">&quot;&quot;</span>) +</div>
<div class="line"><a id="l01286" name="l01286"></a><span class="lineno"> 1286</span>        <span class="stringliteral">&quot; backend requires a network file.&quot;</span>);</div>
<div class="line"><a id="l01287" name="l01287"></a><span class="lineno"> 1287</span>  }</div>
<div class="line"><a id="l01288" name="l01288"></a><span class="lineno"> 1288</span>  <span class="keyword">const</span> <a class="code hl_typedef" href="namespacelczero.html#a6705e82c4f5d6edcac8d0ca3b2240b29">WeightsFile</a>&amp; weights = *w;</div>
<div class="line"><a id="l01289" name="l01289"></a><span class="lineno"> 1289</span>  <span class="keyword">auto</span> nf = weights.format().network_format();</div>
<div class="line"><a id="l01290" name="l01290"></a><span class="lineno"> 1290</span>  <span class="keyword">using </span>NF = pblczero::NetworkFormat;</div>
<div class="line"><a id="l01291" name="l01291"></a><span class="lineno"> 1291</span>  <span class="keywordflow">switch</span> (nf.network()) {</div>
<div class="line"><a id="l01292" name="l01292"></a><span class="lineno"> 1292</span>    <span class="keywordflow">case</span> NF::NETWORK_CLASSICAL_WITH_HEADFORMAT:</div>
<div class="line"><a id="l01293" name="l01293"></a><span class="lineno"> 1293</span>    <span class="keywordflow">case</span> NF::NETWORK_SE_WITH_HEADFORMAT:</div>
<div class="line"><a id="l01294" name="l01294"></a><span class="lineno"> 1294</span>    <span class="keywordflow">case</span> NF::NETWORK_ATTENTIONBODY_WITH_HEADFORMAT:</div>
<div class="line"><a id="l01295" name="l01295"></a><span class="lineno"> 1295</span>    <span class="keywordflow">case</span> NF::NETWORK_ATTENTIONBODY_WITH_MULTIHEADFORMAT:</div>
<div class="line"><a id="l01296" name="l01296"></a><span class="lineno"> 1296</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l01297" name="l01297"></a><span class="lineno"> 1297</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l01298" name="l01298"></a><span class="lineno"> 1298</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Network format &quot;</span> +</div>
<div class="line"><a id="l01299" name="l01299"></a><span class="lineno"> 1299</span>                      NF::NetworkStructure_Name(nf.network()) +</div>
<div class="line"><a id="l01300" name="l01300"></a><span class="lineno"> 1300</span>                      <span class="stringliteral">&quot; is not supported by the CUDA backend.&quot;</span>);</div>
<div class="line"><a id="l01301" name="l01301"></a><span class="lineno"> 1301</span>  }</div>
<div class="line"><a id="l01302" name="l01302"></a><span class="lineno"> 1302</span>  <span class="keywordflow">switch</span> (nf.policy()) {</div>
<div class="line"><a id="l01303" name="l01303"></a><span class="lineno"> 1303</span>    <span class="keywordflow">case</span> NF::POLICY_CLASSICAL:</div>
<div class="line"><a id="l01304" name="l01304"></a><span class="lineno"> 1304</span>    <span class="keywordflow">case</span> NF::POLICY_CONVOLUTION:</div>
<div class="line"><a id="l01305" name="l01305"></a><span class="lineno"> 1305</span>    <span class="keywordflow">case</span> NF::POLICY_ATTENTION:</div>
<div class="line"><a id="l01306" name="l01306"></a><span class="lineno"> 1306</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l01307" name="l01307"></a><span class="lineno"> 1307</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l01308" name="l01308"></a><span class="lineno"> 1308</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Policy format &quot;</span> + NF::PolicyFormat_Name(nf.policy()) +</div>
<div class="line"><a id="l01309" name="l01309"></a><span class="lineno"> 1309</span>                      <span class="stringliteral">&quot; is not supported by the CUDA backend.&quot;</span>);</div>
<div class="line"><a id="l01310" name="l01310"></a><span class="lineno"> 1310</span>  }</div>
<div class="line"><a id="l01311" name="l01311"></a><span class="lineno"> 1311</span>  <span class="keywordflow">switch</span> (nf.value()) {</div>
<div class="line"><a id="l01312" name="l01312"></a><span class="lineno"> 1312</span>    <span class="keywordflow">case</span> NF::VALUE_CLASSICAL:</div>
<div class="line"><a id="l01313" name="l01313"></a><span class="lineno"> 1313</span>    <span class="keywordflow">case</span> NF::VALUE_WDL:</div>
<div class="line"><a id="l01314" name="l01314"></a><span class="lineno"> 1314</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l01315" name="l01315"></a><span class="lineno"> 1315</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l01316" name="l01316"></a><span class="lineno"> 1316</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Value format &quot;</span> + NF::ValueFormat_Name(nf.value()) +</div>
<div class="line"><a id="l01317" name="l01317"></a><span class="lineno"> 1317</span>                      <span class="stringliteral">&quot; is not supported by the CUDA backend.&quot;</span>);</div>
<div class="line"><a id="l01318" name="l01318"></a><span class="lineno"> 1318</span>  }</div>
<div class="line"><a id="l01319" name="l01319"></a><span class="lineno"> 1319</span>  <span class="keywordflow">switch</span> (nf.moves_left()) {</div>
<div class="line"><a id="l01320" name="l01320"></a><span class="lineno"> 1320</span>    <span class="keywordflow">case</span> NF::MOVES_LEFT_NONE:</div>
<div class="line"><a id="l01321" name="l01321"></a><span class="lineno"> 1321</span>    <span class="keywordflow">case</span> NF::MOVES_LEFT_V1:</div>
<div class="line"><a id="l01322" name="l01322"></a><span class="lineno"> 1322</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l01323" name="l01323"></a><span class="lineno"> 1323</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l01324" name="l01324"></a><span class="lineno"> 1324</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Moves left head format &quot;</span> +</div>
<div class="line"><a id="l01325" name="l01325"></a><span class="lineno"> 1325</span>                      NF::MovesLeftFormat_Name(nf.moves_left()) +</div>
<div class="line"><a id="l01326" name="l01326"></a><span class="lineno"> 1326</span>                      <span class="stringliteral">&quot; is not supported by the CUDA backend.&quot;</span>);</div>
<div class="line"><a id="l01327" name="l01327"></a><span class="lineno"> 1327</span>  }</div>
<div class="line"><a id="l01328" name="l01328"></a><span class="lineno"> 1328</span>  <span class="keywordflow">switch</span> (nf.default_activation()) {</div>
<div class="line"><a id="l01329" name="l01329"></a><span class="lineno"> 1329</span>    <span class="keywordflow">case</span> NF::DEFAULT_ACTIVATION_RELU:</div>
<div class="line"><a id="l01330" name="l01330"></a><span class="lineno"> 1330</span>    <span class="keywordflow">case</span> NF::DEFAULT_ACTIVATION_MISH:</div>
<div class="line"><a id="l01331" name="l01331"></a><span class="lineno"> 1331</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l01332" name="l01332"></a><span class="lineno"> 1332</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l01333" name="l01333"></a><span class="lineno"> 1333</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Default activation &quot;</span> +</div>
<div class="line"><a id="l01334" name="l01334"></a><span class="lineno"> 1334</span>                      NF::DefaultActivation_Name(nf.default_activation()) +</div>
<div class="line"><a id="l01335" name="l01335"></a><span class="lineno"> 1335</span>                      <span class="stringliteral">&quot; is not supported by the CUDA backend.&quot;</span>);</div>
<div class="line"><a id="l01336" name="l01336"></a><span class="lineno"> 1336</span>  }</div>
<div class="line"><a id="l01337" name="l01337"></a><span class="lineno"> 1337</span>  <span class="keywordflow">switch</span> (nf.input_embedding()) {</div>
<div class="line"><a id="l01338" name="l01338"></a><span class="lineno"> 1338</span>    <span class="keywordflow">case</span> NF::INPUT_EMBEDDING_NONE:</div>
<div class="line"><a id="l01339" name="l01339"></a><span class="lineno"> 1339</span>    <span class="keywordflow">case</span> NF::INPUT_EMBEDDING_PE_MAP:</div>
<div class="line"><a id="l01340" name="l01340"></a><span class="lineno"> 1340</span>    <span class="keywordflow">case</span> NF::INPUT_EMBEDDING_PE_DENSE:</div>
<div class="line"><a id="l01341" name="l01341"></a><span class="lineno"> 1341</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l01342" name="l01342"></a><span class="lineno"> 1342</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l01343" name="l01343"></a><span class="lineno"> 1343</span>      <span class="keywordflow">throw</span> <a class="code hl_class" href="classlczero_1_1Exception.html">Exception</a>(<span class="stringliteral">&quot;Input embedding &quot;</span> +</div>
<div class="line"><a id="l01344" name="l01344"></a><span class="lineno"> 1344</span>                      NF::InputEmbeddingFormat_Name(nf.input_embedding()) +</div>
<div class="line"><a id="l01345" name="l01345"></a><span class="lineno"> 1345</span>                      <span class="stringliteral">&quot; is not supported by the CUDA backend.&quot;</span>);</div>
<div class="line"><a id="l01346" name="l01346"></a><span class="lineno"> 1346</span>  }</div>
<div class="line"><a id="l01347" name="l01347"></a><span class="lineno"> 1347</span>  <span class="keywordflow">return</span> std::make_unique&lt;CudaNetwork&lt;DataType&gt;&gt;(weights, options);</div>
<div class="line"><a id="l01348" name="l01348"></a><span class="lineno"> 1348</span>}</div>
</div>
<div class="line"><a id="l01349" name="l01349"></a><span class="lineno"> 1349</span> </div>
<div class="foldopen" id="foldopen01350" data-start="{" data-end="}">
<div class="line"><a id="l01350" name="l01350"></a><span class="lineno"><a class="line" href="namespacelczero.html#a50ba8cd031e94ed714f45910053d6570"> 1350</a></span>std::unique_ptr&lt;Network&gt; <a class="code hl_function" href="namespacelczero.html#a50ba8cd031e94ed714f45910053d6570">MakeCudaNetworkAuto</a>(</div>
<div class="line"><a id="l01351" name="l01351"></a><span class="lineno"> 1351</span>    <span class="keyword">const</span> std::optional&lt;WeightsFile&gt;&amp; weights, <span class="keyword">const</span> <a class="code hl_class" href="classlczero_1_1OptionsDict.html">OptionsDict</a>&amp; options) {</div>
<div class="line"><a id="l01352" name="l01352"></a><span class="lineno"> 1352</span>  <span class="keywordtype">int</span> gpu_id = options.<a class="code hl_function" href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">GetOrDefault</a>&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;gpu&quot;</span>, 0);</div>
<div class="line"><a id="l01353" name="l01353"></a><span class="lineno"> 1353</span>  cudaDeviceProp deviceProp = {};</div>
<div class="line"><a id="l01354" name="l01354"></a><span class="lineno"> 1354</span>  <span class="comment">// No error checking here, this will be repeated later.</span></div>
<div class="line"><a id="l01355" name="l01355"></a><span class="lineno"> 1355</span>  cudaGetDeviceProperties(&amp;deviceProp, gpu_id);</div>
<div class="line"><a id="l01356" name="l01356"></a><span class="lineno"> 1356</span> </div>
<div class="line"><a id="l01357" name="l01357"></a><span class="lineno"> 1357</span>  <span class="comment">// Check if the GPU supports FP16.</span></div>
<div class="line"><a id="l01358" name="l01358"></a><span class="lineno"> 1358</span>  <span class="keywordflow">if</span> (deviceProp.major &gt;= 7 ||</div>
<div class="line"><a id="l01359" name="l01359"></a><span class="lineno"> 1359</span>      (deviceProp.major == 6 &amp;&amp; deviceProp.minor != 1) ||</div>
<div class="line"><a id="l01360" name="l01360"></a><span class="lineno"> 1360</span>      (deviceProp.major == 5 &amp;&amp; deviceProp.minor == 3)) {</div>
<div class="line"><a id="l01361" name="l01361"></a><span class="lineno"> 1361</span>    <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;Switching to [cuda-fp16]...&quot;</span>;</div>
<div class="line"><a id="l01362" name="l01362"></a><span class="lineno"> 1362</span>    <span class="keywordflow">return</span> MakeCudaNetwork&lt;half&gt;(weights, options);</div>
<div class="line"><a id="l01363" name="l01363"></a><span class="lineno"> 1363</span>  }</div>
<div class="line"><a id="l01364" name="l01364"></a><span class="lineno"> 1364</span>  <a class="code hl_define" href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a> &lt;&lt; <span class="stringliteral">&quot;Switching to [cuda]...&quot;</span>;</div>
<div class="line"><a id="l01365" name="l01365"></a><span class="lineno"> 1365</span>  <span class="keywordflow">return</span> MakeCudaNetwork&lt;float&gt;(weights, options);</div>
<div class="line"><a id="l01366" name="l01366"></a><span class="lineno"> 1366</span>}</div>
</div>
<div class="line"><a id="l01367" name="l01367"></a><span class="lineno"> 1367</span> </div>
<div class="line"><a id="l01368" name="l01368"></a><span class="lineno"> 1368</span><a class="code hl_define" href="neural_2factory_8h.html#af219bf322aa35924d378cd40e2c314de">REGISTER_NETWORK</a>(<span class="stringliteral">&quot;cuda-auto&quot;</span>, <a class="code hl_function" href="namespacelczero.html#a50ba8cd031e94ed714f45910053d6570">MakeCudaNetworkAuto</a>, 104)</div>
<div class="line"><a id="l01369" name="l01369"></a><span class="lineno"> 1369</span><a class="code hl_define" href="neural_2factory_8h.html#af219bf322aa35924d378cd40e2c314de">REGISTER_NETWORK</a>(&quot;cuda&quot;, <a class="code hl_function" href="namespacelczero.html#ace425dcea6ffa6a3da929f5ddf79d907">MakeCudaNetwork</a>&lt;<span class="keywordtype">float</span>&gt;, 103)</div>
<div class="line"><a id="l01370" name="l01370"></a><span class="lineno"> 1370</span><a class="code hl_define" href="neural_2factory_8h.html#af219bf322aa35924d378cd40e2c314de">REGISTER_NETWORK</a>(&quot;cuda-fp16&quot;, <a class="code hl_function" href="namespacelczero.html#ace425dcea6ffa6a3da929f5ddf79d907">MakeCudaNetwork</a>&lt;half&gt;, 102)</div>
<div class="line"><a id="l01371" name="l01371"></a><span class="lineno"> 1371</span> </div>
<div class="line"><a id="l01372" name="l01372"></a><span class="lineno"> 1372</span>}  <span class="comment">// namespace lczero</span></div>
<div class="ttc" id="aWinogradCommon_8h_html_aba9cd67e67fe1d1e46c1f273b3e68d67"><div class="ttname"><a href="WinogradCommon_8h.html#aba9cd67e67fe1d1e46c1f273b3e68d67">input</a></div><div class="ttdeci">RWBuffer&lt; float4 &gt; input</div><div class="ttdef"><b>Definition</b> <a href="WinogradCommon_8h_source.html#l00048">WinogradCommon.h:48</a></div></div>
<div class="ttc" id="aWinogradCommon_8h_html_acdb1009d58a21974bf65d60a5ef9929e"><div class="ttname"><a href="WinogradCommon_8h.html#acdb1009d58a21974bf65d60a5ef9929e">output</a></div><div class="ttdeci">RWBuffer&lt; float4 &gt; output</div><div class="ttdef"><b>Definition</b> <a href="WinogradCommon_8h_source.html#l00052">WinogradCommon.h:52</a></div></div>
<div class="ttc" id="aattention__policy__map_8h_html"><div class="ttname"><a href="attention__policy__map_8h.html">attention_policy_map.h</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html">lczero::CudaNetworkComputation</a></div><div class="ttdoc">CUDA network computation class.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00134">network_cuda.cc:134</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a11d0d6c9bde122187f4404aec3bb36da"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a11d0d6c9bde122187f4404aec3bb36da">lczero::CudaNetworkComputation::GetBatchSize</a></div><div class="ttdeci">int GetBatchSize() const override</div><div class="ttdoc">Returns the number of samples in the current batch.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00172">network_cuda.cc:172</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a2c13d328c17e7f3a5ba6d488b800a6e4"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a2c13d328c17e7f3a5ba6d488b800a6e4">lczero::CudaNetworkComputation::ComputeBlocking</a></div><div class="ttdeci">void ComputeBlocking() override</div><div class="ttdoc">Computes the network outputs for the current batch.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01262">network_cuda.cc:1262</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a4aa08aa611773a1fe38b28cf6916ecb4"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a4aa08aa611773a1fe38b28cf6916ecb4">lczero::CudaNetworkComputation::GetMVal</a></div><div class="ttdeci">float GetMVal(int sample) const override</div><div class="ttdoc">Retrieves the M-value (moves left) for a specific sample.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00201">network_cuda.cc:201</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a68be8566dc1d5baec280adfd456e6a1d"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a68be8566dc1d5baec280adfd456e6a1d">lczero::CudaNetworkComputation::GetDVal</a></div><div class="ttdeci">float GetDVal(int sample) const override</div><div class="ttdoc">Retrieves the D-value (draw probability) for a specific sample.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00185">network_cuda.cc:185</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a74cd2f1f1688fa09f3edb35d99d4b464"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a74cd2f1f1688fa09f3edb35d99d4b464">lczero::CudaNetworkComputation::inputs_outputs_</a></div><div class="ttdeci">std::unique_ptr&lt; InputsOutputs&lt; DataType &gt; &gt; inputs_outputs_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00210">network_cuda.cc:210</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a75f70f6420e41e170a7e0ba5acfc2ed7"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a75f70f6420e41e170a7e0ba5acfc2ed7">lczero::CudaNetworkComputation::GetPVal</a></div><div class="ttdeci">float GetPVal(int sample, int move_id) const override</div><div class="ttdoc">Retrieves the P-value (policy/move probability) for a specific move in a sample.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00196">network_cuda.cc:196</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a782841c1c8dbe70b647bb56d1a3bcdd5"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a782841c1c8dbe70b647bb56d1a3bcdd5">lczero::CudaNetworkComputation::GetQVal</a></div><div class="ttdeci">float GetQVal(int sample) const override</div><div class="ttdoc">Retrieves the Q-value (expected game result) for a specific sample.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00174">network_cuda.cc:174</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_a83439fbc9dd4cd235c33c2b6a4ce3c4e"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#a83439fbc9dd4cd235c33c2b6a4ce3c4e">lczero::CudaNetworkComputation::CudaNetworkComputation</a></div><div class="ttdeci">CudaNetworkComputation(CudaNetwork&lt; DataType &gt; *network, bool wdl, bool moves_left)</div><div class="ttdoc">Constructor.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01231">network_cuda.cc:1231</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_aa6c57c4e2e5cc50053e86eb2b6297d47"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#aa6c57c4e2e5cc50053e86eb2b6297d47">lczero::CudaNetworkComputation::AddInput</a></div><div class="ttdeci">void AddInput(InputPlanes &amp;&amp;input) override</div><div class="ttdoc">Adds a sample (input planes) to the current batch.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00146">network_cuda.cc:146</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_aa9628aa93257e176db31704c79eb2b4a"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#aa9628aa93257e176db31704c79eb2b4a">lczero::CudaNetworkComputation::moves_left_</a></div><div class="ttdeci">bool moves_left_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00213">network_cuda.cc:213</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_ab16d8a24586379a53268bc760f6db4fe"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#ab16d8a24586379a53268bc760f6db4fe">lczero::CudaNetworkComputation::network_</a></div><div class="ttdeci">CudaNetwork&lt; DataType &gt; * network_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00215">network_cuda.cc:215</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_abef905f0b31b30dbe835e13a23a3c166"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#abef905f0b31b30dbe835e13a23a3c166">lczero::CudaNetworkComputation::CaptureGraph</a></div><div class="ttdeci">void CaptureGraph(std::unique_lock&lt; std::mutex &gt; &amp;&amp;lock={})</div><div class="ttdoc">Captures the CUDA graph for the current batch.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01244">network_cuda.cc:1244</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_abf8d449b0777209bffcaabdef15b578f"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#abf8d449b0777209bffcaabdef15b578f">lczero::CudaNetworkComputation::wdl_</a></div><div class="ttdeci">bool wdl_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00212">network_cuda.cc:212</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_ae02dfda0ef31f9fc8fc2e4a5b6bf8c98"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#ae02dfda0ef31f9fc8fc2e4a5b6bf8c98">lczero::CudaNetworkComputation::batch_size_</a></div><div class="ttdeci">int batch_size_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00211">network_cuda.cc:211</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetworkComputation_html_ae90593942136474f6b3e73520e9e5097"><div class="ttname"><a href="classlczero_1_1CudaNetworkComputation.html#ae90593942136474f6b3e73520e9e5097">lczero::CudaNetworkComputation::~CudaNetworkComputation</a></div><div class="ttdeci">~CudaNetworkComputation()</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01239">network_cuda.cc:1239</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html">lczero::CudaNetwork</a></div><div class="ttdoc">CUDA network implementation.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00221">network_cuda.cc:221</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a01699a1f6860cda41dfee54217b1862c"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a01699a1f6860cda41dfee54217b1862c">lczero::CudaNetwork::enable_graph_capture_</a></div><div class="ttdeci">bool enable_graph_capture_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01115">network_cuda.cc:1115</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a019e15da7d32a5cab87befc6fd040b53"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a019e15da7d32a5cab87befc6fd040b53">lczero::CudaNetwork::CudaNetwork</a></div><div class="ttdeci">CudaNetwork(const WeightsFile &amp;file, const OptionsDict &amp;options)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00223">network_cuda.cc:223</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a07e2823f1a2f64f1fc684e1ec5859ae9"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a07e2823f1a2f64f1fc684e1ec5859ae9">lczero::CudaNetwork::encoder_last_</a></div><div class="ttdeci">BaseLayer&lt; DataType &gt; * encoder_last_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01138">network_cuda.cc:1138</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a09ba6230578a4bb53a0acd260c3eb515"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a09ba6230578a4bb53a0acd260c3eb515">lczero::CudaNetwork::has_se_</a></div><div class="ttdeci">bool has_se_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01129">network_cuda.cc:1129</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a0e4a9ee973e4ff7dfe63ba1d815de39e"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a0e4a9ee973e4ff7dfe63ba1d815de39e">lczero::CudaNetwork::scratch_mem_</a></div><div class="ttdeci">void * scratch_mem_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01144">network_cuda.cc:1144</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a1b16fc6e42242f982303703bbfa55340"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a1b16fc6e42242f982303703bbfa55340">lczero::CudaNetwork::conv_policy_</a></div><div class="ttdeci">bool conv_policy_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01130">network_cuda.cc:1130</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a1bebd0eea32e4608e28d83778458ca29"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a1bebd0eea32e4608e28d83778458ca29">lczero::CudaNetwork::scratch_size_</a></div><div class="ttdeci">size_t scratch_size_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01141">network_cuda.cc:1141</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a1dbd72f2cfd24d3dfb47fc086c7b1824"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a1dbd72f2cfd24d3dfb47fc086c7b1824">lczero::CudaNetwork::moves_left_</a></div><div class="ttdeci">bool moves_left_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01117">network_cuda.cc:1117</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a1fe4bf7e630779253e4c7f7f7b1d0821"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a1fe4bf7e630779253e4c7f7f7b1d0821">lczero::CudaNetwork::lock_</a></div><div class="ttdeci">std::mutex lock_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01125">network_cuda.cc:1125</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a20d84b728c194b4708c6de9fb82445b1"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a20d84b728c194b4708c6de9fb82445b1">lczero::CudaNetwork::has_tensor_cores_</a></div><div class="ttdeci">bool has_tensor_cores_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01149">network_cuda.cc:1149</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a22edd11d982e72b03926885f155bca0d"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a22edd11d982e72b03926885f155bca0d">lczero::CudaNetwork::finishEval</a></div><div class="ttdeci">void finishEval(InputsOutputs&lt; DataType &gt; *io, int batchSize)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01003">network_cuda.cc:1003</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a240b95efc1b5559d4ff8c5ce6faaad5c"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a240b95efc1b5559d4ff8c5ce6faaad5c">lczero::CudaNetwork::min_batch_size_</a></div><div class="ttdeci">int min_batch_size_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01114">network_cuda.cc:1114</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a246408fa495ed9f280c1900ef2672fba"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a246408fa495ed9f280c1900ef2672fba">lczero::CudaNetwork::GetGraphCaptureEnabled</a></div><div class="ttdeci">bool GetGraphCaptureEnabled() const</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00676">network_cuda.cc:676</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a272fc67afccd2b11b44c0f7cbffd0769"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a272fc67afccd2b11b44c0f7cbffd0769">lczero::CudaNetwork::GetCapabilities</a></div><div class="ttdeci">const NetworkCapabilities &amp; GetCapabilities() const override</div><div class="ttdoc">Retrieves the capabilities of this network.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01053">network_cuda.cc:1053</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a31b78a66a9843a40d04521b34e0214f3"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a31b78a66a9843a40d04521b34e0214f3">lczero::CudaNetwork::network_</a></div><div class="ttdeci">std::vector&lt; std::unique_ptr&lt; BaseLayer&lt; DataType &gt; &gt; &gt; network_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01134">network_cuda.cc:1134</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a36a520cd81d849553a4811aea15ba668"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a36a520cd81d849553a4811aea15ba668">lczero::CudaNetwork::upload_stream_</a></div><div class="ttdeci">cudaStream_t upload_stream_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01153">network_cuda.cc:1153</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a41dbeae09f8028210d3115908711a0d3"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a41dbeae09f8028210d3115908711a0d3">lczero::CudaNetwork::head_offset_pointers_</a></div><div class="ttdeci">void ** head_offset_pointers_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01147">network_cuda.cc:1147</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a46d705e0e218edd9dee101e809e29e6f"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a46d705e0e218edd9dee101e809e29e6f">lczero::CudaNetwork::~CudaNetwork</a></div><div class="ttdeci">~CudaNetwork()</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01036">network_cuda.cc:1036</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a4b6b7262af7d5bba9d44b40c3d7da55d"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a4b6b7262af7d5bba9d44b40c3d7da55d">lczero::CudaNetwork::gpu_id_</a></div><div class="ttdeci">int gpu_id_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01110">network_cuda.cc:1110</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a51f27881b41e4b4caff5b18c6faec3f7"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a51f27881b41e4b4caff5b18c6faec3f7">lczero::CudaNetwork::NewComputation</a></div><div class="ttdeci">std::unique_ptr&lt; NetworkComputation &gt; NewComputation() override</div><div class="ttdoc">Creates a new computation instance for performing inference.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01070">network_cuda.cc:1070</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a52518e90e82eda0c97d5c4fa7dea7a2d"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a52518e90e82eda0c97d5c4fa7dea7a2d">lczero::CudaNetwork::BeginCapture</a></div><div class="ttdeci">CudaGraphCapture&lt; DataType &gt; BeginCapture(InputsOutputs&lt; DataType &gt; &amp;io)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00678">network_cuda.cc:678</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a559457fc67b520b091f3cf7940d46bc6"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a559457fc67b520b091f3cf7940d46bc6">lczero::CudaNetwork::compute_ordering_event_</a></div><div class="ttdeci">cudaEvent_t compute_ordering_event_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01155">network_cuda.cc:1155</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a55b3652578313fe3b4ace6617f05b2c0"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a55b3652578313fe3b4ace6617f05b2c0">lczero::CudaNetwork::inputs_outputs_lock_</a></div><div class="ttdeci">std::mutex inputs_outputs_lock_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01159">network_cuda.cc:1159</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a5827d93e06b1e2750fff7848894bdf2e"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a5827d93e06b1e2750fff7848894bdf2e">lczero::CudaNetwork::tensor_mem_</a></div><div class="ttdeci">DataType * tensor_mem_[3]</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01157">network_cuda.cc:1157</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a63ff560fee9c919d16bb0c2d1a691f54"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a63ff560fee9c919d16bb0c2d1a691f54">lczero::CudaNetwork::cublas_</a></div><div class="ttdeci">cublasHandle_t cublas_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01156">network_cuda.cc:1156</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a6e6f47b4107450f2a9d4b3a0831359dc"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a6e6f47b4107450f2a9d4b3a0831359dc">lczero::CudaNetwork::GetMiniBatchSize</a></div><div class="ttdeci">int GetMiniBatchSize() const override</div><div class="ttdoc">Gets the preferred batch size for this network.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01057">network_cuda.cc:1057</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a7203422407bcef3715a4b9fd9836e515"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a7203422407bcef3715a4b9fd9836e515">lczero::CudaNetwork::l2_cache_size_</a></div><div class="ttdeci">int l2_cache_size_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01111">network_cuda.cc:1111</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a7624cbd53dc8fbe448ba8fffb374408c"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a7624cbd53dc8fbe448ba8fffb374408c">lczero::CudaNetwork::use_res_block_winograd_fuse_opt_</a></div><div class="ttdeci">bool use_res_block_winograd_fuse_opt_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01118">network_cuda.cc:1118</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a7d884ee7d32f54c04181ce570ecb56b4"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a7d884ee7d32f54c04181ce570ecb56b4">lczero::CudaNetwork::getLastLayer</a></div><div class="ttdeci">BaseLayer&lt; DataType &gt; * getLastLayer()</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01135">network_cuda.cc:1135</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a819fd55637d72ae879a5e7c8060bd3de"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a819fd55637d72ae879a5e7c8060bd3de">lczero::CudaNetwork::wdl_</a></div><div class="ttdeci">bool wdl_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01116">network_cuda.cc:1116</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a8569c32a2f7f878f57f2a232b097dac8"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a8569c32a2f7f878f57f2a232b097dac8">lczero::CudaNetwork::capabilities_</a></div><div class="ttdeci">const NetworkCapabilities capabilities_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01109">network_cuda.cc:1109</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a8be42510552691603217878b80f6603f"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a8be42510552691603217878b80f6603f">lczero::CudaNetwork::GetInputsOutputs</a></div><div class="ttdeci">std::unique_ptr&lt; InputsOutputs&lt; DataType &gt; &gt; GetInputsOutputs()</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01082">network_cuda.cc:1082</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a8d9a8f591d15d014e2d7bf7dfd6f949d"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a8d9a8f591d15d014e2d7bf7dfd6f949d">lczero::CudaNetwork::numBlocks_</a></div><div class="ttdeci">int numBlocks_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01127">network_cuda.cc:1127</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a9145d366464720a1f82f065bed9b0b32"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a9145d366464720a1f82f065bed9b0b32">lczero::CudaNetwork::tensor_mem_size_</a></div><div class="ttdeci">size_t tensor_mem_size_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01140">network_cuda.cc:1140</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a9683824184574828ebc862d3aa764eff"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a9683824184574828ebc862d3aa764eff">lczero::CudaNetwork::max_batch_size_</a></div><div class="ttdeci">int max_batch_size_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01113">network_cuda.cc:1113</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a9777fa5c5fe58d7eff4447cd7be0764b"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a9777fa5c5fe58d7eff4447cd7be0764b">lczero::CudaNetwork::offset_pointers_</a></div><div class="ttdeci">void ** offset_pointers_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01146">network_cuda.cc:1146</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_a9833f4ec072627e0d27b4ab5fdf22900"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#a9833f4ec072627e0d27b4ab5fdf22900">lczero::CudaNetwork::download_stream_</a></div><div class="ttdeci">cudaStream_t download_stream_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01154">network_cuda.cc:1154</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_aa3b5bd67092d91cdf27dca2ebfbd1e5c"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#aa3b5bd67092d91cdf27dca2ebfbd1e5c">lczero::CudaNetwork::forwardEval</a></div><div class="ttdeci">void forwardEval(InputsOutputs&lt; DataType &gt; *io, int batchSize, bool capture=false)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00724">network_cuda.cc:724</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ab19946d2a476243f2fc88090f99fa130"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ab19946d2a476243f2fc88090f99fa130">lczero::CudaNetwork::attn_body_</a></div><div class="ttdeci">bool attn_body_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01132">network_cuda.cc:1132</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ab5f7f804f46016185d60917813962b11"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ab5f7f804f46016185d60917813962b11">lczero::CudaNetwork::LockEval</a></div><div class="ttdeci">std::unique_lock&lt; std::mutex &gt; LockEval()</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00668">network_cuda.cc:668</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_abcc07a7f035ddc5baff3b24c0e6119e8"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#abcc07a7f035ddc5baff3b24c0e6119e8">lczero::CudaNetwork::GetThreads</a></div><div class="ttdeci">int GetThreads() const override</div><div class="ttdoc">Gets the number of threads used by this network backend.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01068">network_cuda.cc:1068</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_aca8d94d41b7aa1167404d99966f65ef9"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#aca8d94d41b7aa1167404d99966f65ef9">lczero::CudaNetwork::ReleaseInputsOutputs</a></div><div class="ttdeci">void ReleaseInputsOutputs(std::unique_ptr&lt; InputsOutputs&lt; DataType &gt; &gt; resource)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01096">network_cuda.cc:1096</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_acdd66225ad7c652e33a47accfdc411e8"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#acdd66225ad7c652e33a47accfdc411e8">lczero::CudaNetwork::num_encoder_blocks_</a></div><div class="ttdeci">int num_encoder_blocks_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01133">network_cuda.cc:1133</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ace0225a707963a917029a40ba0a96ece"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ace0225a707963a917029a40ba0a96ece">lczero::CudaNetwork::numFilters_</a></div><div class="ttdeci">int numFilters_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01128">network_cuda.cc:1128</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_acf0c68f201e2f315d6ede2319680aa76"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#acf0c68f201e2f315d6ede2319680aa76">lczero::CudaNetwork::compute_stream_</a></div><div class="ttdeci">cudaStream_t compute_stream_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01152">network_cuda.cc:1152</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ad0acd2032fffa2aab27dbfaf23a48f1c"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ad0acd2032fffa2aab27dbfaf23a48f1c">lczero::CudaNetwork::GraphLaunch</a></div><div class="ttdeci">void GraphLaunch(InputsOutputs&lt; DataType &gt; *io, int batchSize)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00706">network_cuda.cc:706</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ad2c0d5066570e1aa1b97873cf5da9bea"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ad2c0d5066570e1aa1b97873cf5da9bea">lczero::CudaNetwork::sm_count_</a></div><div class="ttdeci">int sm_count_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01112">network_cuda.cc:1112</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ad4e9918939cfb8e524021339b08cfb44"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ad4e9918939cfb8e524021339b08cfb44">lczero::CudaNetwork::free_inputs_outputs_</a></div><div class="ttdeci">std::list&lt; std::unique_ptr&lt; InputsOutputs&lt; DataType &gt; &gt; &gt; free_inputs_outputs_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01160">network_cuda.cc:1160</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ad9bc088c3f7061fc9b4a50b9287cec94"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ad9bc088c3f7061fc9b4a50b9287cec94">lczero::CudaNetwork::UploadInputs</a></div><div class="ttdeci">void UploadInputs(InputsOutputs&lt; DataType &gt; *io, int batchSize)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00690">network_cuda.cc:690</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_adc7949af70ead285eee67c3e5852caee"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#adc7949af70ead285eee67c3e5852caee">lczero::CudaNetwork::multi_stream_</a></div><div class="ttdeci">bool multi_stream_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01120">network_cuda.cc:1120</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ae017cf365d571ddb91a223a3e7c48a0f"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ae017cf365d571ddb91a223a3e7c48a0f">lczero::CudaNetwork::attn_policy_</a></div><div class="ttdeci">bool attn_policy_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01131">network_cuda.cc:1131</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ae2634feddcb0d9eda97273d45465bcf9"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ae2634feddcb0d9eda97273d45465bcf9">lczero::CudaNetwork::resi_last_</a></div><div class="ttdeci">BaseLayer&lt; DataType &gt; * resi_last_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01137">network_cuda.cc:1137</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ae27e343d2c18e3ecd492101c33d24239"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ae27e343d2c18e3ecd492101c33d24239">lczero::CudaNetwork::allow_cache_opt_</a></div><div class="ttdeci">bool allow_cache_opt_</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01121">network_cuda.cc:1121</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ae45134fc073d795ca426fc3d7cca6f80"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ae45134fc073d795ca426fc3d7cca6f80">lczero::CudaNetwork::UglyFunctionToSilenceNvccWarning</a></div><div class="ttdeci">void UglyFunctionToSilenceNvccWarning()</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01104">network_cuda.cc:1104</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_ae4d5a550345de6b79b516b740871649f"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#ae4d5a550345de6b79b516b740871649f">lczero::CudaNetwork::showInfo</a></div><div class="ttdeci">void showInfo() const</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01162">network_cuda.cc:1162</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_af647744ff0e16fa1875f0b2e9504c8f8"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#af647744ff0e16fa1875f0b2e9504c8f8">lczero::CudaNetwork::showDeviceInfo</a></div><div class="ttdeci">void showDeviceInfo(const cudaDeviceProp &amp;deviceProp, int deviceId) const</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01199">network_cuda.cc:1199</a></div></div>
<div class="ttc" id="aclasslczero_1_1CudaNetwork_html_af9036a86e264666d5bf78e7ce38ba94d"><div class="ttname"><a href="classlczero_1_1CudaNetwork.html#af9036a86e264666d5bf78e7ce38ba94d">lczero::CudaNetwork::GetPreferredBatchStep</a></div><div class="ttdeci">int GetPreferredBatchStep() const override</div><div class="ttdoc">Gets the preferred batch step (increment).</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01062">network_cuda.cc:1062</a></div></div>
<div class="ttc" id="aclasslczero_1_1Exception_html"><div class="ttname"><a href="classlczero_1_1Exception.html">lczero::Exception</a></div><div class="ttdef"><b>Definition</b> <a href="exception_8h_source.html#l00036">exception.h:36</a></div></div>
<div class="ttc" id="aclasslczero_1_1NetworkComputation_html"><div class="ttname"><a href="classlczero_1_1NetworkComputation.html">lczero::NetworkComputation</a></div><div class="ttdoc">Abstract interface for neural network computation backends.</div><div class="ttdef"><b>Definition</b> <a href="network_8h_source.html#l00068">network.h:68</a></div></div>
<div class="ttc" id="aclasslczero_1_1Network_html"><div class="ttname"><a href="classlczero_1_1Network.html">lczero::Network</a></div><div class="ttdoc">Abstract base class for a neural network backend.</div><div class="ttdef"><b>Definition</b> <a href="network_8h_source.html#l00167">network.h:167</a></div></div>
<div class="ttc" id="aclasslczero_1_1OptionsDict_html"><div class="ttname"><a href="classlczero_1_1OptionsDict.html">lczero::OptionsDict</a></div><div class="ttdef"><b>Definition</b> <a href="optionsdict_8h_source.html#l00163">optionsdict.h:167</a></div></div>
<div class="ttc" id="aclasslczero_1_1OptionsDict_html_a1d4e92198fa104f08d9f7ae8efba8498"><div class="ttname"><a href="classlczero_1_1OptionsDict.html#a1d4e92198fa104f08d9f7ae8efba8498">lczero::OptionsDict::GetOrDefault</a></div><div class="ttdeci">T GetOrDefault(const std::string &amp;key, const T &amp;default_val) const</div><div class="ttdef"><b>Definition</b> <a href="optionsdict_8h_source.html#l00328">optionsdict.h:328</a></div></div>
<div class="ttc" id="aclasslczero_1_1OptionsDict_html_a1e48aa5d30fccb31803845d8cde4047d"><div class="ttname"><a href="classlczero_1_1OptionsDict.html#a1e48aa5d30fccb31803845d8cde4047d">lczero::OptionsDict::Get</a></div><div class="ttdeci">T Get(const std::string &amp;key) const</div><div class="ttdef"><b>Definition</b> <a href="optionsdict_8h_source.html#l00271">optionsdict.h:271</a></div></div>
<div class="ttc" id="aclasslczero_1_1OptionsDict_html_a7a5cef61f5c4aa5cba99b314e0ba05ac"><div class="ttname"><a href="classlczero_1_1OptionsDict.html#a7a5cef61f5c4aa5cba99b314e0ba05ac">lczero::OptionsDict::Exists</a></div><div class="ttdeci">bool Exists(const std::string &amp;key) const</div><div class="ttdef"><b>Definition</b> <a href="optionsdict_8h_source.html#l00298">optionsdict.h:298</a></div></div>
<div class="ttc" id="aclasslczero_1_1cudnn__backend_1_1BaseLayer_html"><div class="ttname"><a href="classlczero_1_1cudnn__backend_1_1BaseLayer.html">lczero::cudnn_backend::BaseLayer</a></div><div class="ttdoc">Base class for neural network layers in CUDA backend.</div><div class="ttdef"><b>Definition</b> <a href="cuda_2layers_8h_source.html#l00051">layers.h:51</a></div></div>
<div class="ttc" id="acuda__common_8h_html"><div class="ttname"><a href="cuda__common_8h.html">cuda_common.h</a></div><div class="ttdoc">Common includes and definitions for CUDA backend.</div></div>
<div class="ttc" id="acuda__common_8h_html_a5df7402b2cc2025fcde387e576d19e1c"><div class="ttname"><a href="cuda__common_8h.html#a5df7402b2cc2025fcde387e576d19e1c">CUBLAS_PEDANTIC_MATH</a></div><div class="ttdeci">#define CUBLAS_PEDANTIC_MATH</div><div class="ttdef"><b>Definition</b> <a href="cuda__common_8h_source.html#l00045">cuda_common.h:45</a></div></div>
<div class="ttc" id="acuda__common_8h_html_a7df6734b37d817be68002a816e49a5d1"><div class="ttname"><a href="cuda__common_8h.html#a7df6734b37d817be68002a816e49a5d1">ReportCUBLASErrors</a></div><div class="ttdeci">#define ReportCUBLASErrors(status)</div><div class="ttdef"><b>Definition</b> <a href="cuda__common_8h_source.html#l00075">cuda_common.h:75</a></div></div>
<div class="ttc" id="acuda__common_8h_html_ab0dc7d3b054b17644e2012df7c89a87c"><div class="ttname"><a href="cuda__common_8h.html#ab0dc7d3b054b17644e2012df7c89a87c">ReportCUDAErrors</a></div><div class="ttdeci">#define ReportCUDAErrors(status)</div><div class="ttdef"><b>Definition</b> <a href="cuda__common_8h_source.html#l00076">cuda_common.h:76</a></div></div>
<div class="ttc" id="aexception_8h_html"><div class="ttname"><a href="exception_8h.html">exception.h</a></div></div>
<div class="ttc" id="afp16__utils_8h_html"><div class="ttname"><a href="fp16__utils_8h.html">fp16_utils.h</a></div></div>
<div class="ttc" id="alogging_8h_html_a176c0577baa96c686397bca42f7ee6ff"><div class="ttname"><a href="logging_8h.html#a176c0577baa96c686397bca42f7ee6ff">CERR</a></div><div class="ttdeci">#define CERR</div><div class="ttdef"><b>Definition</b> <a href="logging_8h_source.html#l00092">logging.h:92</a></div></div>
<div class="ttc" id="amemcache_8cc_html_a3fbbd8a3959e76a2bc3455d3bade52dc"><div class="ttname"><a href="memcache_8cc.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a></div><div class="ttdeci">float d</div><div class="ttdef"><b>Definition</b> <a href="memcache_8cc_source.html#l00047">memcache.cc:47</a></div></div>
<div class="ttc" id="amemcache_8cc_html_ac51334f57ef8b81c0629c9421798c344"><div class="ttname"><a href="memcache_8cc.html#ac51334f57ef8b81c0629c9421798c344">m</a></div><div class="ttdeci">float m</div><div class="ttdef"><b>Definition</b> <a href="memcache_8cc_source.html#l00048">memcache.cc:48</a></div></div>
<div class="ttc" id="anamespacelczero_1_1cudnn__backend_html_a2d28b2933cc4dbdac8714d9f28861a19"><div class="ttname"><a href="namespacelczero_1_1cudnn__backend.html#a2d28b2933cc4dbdac8714d9f28861a19">lczero::cudnn_backend::FromType</a></div><div class="ttdeci">float FromType(float src)</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00046">inputs_outputs.h:46</a></div></div>
<div class="ttc" id="anamespacelczero_1_1cudnn__backend_html_a3298666071469a49009d91a8ac5f9c7b"><div class="ttname"><a href="namespacelczero_1_1cudnn__backend.html#a3298666071469a49009d91a8ac5f9c7b">lczero::cudnn_backend::kNumOutputPolicy</a></div><div class="ttdeci">static constexpr int kNumOutputPolicy</div><div class="ttdoc">Maximum number of output policy channels.</div><div class="ttdef"><b>Definition</b> <a href="cuda__common_8h_source.html#l00052">cuda_common.h:52</a></div></div>
<div class="ttc" id="anamespacelczero_1_1cudnn__backend_html_abe98729db620e6ebf04d17937ef638b6"><div class="ttname"><a href="namespacelczero_1_1cudnn__backend.html#abe98729db620e6ebf04d17937ef638b6">lczero::cudnn_backend::ToType</a></div><div class="ttdeci">void ToType(float &amp;dst, float src)</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00040">inputs_outputs.h:40</a></div></div>
<div class="ttc" id="anamespacelczero_1_1cudnn__backend_html_ae749a185fa49e8fe54067dcd0647f4fe"><div class="ttname"><a href="namespacelczero_1_1cudnn__backend.html#ae749a185fa49e8fe54067dcd0647f4fe">lczero::cudnn_backend::expandPlanes_NCHW</a></div><div class="ttdeci">void expandPlanes_NCHW(T *output, const uint64_t *masks, const T *values, int n, cudaStream_t stream)</div></div>
<div class="ttc" id="anamespacelczero_html"><div class="ttname"><a href="namespacelczero.html">lczero</a></div><div class="ttdef"><b>Definition</b> <a href="bitboard_8h_source.html#l00038">bitboard.h:38</a></div></div>
<div class="ttc" id="anamespacelczero_html_a1110b86a736271d5d1669bee1adf0065"><div class="ttname"><a href="namespacelczero.html#a1110b86a736271d5d1669bee1adf0065">lczero::InputPlanes</a></div><div class="ttdeci">std::vector&lt; InputPlane &gt; InputPlanes</div><div class="ttdef"><b>Definition</b> <a href="network_8h_source.html#l00062">network.h:62</a></div></div>
<div class="ttc" id="anamespacelczero_html_a240fb199a13e5acdecb5207efc7becde"><div class="ttname"><a href="namespacelczero.html#a240fb199a13e5acdecb5207efc7becde">lczero::getMaxAttentionHeadSize</a></div><div class="ttdeci">static size_t getMaxAttentionHeadSize(const MultiHeadWeights::PolicyHead &amp;weights, int N)</div><div class="ttdoc">Computes maximum attention head size.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00061">network_cuda.cc:61</a></div></div>
<div class="ttc" id="anamespacelczero_html_a27f519ff52a925ebea6591f5c0b1fd75"><div class="ttname"><a href="namespacelczero.html#a27f519ff52a925ebea6591f5c0b1fd75">lczero::kAttnPolicyMap</a></div><div class="ttdeci">const short kAttnPolicyMap[]</div><div class="ttdef"><b>Definition</b> <a href="attention__policy__map_8h_source.html#l00024">attention_policy_map.h:24</a></div></div>
<div class="ttc" id="anamespacelczero_html_a2c97d5e3f3602f9ec8b13fe7b2357f45"><div class="ttname"><a href="namespacelczero.html#a2c97d5e3f3602f9ec8b13fe7b2357f45">lczero::kConvPolicyMap</a></div><div class="ttdeci">const short kConvPolicyMap[]</div><div class="ttdef"><b>Definition</b> <a href="policy__map_8h_source.html#l00024">policy_map.h:24</a></div></div>
<div class="ttc" id="anamespacelczero_html_a3a02ce348b57ce09ca329e0155aa5deb"><div class="ttname"><a href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deb">lczero::ActivationFunction</a></div><div class="ttdeci">ActivationFunction</div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00024">activation_function.h:24</a></div></div>
<div class="ttc" id="anamespacelczero_html_a3a02ce348b57ce09ca329e0155aa5deba26efbe0bfd6bc4ec3eb8a7ead18e599b"><div class="ttname"><a href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deba26efbe0bfd6bc4ec3eb8a7ead18e599b">lczero::ACTIVATION_RELU</a></div><div class="ttdeci">@ ACTIVATION_RELU</div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00027">activation_function.h:27</a></div></div>
<div class="ttc" id="anamespacelczero_html_a3a02ce348b57ce09ca329e0155aa5deba6d1459a7bd32ebd9560eac8dd0935406"><div class="ttname"><a href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5deba6d1459a7bd32ebd9560eac8dd0935406">lczero::ACTIVATION_MISH</a></div><div class="ttdeci">@ ACTIVATION_MISH</div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00026">activation_function.h:26</a></div></div>
<div class="ttc" id="anamespacelczero_html_a3a02ce348b57ce09ca329e0155aa5debabf0ab8acc3bbb5028fde6be432108a42"><div class="ttname"><a href="namespacelczero.html#a3a02ce348b57ce09ca329e0155aa5debabf0ab8acc3bbb5028fde6be432108a42">lczero::ACTIVATION_NONE</a></div><div class="ttdeci">@ ACTIVATION_NONE</div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00028">activation_function.h:28</a></div></div>
<div class="ttc" id="anamespacelczero_html_a50ba8cd031e94ed714f45910053d6570"><div class="ttname"><a href="namespacelczero.html#a50ba8cd031e94ed714f45910053d6570">lczero::MakeCudaNetworkAuto</a></div><div class="ttdeci">std::unique_ptr&lt; Network &gt; MakeCudaNetworkAuto(const std::optional&lt; WeightsFile &gt; &amp;weights, const OptionsDict &amp;options)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01350">network_cuda.cc:1350</a></div></div>
<div class="ttc" id="anamespacelczero_html_a6705e82c4f5d6edcac8d0ca3b2240b29"><div class="ttname"><a href="namespacelczero.html#a6705e82c4f5d6edcac8d0ca3b2240b29">lczero::WeightsFile</a></div><div class="ttdeci">pblczero::Net WeightsFile</div><div class="ttdef"><b>Definition</b> <a href="loader_8h_source.html#l00044">loader.h:44</a></div></div>
<div class="ttc" id="anamespacelczero_html_a6859c8ceb3dbdef33a21752d16b40311"><div class="ttname"><a href="namespacelczero.html#a6859c8ceb3dbdef33a21752d16b40311">lczero::InputEmbedding</a></div><div class="ttdeci">InputEmbedding</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00231">network_legacy.h:231</a></div></div>
<div class="ttc" id="anamespacelczero_html_a6859c8ceb3dbdef33a21752d16b40311a450d6145004b0b7a54288b65401b9c91"><div class="ttname"><a href="namespacelczero.html#a6859c8ceb3dbdef33a21752d16b40311a450d6145004b0b7a54288b65401b9c91">lczero::INPUT_EMBEDDING_PE_DENSE</a></div><div class="ttdeci">@ INPUT_EMBEDDING_PE_DENSE</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00234">network_legacy.h:234</a></div></div>
<div class="ttc" id="anamespacelczero_html_a688fe39dcd5064cc42376d9c5beda6c1"><div class="ttname"><a href="namespacelczero.html#a688fe39dcd5064cc42376d9c5beda6c1">lczero::kInputPlanes</a></div><div class="ttdeci">const int kInputPlanes</div><div class="ttdef"><b>Definition</b> <a href="network_8h_source.html#l00038">network.h:38</a></div></div>
<div class="ttc" id="anamespacelczero_html_ace425dcea6ffa6a3da929f5ddf79d907"><div class="ttname"><a href="namespacelczero.html#ace425dcea6ffa6a3da929f5ddf79d907">lczero::MakeCudaNetwork</a></div><div class="ttdeci">std::unique_ptr&lt; Network &gt; MakeCudaNetwork(const std::optional&lt; WeightsFile &gt; &amp;w, const OptionsDict &amp;options)</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l01280">network_cuda.cc:1280</a></div></div>
<div class="ttc" id="anamespacelczero_html_af3c3d8d9760200f64a76d8e13de19e9f"><div class="ttname"><a href="namespacelczero.html#af3c3d8d9760200f64a76d8e13de19e9f">lczero::getMaxAttentionBodySize</a></div><div class="ttdeci">static size_t getMaxAttentionBodySize(const MultiHeadWeights &amp;weights, int N)</div><div class="ttdoc">Computes maximum attention body size.</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00098">network_cuda.cc:98</a></div></div>
<div class="ttc" id="anetwork__blas_8cc_html_a5962f2d981f098ad69c81771db5452da"><div class="ttname"><a href="network__blas_8cc.html#a5962f2d981f098ad69c81771db5452da">moves_left_</a></div><div class="ttdeci">bool moves_left_</div><div class="ttdef"><b>Definition</b> <a href="network__blas_8cc_source.html#l00180">network_blas.cc:180</a></div></div>
<div class="ttc" id="anetwork__blas_8cc_html_a705d0a7ba8d3c6c61f9486a9e37c0197"><div class="ttname"><a href="network__blas_8cc.html#a705d0a7ba8d3c6c61f9486a9e37c0197">wdl_</a></div><div class="ttdeci">bool wdl_</div><div class="ttdef"><b>Definition</b> <a href="network__blas_8cc_source.html#l00179">network_blas.cc:179</a></div></div>
<div class="ttc" id="anetwork__blas_8cc_html_aa5236f0345b968584f3525ebb0fcfd29"><div class="ttname"><a href="network__blas_8cc.html#aa5236f0345b968584f3525ebb0fcfd29">network_</a></div><div class="ttdeci">BlasNetwork&lt; use_eigen &gt; * network_</div><div class="ttdef"><b>Definition</b> <a href="network__blas_8cc_source.html#l00190">network_blas.cc:190</a></div></div>
<div class="ttc" id="anetwork__cuda_8cc_html_ad0077596f0a38b26cf89984e950c8225"><div class="ttname"><a href="network__cuda_8cc.html#ad0077596f0a38b26cf89984e950c8225">CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</a></div><div class="ttdeci">#define CUDA_GRAPH_SUPPORTS_EXTERNAL_EVENTS</div><div class="ttdef"><b>Definition</b> <a href="network__cuda_8cc_source.html#l00049">network_cuda.cc:49</a></div></div>
<div class="ttc" id="anetwork__legacy_8h_html"><div class="ttname"><a href="network__legacy_8h.html">network_legacy.h</a></div></div>
<div class="ttc" id="aneural_2factory_8h_html"><div class="ttname"><a href="neural_2factory_8h.html">factory.h</a></div></div>
<div class="ttc" id="aneural_2factory_8h_html_af219bf322aa35924d378cd40e2c314de"><div class="ttname"><a href="neural_2factory_8h.html#af219bf322aa35924d378cd40e2c314de">REGISTER_NETWORK</a></div><div class="ttdeci">#define REGISTER_NETWORK(name, func, priority)</div><div class="ttdef"><b>Definition</b> <a href="neural_2factory_8h_source.html#l00164">factory.h:164</a></div></div>
<div class="ttc" id="aonnx2hlo_8cc_html_a97690fc7b8c771025c632d5fc80fe1e0"><div class="ttname"><a href="onnx2hlo_8cc.html#a97690fc7b8c771025c632d5fc80fe1e0">flow</a></div><div class="ttdeci">HloFlow flow</div><div class="ttdef"><b>Definition</b> <a href="onnx2hlo_8cc_source.html#l01725">onnx2hlo.cc:1725</a></div></div>
<div class="ttc" id="apolicy__map_8h_html"><div class="ttname"><a href="policy__map_8h.html">policy_map.h</a></div></div>
<div class="ttc" id="astructlczero_1_1Activations_html"><div class="ttname"><a href="structlczero_1_1Activations.html">lczero::Activations</a></div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00037">activation_function.h:37</a></div></div>
<div class="ttc" id="astructlczero_1_1Activations_html_a61bc2215e0e54dee6ce148dfa3194c89"><div class="ttname"><a href="structlczero_1_1Activations.html#a61bc2215e0e54dee6ce148dfa3194c89">lczero::Activations::smolgen_activation</a></div><div class="ttdeci">ActivationFunction smolgen_activation</div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00039">activation_function.h:39</a></div></div>
<div class="ttc" id="astructlczero_1_1Activations_html_acedf50afa85656c44557297ae292b2fe"><div class="ttname"><a href="structlczero_1_1Activations.html#acedf50afa85656c44557297ae292b2fe">lczero::Activations::default_activation</a></div><div class="ttdeci">ActivationFunction default_activation</div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00038">activation_function.h:38</a></div></div>
<div class="ttc" id="astructlczero_1_1Activations_html_af742824fa3de24a9ed53aaeb108f4743"><div class="ttname"><a href="structlczero_1_1Activations.html#af742824fa3de24a9ed53aaeb108f4743">lczero::Activations::ffn_activation</a></div><div class="ttdeci">ActivationFunction ffn_activation</div><div class="ttdef"><b>Definition</b> <a href="activation__function_8h_source.html#l00040">activation_function.h:40</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_1_1ConvBlock_html_a062401a39d4b2600851563d3dbde5c22"><div class="ttname"><a href="structlczero_1_1BaseWeights_1_1ConvBlock.html#a062401a39d4b2600851563d3dbde5c22">lczero::BaseWeights::ConvBlock::weights</a></div><div class="ttdeci">Vec weights</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00035">network_legacy.h:35</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_1_1ConvBlock_html_ab21313f91a9594669ee08868d6ce7200"><div class="ttname"><a href="structlczero_1_1BaseWeights_1_1ConvBlock.html#ab21313f91a9594669ee08868d6ce7200">lczero::BaseWeights::ConvBlock::biases</a></div><div class="ttdeci">Vec biases</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00036">network_legacy.h:36</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_a04d06ffa0a10ca7eadd5a6487eaab749"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#a04d06ffa0a10ca7eadd5a6487eaab749">lczero::BaseWeights::encoder</a></div><div class="ttdeci">std::vector&lt; EncoderLayer &gt; encoder</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00130">network_legacy.h:130</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_a218ce4baa9bb56870ffd003f13644899"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#a218ce4baa9bb56870ffd003f13644899">lczero::BaseWeights::ip_mov_b</a></div><div class="ttdeci">Vec ip_mov_b</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00139">network_legacy.h:139</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_a24798deb8d6e2f121fca8c0ff14b6f82"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#a24798deb8d6e2f121fca8c0ff14b6f82">lczero::BaseWeights::ip1_mov_b</a></div><div class="ttdeci">Vec ip1_mov_b</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00141">network_legacy.h:141</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_a34d8bebf0bc622ba0c2aabd0d15f1b8c"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#a34d8bebf0bc622ba0c2aabd0d15f1b8c">lczero::BaseWeights::ip_mov_w</a></div><div class="ttdeci">Vec ip_mov_w</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00138">network_legacy.h:138</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_a416c6acae612bf4d6175b91a572288ba"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#a416c6acae612bf4d6175b91a572288ba">lczero::BaseWeights::moves_left</a></div><div class="ttdeci">ConvBlock moves_left</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00137">network_legacy.h:137</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_a50df248b182ed963bd366a66d12bcf6d"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#a50df248b182ed963bd366a66d12bcf6d">lczero::BaseWeights::input</a></div><div class="ttdeci">ConvBlock input</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00105">network_legacy.h:105</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_a9582fabaa777e21eba5346b865646913"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#a9582fabaa777e21eba5346b865646913">lczero::BaseWeights::encoder_head_count</a></div><div class="ttdeci">int encoder_head_count</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00131">network_legacy.h:131</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_aa1cebf1449bd6f7ad6dba9de31500be7"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#aa1cebf1449bd6f7ad6dba9de31500be7">lczero::BaseWeights::ip2_mov_b</a></div><div class="ttdeci">Vec ip2_mov_b</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00143">network_legacy.h:143</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_af1184855e43ad9ab83b48cfb9070a1b9"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#af1184855e43ad9ab83b48cfb9070a1b9">lczero::BaseWeights::ip1_mov_w</a></div><div class="ttdeci">Vec ip1_mov_w</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00140">network_legacy.h:140</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_af20434c7ec66229e04a1230a1e2a54a1"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#af20434c7ec66229e04a1230a1e2a54a1">lczero::BaseWeights::ip2_mov_w</a></div><div class="ttdeci">Vec ip2_mov_w</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00142">network_legacy.h:142</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_afd8cd75e63fb1aedd507537dd8cc0318"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#afd8cd75e63fb1aedd507537dd8cc0318">lczero::BaseWeights::ip_emb_b</a></div><div class="ttdeci">Vec ip_emb_b</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00113">network_legacy.h:113</a></div></div>
<div class="ttc" id="astructlczero_1_1BaseWeights_html_aff24b3bb61649f83ec691c756b584ff7"><div class="ttname"><a href="structlczero_1_1BaseWeights.html#aff24b3bb61649f83ec691c756b584ff7">lczero::BaseWeights::residual</a></div><div class="ttdeci">std::vector&lt; Residual &gt; residual</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00134">network_legacy.h:134</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html">lczero::MultiHeadWeights::PolicyHead</a></div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00181">network_legacy.h:181</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_a4ad6b4f6a45370d2b027e485810f6664"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a4ad6b4f6a45370d2b027e485810f6664">lczero::MultiHeadWeights::PolicyHead::ip_pol_w</a></div><div class="ttdeci">Vec &amp; ip_pol_w</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00192">network_legacy.h:192</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_a66881320029e901b5440098017bebd40"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a66881320029e901b5440098017bebd40">lczero::MultiHeadWeights::PolicyHead::policy</a></div><div class="ttdeci">ConvBlock policy</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00196">network_legacy.h:196</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_a6708295c625a521a7b574d5c686ef902"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a6708295c625a521a7b574d5c686ef902">lczero::MultiHeadWeights::PolicyHead::ip3_pol_b</a></div><div class="ttdeci">Vec ip3_pol_b</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00201">network_legacy.h:201</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_a989114dff69e54ef3ade4e826b10050e"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#a989114dff69e54ef3ade4e826b10050e">lczero::MultiHeadWeights::PolicyHead::pol_encoder</a></div><div class="ttdeci">std::vector&lt; EncoderLayer &gt; pol_encoder</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00204">network_legacy.h:204</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_ab693b3cf4392b0a4e2e5e2f71c31e942"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#ab693b3cf4392b0a4e2e5e2f71c31e942">lczero::MultiHeadWeights::PolicyHead::ip2_pol_b</a></div><div class="ttdeci">Vec ip2_pol_b</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00199">network_legacy.h:199</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_abf72641a1aa339a3fcfbb090e8f15069"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#abf72641a1aa339a3fcfbb090e8f15069">lczero::MultiHeadWeights::PolicyHead::policy1</a></div><div class="ttdeci">ConvBlock policy1</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00195">network_legacy.h:195</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_af4967d303488d7d3c623f9db707e5281"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#af4967d303488d7d3c623f9db707e5281">lczero::MultiHeadWeights::PolicyHead::pol_encoder_head_count</a></div><div class="ttdeci">int pol_encoder_head_count</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00203">network_legacy.h:203</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1PolicyHead_html_afa3328e192dbca1c42f672b922c58c07"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1PolicyHead.html#afa3328e192dbca1c42f672b922c58c07">lczero::MultiHeadWeights::PolicyHead::ip_pol_b</a></div><div class="ttdeci">Vec &amp; ip_pol_b</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00193">network_legacy.h:193</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_1_1ValueHead_html"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights_1_1ValueHead.html">lczero::MultiHeadWeights::ValueHead</a></div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00207">network_legacy.h:207</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_html"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights.html">lczero::MultiHeadWeights</a></div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00178">network_legacy.h:178</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_html_a48356a0287e65c36497e0bb0f70283e0"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights.html#a48356a0287e65c36497e0bb0f70283e0">lczero::MultiHeadWeights::value_heads</a></div><div class="ttdeci">std::unordered_map&lt; std::string, ValueHead &gt; value_heads</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00227">network_legacy.h:227</a></div></div>
<div class="ttc" id="astructlczero_1_1MultiHeadWeights_html_a70de487aab76d3bd5cd544c2355d5d15"><div class="ttname"><a href="structlczero_1_1MultiHeadWeights.html#a70de487aab76d3bd5cd544c2355d5d15">lczero::MultiHeadWeights::policy_heads</a></div><div class="ttdeci">std::unordered_map&lt; std::string, PolicyHead &gt; policy_heads</div><div class="ttdef"><b>Definition</b> <a href="network__legacy_8h_source.html#l00228">network_legacy.h:228</a></div></div>
<div class="ttc" id="astructlczero_1_1NetworkCapabilities_html"><div class="ttname"><a href="structlczero_1_1NetworkCapabilities.html">lczero::NetworkCapabilities</a></div><div class="ttdoc">Describes the capabilities and requirements of a neural network backend.</div><div class="ttdef"><b>Definition</b> <a href="network_8h_source.html#l00122">network.h:122</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1CudaGraphCapture_html"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1CudaGraphCapture.html">lczero::cudnn_backend::CudaGraphCapture</a></div><div class="ttdoc">Forward declaration of CudaGraphCapture.</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00250">inputs_outputs.h:250</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html">lczero::cudnn_backend::InputsOutputs</a></div><div class="ttdoc">Manages input and output buffers for the network.</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00078">inputs_outputs.h:78</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a0d6a81afd143971bdd7b624e63ba4f87"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a0d6a81afd143971bdd7b624e63ba4f87">lczero::cudnn_backend::InputsOutputs::op_moves_left_mem_</a></div><div class="ttdeci">DataType * op_moves_left_mem_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00207">inputs_outputs.h:207</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a0f56c096b24f7992e92fdef66c78ed65"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a0f56c096b24f7992e92fdef66c78ed65">lczero::cudnn_backend::InputsOutputs::cuda_graphs_</a></div><div class="ttdeci">std::unique_ptr&lt; CudaGraphExec&lt; DataType &gt;[]&gt; cuda_graphs_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00241">inputs_outputs.h:241</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a123f601c65e02f3f56afed1d6a0ea081"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a123f601c65e02f3f56afed1d6a0ea081">lczero::cudnn_backend::InputsOutputs::op_policy_mem_gpu_</a></div><div class="ttdeci">DataType * op_policy_mem_gpu_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00212">inputs_outputs.h:212</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a1dd4b31880458cf40c1846c96b0ffb85"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a1dd4b31880458cf40c1846c96b0ffb85">lczero::cudnn_backend::InputsOutputs::compute_stream_</a></div><div class="ttdeci">cudaStream_t compute_stream_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00227">inputs_outputs.h:227</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a30d21cb6211dea2b644fc266b2346a0b"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a30d21cb6211dea2b644fc266b2346a0b">lczero::cudnn_backend::InputsOutputs::input_val_mem_</a></div><div class="ttdeci">DataType * input_val_mem_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00204">inputs_outputs.h:204</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a4da2faa3d3467b0b891fda272ec89186"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a4da2faa3d3467b0b891fda272ec89186">lczero::cudnn_backend::InputsOutputs::exec_stream_</a></div><div class="ttdeci">cudaStream_t exec_stream_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00240">inputs_outputs.h:240</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a54e36f778959e1698ea7f47ca3069d26"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a54e36f778959e1698ea7f47ca3069d26">lczero::cudnn_backend::InputsOutputs::download_done_event_</a></div><div class="ttdeci">cudaEvent_t download_done_event_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00237">inputs_outputs.h:237</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a571a3d91326a06e4ef7ec76e949627c2"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a571a3d91326a06e4ef7ec76e949627c2">lczero::cudnn_backend::InputsOutputs::scratch_mem_</a></div><div class="ttdeci">void * scratch_mem_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00222">inputs_outputs.h:222</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a5e256066b490e604c805c7f536ef06f9"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a5e256066b490e604c805c7f536ef06f9">lczero::cudnn_backend::InputsOutputs::head_offset_pointers_</a></div><div class="ttdeci">void ** head_offset_pointers_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00224">inputs_outputs.h:224</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a7306070b1b58feb189bc380e0071e7a1"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7306070b1b58feb189bc380e0071e7a1">lczero::cudnn_backend::InputsOutputs::cublas_</a></div><div class="ttdeci">cublasHandle_t cublas_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00245">inputs_outputs.h:245</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a7c64b4d62f281e4fc83f0dfcf82cfb08"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7c64b4d62f281e4fc83f0dfcf82cfb08">lczero::cudnn_backend::InputsOutputs::op_value_mem_gpu_</a></div><div class="ttdeci">DataType * op_value_mem_gpu_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00213">inputs_outputs.h:213</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a7cf020ede9475c67907d528517fbb559"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a7cf020ede9475c67907d528517fbb559">lczero::cudnn_backend::InputsOutputs::op_policy_mem_</a></div><div class="ttdeci">DataType * op_policy_mem_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00205">inputs_outputs.h:205</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a86b4ff2bf7753745691b0e2d2d445697"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a86b4ff2bf7753745691b0e2d2d445697">lczero::cudnn_backend::InputsOutputs::value_done_event_</a></div><div class="ttdeci">cudaEvent_t value_done_event_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00234">inputs_outputs.h:234</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a88cce011cef46a3778871a606e2cfb0d"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a88cce011cef46a3778871a606e2cfb0d">lczero::cudnn_backend::InputsOutputs::tensor_mem_</a></div><div class="ttdeci">void * tensor_mem_[3]</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00221">inputs_outputs.h:221</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a8912b9a29a368748dfb2c2a0f6ef8e81"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a8912b9a29a368748dfb2c2a0f6ef8e81">lczero::cudnn_backend::InputsOutputs::input_masks_mem_gpu_</a></div><div class="ttdeci">uint64_t * input_masks_mem_gpu_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00210">inputs_outputs.h:210</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a96fb812fdea09c0bfb3652971b33ff4d"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a96fb812fdea09c0bfb3652971b33ff4d">lczero::cudnn_backend::InputsOutputs::offset_pointers_</a></div><div class="ttdeci">void ** offset_pointers_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00223">inputs_outputs.h:223</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a9b3778db8e28d7d69e3a411b021f382d"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9b3778db8e28d7d69e3a411b021f382d">lczero::cudnn_backend::InputsOutputs::wdl_download_done_event_</a></div><div class="ttdeci">cudaEvent_t wdl_download_done_event_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00236">inputs_outputs.h:236</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_a9c9eb0b6e28c313e2ebcc1a4e5f8155b"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#a9c9eb0b6e28c313e2ebcc1a4e5f8155b">lczero::cudnn_backend::InputsOutputs::op_value_mem_</a></div><div class="ttdeci">DataType * op_value_mem_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00206">inputs_outputs.h:206</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_aa9840db2798fa87fd3b8b229b876297b"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aa9840db2798fa87fd3b8b229b876297b">lczero::cudnn_backend::InputsOutputs::op_moves_left_mem_gpu_</a></div><div class="ttdeci">DataType * op_moves_left_mem_gpu_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00214">inputs_outputs.h:214</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_aac9567857edcb49b00e14289ba13879c"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aac9567857edcb49b00e14289ba13879c">lczero::cudnn_backend::InputsOutputs::upload_done_event_</a></div><div class="ttdeci">cudaEvent_t upload_done_event_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00232">inputs_outputs.h:232</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_ac2d5c4d887a02dd9412fb7feb86f1a12"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#ac2d5c4d887a02dd9412fb7feb86f1a12">lczero::cudnn_backend::InputsOutputs::input_masks_mem_</a></div><div class="ttdeci">uint64_t * input_masks_mem_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00203">inputs_outputs.h:203</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_acbcc77293f33466a563a107ba64ee66f"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acbcc77293f33466a563a107ba64ee66f">lczero::cudnn_backend::InputsOutputs::download_stream_</a></div><div class="ttdeci">cudaStream_t download_stream_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00229">inputs_outputs.h:229</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_acde2451f3e98943ed59a4642835d5970"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acde2451f3e98943ed59a4642835d5970">lczero::cudnn_backend::InputsOutputs::policy_done_event_</a></div><div class="ttdeci">cudaEvent_t policy_done_event_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00233">inputs_outputs.h:233</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_acfb18940f77e933875fa4c5ee1fc4fc3"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acfb18940f77e933875fa4c5ee1fc4fc3">lczero::cudnn_backend::InputsOutputs::input_val_mem_gpu_</a></div><div class="ttdeci">DataType * input_val_mem_gpu_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00211">inputs_outputs.h:211</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_acfddb909034c09e42b6a25dd2c3fb49d"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#acfddb909034c09e42b6a25dd2c3fb49d">lczero::cudnn_backend::InputsOutputs::moves_left_done_event_</a></div><div class="ttdeci">cudaEvent_t moves_left_done_event_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00235">inputs_outputs.h:235</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_aebb70855764f1d081f94c14144b5d834"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aebb70855764f1d081f94c14144b5d834">lczero::cudnn_backend::InputsOutputs::upload_stream_</a></div><div class="ttdeci">cudaStream_t upload_stream_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00228">inputs_outputs.h:228</a></div></div>
<div class="ttc" id="astructlczero_1_1cudnn__backend_1_1InputsOutputs_html_aed753991b629b7e429233f65cb1cb40c"><div class="ttname"><a href="structlczero_1_1cudnn__backend_1_1InputsOutputs.html#aed753991b629b7e429233f65cb1cb40c">lczero::cudnn_backend::InputsOutputs::wdl_cpu_softmax_</a></div><div class="ttdeci">std::unique_ptr&lt; float[]&gt; wdl_cpu_softmax_</div><div class="ttdef"><b>Definition</b> <a href="cuda_2inputs__outputs_8h_source.html#l00216">inputs_outputs.h:216</a></div></div>
<div class="ttc" id="asycl_2inputs__outputs_8h_html"><div class="ttname"><a href="sycl_2inputs__outputs_8h.html">inputs_outputs.h</a></div></div>
<div class="ttc" id="asycl_2kernels_8h_html"><div class="ttname"><a href="sycl_2kernels_8h.html">kernels.h</a></div></div>
<div class="ttc" id="asycl_2layers_8h_html"><div class="ttname"><a href="sycl_2layers_8h.html">layers.h</a></div></div>
<div class="ttc" id="atrace_8h_html"><div class="ttname"><a href="trace_8h.html">trace.h</a></div></div>
<div class="ttc" id="atrace_8h_html_a389db795981333907e77e3454e1fcbf3"><div class="ttname"><a href="trace_8h.html#a389db795981333907e77e3454e1fcbf3">LCTRACE_FUNCTION_SCOPE</a></div><div class="ttdeci">#define LCTRACE_FUNCTION_SCOPE</div><div class="ttdef"><b>Definition</b> <a href="trace_8h_source.html#l00070">trace.h:70</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_bd24ae0ef06be76c437fa34de7a105aa.html">neural</a></li><li class="navelem"><a class="el" href="dir_58abfc17a9a6ed07a1f39066bdc89238.html">backends</a></li><li class="navelem"><a class="el" href="dir_126b39772f0557f9803560f7a96cadf3.html">cuda</a></li><li class="navelem"><a class="el" href="network__cuda_8cc.html">network_cuda.cc</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../images/doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
